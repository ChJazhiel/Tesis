\documentclass[a4paper,openright,12pt]{book}
\usepackage[spanish]{babel}
\usepackage[utf8]{inputenc} 
\usepackage{amssymb, amsmath, amsbsy} % simbolitos
\usepackage{upgreek} % para poner letras griegas sin cursiva
\usepackage{cancel} % para tachar
\usepackage{mathdots} % para el comando \iddots
\usepackage{mathrsfs} % para formato de letra
\usepackage{stackrel} % para el comando \stackbin
\usepackage{graphicx} %para meter figuritas chavo
\usepackage{subfigure} %para más figuritas
\usepackage{float} % para que las imágenes me obedezcan. Como sirve este pedo
\usepackage{enumerate} %para enumerar ps es obvio OBVIO
\setcounter{secnumdepth}{3} %para que ponga 1.1.1.1 en subsubsecciones
\setcounter{tocdepth}{3} % para que ponga subsubsecciones en el indice


\begin{document}

\begin{titlepage}
\begin{center}
\begin{Huge}
\textsc{Modelos de Materia Oscura: Una Perspectiva Numérica}
\end{Huge}
\end{center}
\end{titlepage}

% para crear una cara en blanco
\newpage
$\ $
\thispagestyle{empty} % para que no se numere esta página

\chapter*{}
\pagenumbering{Roman} % para comenzar la numeración de paginas en números romanos
\begin{flushright}
\textit{Dedicado a \\
mi familia}
\end{flushright}

\chapter*{Agradecimientos} % si no queremos que añada la palabra "Capitulo"
\addcontentsline{toc}{chapter}{Agradecimientos} % si queremos que aparezca en el índice
\markboth{AGRADECIMIENTOS}{AGRADECIMIENTOS} % encabezado

¡Muchas gracias a todos!

\chapter*{Resumen} % si no queremos que añada la palabra "Capitulo"
\addcontentsline{toc}{chapter}{Resumen} % si queremos que aparezca en el índice
\markboth{RESUMEN}{RESUMEN} % encabezado

\tableofcontents % indice de contenidos

\cleardoublepage
\addcontentsline{toc}{chapter}{Lista de figuras} % para que aparezca en el indice de contenidos
\listoffigures % indice de figuras

\cleardoublepage
\addcontentsline{toc}{chapter}{Lista de tablas} % para que aparezca en el indice de contenidos
\listoftables % indice de tablas




\chapter{Introducción a la Cosmología}
\pagenumbering{arabic}
La cosmología es la ciencia que estudia y busca explicar el origen y la evolución del Universo como un todo, la física fundamental detrás de esos procesos y por lo tanto obtener un entendimiento más profundo de las leyes de la física que se supone que gobiernan a todo el Universo. Sin embargo existe solo un Universo que se puede estudiar y no se puede  experimentar con el, sólo hacer observaciones. Esto conlleva bastantes limitantes sobre lo que se puede conocer acerca de su origen \cite{1.01}. 

\textbf{El Universo es homogéneo e isótropo en un espacio tridimensional}. Esta pequeña pero poderosa frase es lo que se conoce como el \textit{Principio cosmológico}. Que sea homogéneo se refiere a que la materia está uniformemente distribuida en todo el espacio, mientras que isótropo hace referencia a que tiene las mismas propiedades en todas las direcciones espaciales. Así, en un Universo homogéneo e isótropo la distribución de materia sería la misma para cualquier observador en cualquier ubicación del espacio, es decir, ningún lugar sería preferencial de acuerdo a este principio.

Suponer que el principio cosmológico implica un Universo infinito es un poco ingenuo. La teoría de la relatividad nos dice que el espacio puede ser curvo y que, por tanto, es imaginable un Universo finito que no tenga bordes. Una imagen intuitiva utilizada por Einstein y Hubble, que permite la captación de la posibilidad de un Universo finito compatible con el principio cosmológico es la de un Universo bidimensional formando una superficie esférica. Sobre ella, un observador bidimensional podría recorrer todo el Universo, por ser finito, y nunca encontrarse con el borde. Esta imagen, llevada a las tres dimensiones espaciales de nuestro Universo real, nos permite comprender el Universo finito y sin bordes.

Pero la concepción de un universo finito y cerrado conlleva a un problema de \textit{coalescencia}. Esto es, la gravedad haría que, con tiempo suficiente, todas las galaxias se atrajeran, amontonando toda la masa del Universo en un solo punto. ¿Hay alguna forma de evitar la coalescencia? La relatividad nos enseña que todo movimiento es siempre en referencia de algo; no hay movimiento absoluto. Si se introduce un Universo en expansión, ciertamente se evitaría la coalescencia. Las galaxias no se abalanzarían unas sobre otras si inicialmente hubiera habido una ``explosión'' y estuvieran alejándose por su efecto. La autogravitación del Universo iría frenando la expansión y podría llegar a detenerla, o no podría, dependiendo de la violencia de la expansión inicial y de la densidad de galaxias.

Estas ideas están muy cercanas a la modelación del Big Bang, modelo del Universo aceptado hoy día. La idea intuitiva, aunque básica y simple, debe ajustarse a unas bases físicas más firmes. Por ejemplo, la homogeneidad del principio cosmológico anula los gradientes de parámetros termodinámicos, lo que reduce la expresión de las ecuaciones que gobiernan el Universo.

Se requieren algunas precisiones más para entender el principio cosmológico. Si un observador ve el Universo isótropo, otro que se mueva a gran velocidad con respecto a él ya no podrá verlo isótropo. Este segundo observador vería un \textit{desplazamiento Doppler} hacia el azul de las galaxias en la dirección de su movimiento, y verá desplazadas hacia el rojo las galaxias que se alejan de él. Por lo tanto si el principio cosmológico se cumple para el primer observador, no lo haría para el segundo.

La teoría de la relatividad general nos resuelve el problema. Esta teoría establece que en todo punto del espacio, en un sistema cualquiera (no forzosamente el Universo) existe un observador que ve su microentorno plano, en el sentido de que para él no hay gravedad, de que para él se cumplen las leyes de la relatividad restringida. ¿Quién es ese individuo que goza de tan grande privilegio? Es muy sencillo: cualquiera puede adquirir ese título de observador inimaginable dejando de lado a la gravedad.

En uno de los experimentos mentales de Einstein, un observador en un ascensor que cayera libremente no pesaría sobre el suelo del ascensor ni notaría ningún efecto gravitatorio. Por eso, a dichos observadores privilegiados se les puede llamar \textit{observadores cayentes}. Para ellos se cumple el principio cosmológico. En cuanto al Universo, estos observadores cayentes se les llama \textit{observadores fundamentales}.

Otra precisión importante para entender el principio cosmológico es la de \textit{tiempo cósmico}. La teoría de la relatividad nos dice que cada observador tiene su tiempo. Por tanto, podría pensarse que no todos los observadores fundamentales tienen el mismo tiempo. El principio cosmológico equivale a decir que sí, que todos los observadores fundamentales pueden tener el mismo tiempo. Todos los observadores ven el mismo Universo si lo hacen en ese tiempo común a todos ellos. Este tiempo común se le conoce como \textit{tiempo cósmico}. El principio cosmológico, para atenerse a las premisas relativistas, debe entenderse así: \textit{todos los observadores fundamentales ven lo mismo cuando utilizan ese tiempo cósmico común a todos ellos} \cite{1.02}.

%-----------------------------------------------------------------------------%

\section{La Expansión del Universo}
Según la \textit{ley de Hubble} \cite{1.1} la velocidad ``aparente'' $\vec{v}$ de alejamiento de unas galaxias es porporcional a su distancia $\vec{r}$
\begin{equation}
\vec{v} = H\vec{r}.\label{eqn 1.1}
\end{equation}
Las tres cantidades de la ecuación cambian con el tiempo, por lo que se escriben como funciones $\vec{v}(t), H(t), \vec{r}(t)$. Para ser precisos $\vec{r}(t)$ es la \textit{distancia propia}, esto es, la distancia que sería medida entre una galaxia y nosotros en un tiempo $t$. La velocidad de recesión $\vec{v}$ es el ritmo al cual $\vec{r}$ incrementa, y $H$, el \textit{parámetro de Hubble}, es constante en todo el espacio debido a la homogeneidad. Muchas teorías predicen que cambia con el tiempo, $H = H(t)$. En cosmología se le da al valor de la época actual el subíndice cero. Así el parámetro de Hubble al día de hoy, a un tiempo $t= t_{0}$ es $H(t_{0})= H_{0}$. Esta es la \textit{constante de Hubble}.

Para un poco más de claridad, es de mucha ayuda introducir las \textit{coordenadas comóviles}. Un sistema de referencia comóvil de una partícula es un sistema de referencia que se mueve junto con una partícula, y por tanto, respecto a un sistema de referencia comóvil una partícula siempre está en reposo. Las coordenadas comóviles se expanden junto con el Universo. Si nuestra galaxia tiene una coordenada comóvil $\vec{x}=0$ y otra galaxia tiene una coordenada comóvil $\vec{x}$, entonces, la distancia propio hasta ella es
\begin{equation}
\vec{r} = a(t)\vec{x}\label{eqn 1.2}
\end{equation}
donde $a(t)$ es llamado el \textit{factor de escala} que depende del tiempo, no de la posición. Puede definirse ahora la velocidad $v$ como 
\begin{equation}
\vec{r} = \dot{\vec{r}} = H\vec{r},\label{eqn 1.3}
\end{equation}
\begin{equation}
\frac{d}{dt}(a\vec{x})= Ha\vec{x}.\label{eqn 1.4}
\end{equation} 
Por definición, la coordenada comóvil no depende del tiempo, por lo que todo el cambio en $(a\vec{x})$ debe ser solo para $a$. Esto lleva a cancelar $\vec{x}$ de nuestra ecuación (\ref{eqn 1.4}) y se tiene así la siguiente expresión para el parámetro de Hubble
\begin{equation}
H(t) = \frac{\dot{a}(t)}{a(t)}.\label{eqn 1.5}
\end{equation}
Otro parámetro importante es el corrimiento al rojo o \textit{redshift}. La luz de las galaxias y estrellas distantes no es monótona, sino que tiene diferentes características espectrales propias de los átomos de los gases de alrededor de las estrellas. Cuando se examinan estos espectros, se encuentran que están desplazados hacia el extremo rojo del espectro. Este cambio es al parecer por un desplazamiento Doppler, e indica que esencialmente todas las galaxias se están alejando del observador. El redshift se define entonces como 
\begin{equation}
 z \equiv \frac{\lambda - \lambda_{0}}{\lambda_{0}}\label{eqn 1.6}
\end{equation}
siendo $\lambda_{0}$ la longitud de onda de una línea espectral de la galaxia y $\lambda$, la longitud de onda de esa misma línea espectral medida en la Tierra. Las velocidades se infieren con una fórmula aproximada 
\begin{equation*}
z \approx \frac{v}{c}.
\end{equation*}
En la actualidad, se observan galaxias con redshift mucho mayor que ese. Para entender esto, se requiere un análisis más profundo sobre la naturaleza del redshift. Considerando un fotón emitido desde una galaxia hacia una galaxia cercana con una distancia propia $dr$, por cercana entiéndase lo bastante próxima para suponer que la diferencia de velocidades entre las galaxias $dv$ está dada por la fórmula $dv = cz$. El fotón hace su viaje en un tiempo $dt = dr/c$, durante este período, el factor de escala incrementa una pequeña cantidad $da = \dot{a} dt$. La velocidad relativa entre las galaxias es
\begin{equation}
d\vec{v}=Hd\vec{r}=\frac{\dot{a}}{a}cdt=c\frac{da}{a}.\label{eqn 1.7}
\end{equation}
El pequeño cambio en la longitud de onda se escribe como $ \lambda - \lambda_{0} = d\lambda$; sustituyendo esto y la fórmula de velocidad-redshift, se obtiene
\begin{equation}
c\frac{da}{a}=d\vec{v}=cz=c\frac{d\lambda}{\lambda}.\label{eqn 1.8}
\end{equation}
Esto es, en el pequeño intervalo de tiempo $dt$, el cambio fraccional en la longitud de onda es la misma que el crecimiento fraccional en el Universo. Ahora, suponga que el fotón rebasa a la segunda galaxia y viaja un largo camino a través del Universo antes de ser detectado en una tercera galaxia (la Vía Láctea, por ejemplo). La misma formulación de las ecuaciones (\ref{eqn 1.7}) y (\ref{eqn 1.8}) puede hacerse para cualquier segmento pequeño de su camino, la longitud de onda y el factor de escala seguirán siendo proporcionales $\lambda \propto a$, es decir
\begin{equation}
\frac{\lambda}{\lambda_{0}}= \frac{t_{0}}{t_{em}}.\label{eqn 1.9}
\end{equation}
¡El fotón se expande en la misma proporción que lo hace el Universo! El significado profundo del redshift cosmológico
\begin{equation}
z = \frac{\lambda}{\lambda_{0}} - 1\label{eqn 1.10}
\end{equation} 
es que $(1+z)$ dice cuánto se ha expandido el Universo desde que la luz fue emitida. Aunque se usó el efecto Doppler en el argumento, el resultado de añadir todos los efectos infinitesimales es muy diferente al de uno muy grande. Por ejemplo, el redshift no depende de la velocidad $v(t)$, ni en el presente $t_{0}$ ni en la época de emisión $(t_{em})$. Para comprobarlo, suponga que el Universo no estuvo expandiéndose cuando el fotón fue emitido, i.e. $H(t_{em}=0)$, así $\vec{v}(t_{em})=0$. El Universo empieza su expansión, pero se detiene nuevamente antes de que el fotón llegue a su destino, es decir $\vec{v}(t_{0})=0$. El fotón aún tendría un redshift porque la expansión ocurrió mientras estaba en movimiento.

Todo esto indica que los altos redshifts de las galaxias distantes no necesariamente implica que las velocidades de recesión son mayores a la velocidad de la luz. Como se esperaría, la ecuación $cz = H\vec{r}$ es sólo válida para redshifts pequeños. Examinando nuevamente la ecuación (\ref{eqn 1.1}), que como se puntualizó, siempre es cierta para \textit{cualquier} separación. Si un observador fuese suficientemente lejos, $\vec{v}$ sería más rápida que la velocidad de la luz. Los fotones emitidos desde esa distancia no lo alcazarían, a menos que el Universo empezara a desacelerar en algún tiempo en el futuro. Podría ser capaces o no de observar que dejaron esa galaxia hace miles de millones de años, dependiendo de si el Universo ha acelerado en el pasado.

Algunos cosmólogos tratan de evitar esta conclusión diciendo que el valor del incremento en la distancia propia no es una velocidad ``real''; argumentan que es el espacio entre las galaxias el que se está expandiendo, mientras las galaxias están mas o menos en reposo. En efecto, esta aproximación prefiere distancia comóvil a distancia propia. A veces es útil pensar de esta manera, pero no hay diferencia, almenos físicamente entre dos galaxias ``realmente'' separándose unas de otras y dos galaxias estacionarias con la intervención de la expansión del espacio. Ambas son descripciones equivalentes de la relatividad general.\\\\\\


%---------------------------------------------------------------------------------%
\subsection*{Ecuaciones de Einstein}

La Relatividad General, está conformada esencialmente por 10 ecuaciones diferenciales acopladas, la cual rige la física de los sistemas gravitacionales. Para trabajar con relatividad general, se inicia introduciendo un espacio-tiempo mediante la ecuación de la métrica
\begin{equation}
ds^{2}=g_{\alpha \beta}dx^{\alpha}dx^{\beta}\label{eqn 1.11}
\end{equation}

\begin{equation}
R_{\alpha \beta} - \frac{1}{2} R g_{\alpha \beta} + \Lambda g_{\alpha \beta} = 0,\label{eqn 1.12}
\end{equation}
donde $R_{\alpha \beta}$ es el tensor de Riemann, $R$ es el escalar de curvatura de Ricci, $g_{\alpha \beta}$ es el tensor métrico y $\Lambda$ es la constante cosmológica. En presencia de materia y energía, las ecuaciones de campo de Einstein se convierten en \cite{1.4}
\begin{equation}
R_{\mu \nu} - \frac{1}{2} R g_{\mu \nu} + \Lambda g_{\mu \nu} = \kappa T_{\mu \nu}\label{eqn 1.13}
\end{equation}
donde $T_{\mu \nu}$ es el tensor de energía-momento y $\kappa$ es una constante, cuyo valor es $\kappa = 8 \pi G / c^{4}$.

%-------------------------------------------------------------------------------%

\subsection*{Métrica de Friedmann-Lemaître-Robertson-Walker}
Basados en la suposición de homogeneidad e isotropía, las ecuaciones de movimiento del Universo se pueden deducir de la siguiente forma. Sean dos eventos en el espacio--tiempo, uno ocurriendo en el punto localizado en $(t,r,\theta , \phi)$ y otro ocurriendo en el punto localizado en $(t +dt, r + dr, \theta + d\theta, \phi + d\phi)$. La separación espacio-temporal entre estos dos eventos es
\begin{equation}
ds^{2}=-c^{2}dt^{2} + dr_{2} +r^{2}d\Omega^{2},\label{eqn 1.14}
\end{equation}
donde
\begin{equation*}
d\Omega^{2} \equiv d\theta^{2} + \sin^{2}\theta d\phi^{2}.
\end{equation*}
La métrica descrita por la ecuación (\ref{eqn 1.14}) es llamada \textit{métrica de Minkowski}, y el espacio-tiempo que ella describe es el espacio-tiempo de Minkowski. De la teoría de la relatividad general se sabe el camino que describe un fotón en un espacio-tiempo es una \textit{geodésica} y que para cualquier espacio-- tiempo, ésta debe ser \textit{nula}, es decir $ds=0$. En un espacio--tiempo de Minkowski, la trayectoria de un fotón obedece la relación
\begin{equation}
ds^{2}=0 = -c^{2}dt^{2} + dr_{2} +r^{2}\Omega^{2}.\label{eqn 1.15}
\end{equation}
Si el fotón se mueve de forma radial alejándose del origen, lo que significa que $\theta$ y $\phi$ son constantes, entonces
\begin{equation}
c^{2}dt^{2}=dr^{2},\label{eqn 1.16}
\end{equation}
es decir
\begin{equation}
\frac{dr}{dt}=\pm c. \label{eqn 1.17}
\end{equation}
La métrica de Minkowski de la ecuación (\ref{eqn 1.14}) aplica solamente dentro del contexto de la relatividad especial, sin efectos gravitacionales, el resultado será una  métrica que es plana. Al añadir la gravedad, sin embargo, el espacio-timepo toma una forma más interesante. En la década de 1930 los físicos Howard Robertson y Arthur Walker llegaron a un resultado, de manera independiente, que se conoció como la \textit{métrica de Robertson--Walker} y cuya forma es generalmente conocida como
\begin{equation}
ds^{2}
=
-c^{2}dt^{2} + a^{2}(t)
\left[
\frac{dr^{2}}{1-k r^{2}} + r^{2}d\Omega^{2}
\right],\label{eqn 1.18}
\end{equation}
donde $k > 0$, $k = 0$ o $k < 0$. Todos los modelos homogéneos e isotrópicos tienen esta forma. Para $k > 0$ se tiene un espacio--tiempo con curvatura positiva y se llaman modelos \textit{cerrados}. Para $k = 0$ se tiene un espacio--tiempo Euclideano o \textit{plano}. Por último, para $k < 0$ se tiene un espacio--tiempo con curvatura negativa y a estos modelos se les llama \textit{abiertos}.

En escalas pequeñas, sin embargo, se ha observado que el Universo \textit{no} es homogéneo. Por lo que la métrica de Robertson--Walker es sólo una aproximación que es buena para escalas mayores. En un sentido cosmológico, las ecuaciones de Einstein pueden usarse para encontrar una relación entre el factor de escala $a(t)$, la curvatura $\kappa$, y los contenidos de densidad de energía $\epsilon(t)$ y presión $p(t)$ del Universo. Las ecuaciones que hacen esto posible son las \textit{Ecuaciones de Friedmann}, encontradas por Alexander Alexandrovich Friedmann en 1922, sorprendentemente 7 años antes de los trabajos publicados por Hubble y en ellas ya consideraba que un Universo homogéneo e isotrópico se expandía como función del tiempo. 

Recordando la ley de Hubble (\ref{eqn 1.1}) la ecuación de Friedmann puede escribirse de la siguiente manera
\begin{equation}
H^{2}(t) = \frac{8 \pi G}{3 c^{2}}\epsilon(t) 
-\frac{k c^{2}}{a^{2}(t)}.\label{eqn 1.19}
\end{equation}
Con $H(t) \equiv \dot{a}/a$.

En la época actual, esta ecuación es 
\begin{equation}
H_{0} = H(t_{0}) = \left(\frac{\dot{a}}{a}\right) 
_{t=t_{0}} = 70 \pm 7 \textup{km s}^{-1} \textup{Mpc}^{-1},\label{eqn 1.20}
\end{equation}
donde $H_{0}$ es la constante de Hubble. Así, la ecuación de Friedmann en la época actual es $(a(t) = 1)$ 
\begin{equation}
H_{0}^{2} = \frac{8 \pi G}{3 c^{2}}\epsilon_{0} 
-k c^{2}. \label{eqn 1.21}
\end{equation}
Lo anterior ofrece una relación entre $H_{0}$, la cual dice la rapidez de expansión, $\epsilon_{0}$, la densidad de energía actual, y $\kappa$, que indica la curvatura actual. Esta ecuación es válida para todo Universo con una métrica de Robertson--Walker gobernada por las reglas de la relatividad general. En un Universo plano $(k = 0)$ la ecuación de Friedmann se reduce a la expresión
\begin{equation}
H^{2}(t)=\frac{8 \pi G}{3 c^{2}}\epsilon(t).\label{eqn 1.22}
\end{equation}
Así, para un valor dado del parámetro de Hubble, existe una \textit{densidad crítica}
\begin{equation}
\epsilon_{c}(t) \equiv \frac{3 c^{2}}{8 \pi G} H^{2}(t).\label{eqn 1.23}
\end{equation}
Si la densidad de energía $\epsilon(t)$ es mayor a este valor, el Universo tiene curvatura positiva $(k = +1)$. Si $\epsilon(t)$ es menor a este valor, el Universo tiene curvatura negativa. Dado que se tiene un valor actual del parámetro de Hubble, se calcula la densidad crítica
\begin{equation}
\epsilon_{c,0} = \frac{3 c^{2}}{8 \pi G}H_{0}^{2}
=
(8.3 \pm 1.7) \times 10^{-10} \textup{J m} ^{-3}
=
5200 \pm 1000 \textup{MeV m} ^{-3},\label{eqn 1.24}
\end{equation}
que suele escribirse de manera más común en términos de la \textit{densidad de masa crítica}
\begin{equation}
\rho_{c,0} \equiv \epsilon_{c,0}/c^{2}
=
(9.2 \pm 1.8) \times 10^{-27} \textup{kg m}^{-3}
=
(1.4 \pm 0.3) \times 10^{11} \textup{M}_{\odot} \textup{Mpc}^{-3}.\label{eqn 1.25}
\end{equation}

$M_{\odot}$ es una cantidad conocida como \textit{Masa solar} y su valor es $M_{\odot} = 1.989 \times 10^{30}$kg. Se ha supuesto, basados en el principio cosmológico, que el Universo es homogéneo e isotrópico. Para resolver las ecuaciones de campo de Einstein bajo esa suposición se requiere un tensor de energía--momento que sea también homogéneo e isótropo. La forma más general para tal tensor es la de un tensor para un fluido perfecto, que se escribe como \cite{1.2, 1.3}
\begin{equation}
T_{\mu \nu} =
(\rho + p)u_{\mu}u_{\nu} + pg_{\mu \nu},\label{eqn 1.26}
\end{equation}
donde $\rho$ es la densidad propia de masa del fluido, $u_{\mu}$ es la cuadrivelocidad y $p$ es la presión $(p > 0)$ o la tensión $(p < 0)$. La homogeneidad implica que la presión y la densidad deberían ser independientes de la posición y sólo deberían depender del tiempo. Para la métrica descrita en la ecuación (\ref{eqn 1.18}), este tensor es diagonal 
\begin{equation}
T_{\mu \nu} = \textup{diag}(\rho, p, p, p).\label{eqn 1.27}
\end{equation}
Insertando este resultado en las ecuaciones de campo de Einstein (\ref{eqn 1.11}), tomando $\Lambda = 0$ y normalizando $(c = 1)$ se tiene\\\\
\begin{equation}
\begin{array}{ll}
\;\;\;\;\;\;\;\;\; 3\frac{\dot{a}^{2} + k}{a^{2}}  = 8 \pi G \rho \\\\
-2\frac{\ddot{a}}{a} - \frac{\dot{a}^{2} + k}{a^{2}}= 8 \pi G p.
\end{array}\label{eqn 1.28}
\end{equation}\\\\
Esta es otra forma de escribir las ecuaciones de Friedmann, sin la constante cosmológica. Al combinar ambas ecuaciones se tiene
\begin{equation}
\frac{\ddot{a}}{a} = -\frac{4 \pi G}{3}(\rho + 3p), \label{eqn 1.29}
\end{equation}
donde la energía gravitacional efectiva viene dada por $(\rho + 3p)$; se observa que la presión también contribuye a la gravitación. Se puede deducir también una ecuación que relacione a la energía, la presión y el factor de escala. Usando la conservación de la energía, al diferenciar la ecuación (\ref{eqn 1.28}) conduce a una expresión como la siguiente
\begin{equation}
\dot{\rho} + 3\frac{\dot{a}}{a}(\rho + p) = 0,\label{eqn 1.30}
\end{equation}
que puede reescribirse como
\begin{equation}
\frac{d}{dt} (\rho a^{3}) + p\frac{d}{dt}a^{3} = 0.\label{eqn 1.31}
\end{equation}
Considerando un volumen comóvil $V = a^{3}$ e interpretando $\rho a^{3} = U$ como la energía en el volumen comóvil, se obtiene lo siguiente
\begin{equation}
dU + pdV = 0. \label{eqn 1.32}
\end{equation}
Recordando la primera ley de la termodinámica, dice que para un fluido en equilibrio se cumple que 
\begin{equation}
TdS = dU +pdV, \label{eqn 1.33}
\end{equation}
donde $T$ es la temperatura y $S$ es la entropía de fluido. Un proceso en el cual el cambio en la entropía es $dS = 0$ es llamado \textit{adiabático}. la ecuación \ref{eqn 1.32} muestra que el modelo homogéneo e isotrópico se expande de forma adiabática. No es extraño ya que la propia homogeneidad e isotropía implica que no haya gradientes de temperatura y no haya flujo de calor.

Si además se asume que el fluido perfecto obedece la ecuación de estado barotrópica, es decir, que la presión sea proporcional a la densidad
\begin{equation}
p = w\rho, \label{eqn 1.34}
\end{equation}
la ecuación (\ref{eqn 1.31}) se reescribe como sigue
\begin{equation}
\frac{d}{dt}(\rho a^{3}) + w p \frac{d}{dt} a^{3} = 0,\label{eqn 1.35}
\end{equation}
cuya solución es
\begin{equation}
\rho a^{3(w + 1)} = \rho _{0}, \label{eqn 1.36}
\end{equation}
donde $\rho _{0}$ es el valor de la densidad en la época presente. $w$ puede tomar diferentes valores que dependen de la época en la cual se esté considerando, esto es, existe una única presión para cada densidad dependiendo de la época:

-- Época actual (polvo) $\rightarrow$ $p=0$.

-- Época dominada por la radiación $\rightarrow$ $p = 1/3 \rho$.

Las ecuaciones de Friedmann (\ref{eqn 1.28}) para un Universo dominado por un fluido perfecto con ecuación de estado (\ref{eqn 1.34}) pueden escribirse como
\begin{equation}
\left(\frac{\dot{a}}{a}\right)^{2}
=
\frac{8 \pi G}{3} \frac{\rho _{0}}{a^{3(w + 1)}} - \frac{k}{a^{2}}.\label{eqn 1.37}
\end{equation}

Si $w > -1/3$ esta última ecuación indica que la evolución y posible destino del Universo dependerá de la curvatura espacial. Un Universo plano y uno con curvatura negativa se expanderá indefinidamente, mientras que un Universo con curvatura positiva detendrá su expansión y empezará a contraerse en algún punto. Si $w < -1/3$ la expansión seguirá para cualquier tiempo independientemente de la curvatura. Y el caso límite $w = - 1/3$, representa un Universo con velocidad de expansión $\dot{a}$ constante (Figura \ref{fig 1.1}).
\begin{figure}
\centering
    \includegraphics[width=0.6\textwidth]{./Figuras/ScaleFactor}
  \caption{\footnotesize{El factor de escala cosmológico $a(t)$ para modelos de Universo abierto $(k = -1)$, plano $(k = 0)$ y cerrado $(k = 1)$.}}
  \label{fig 1.1}
\end{figure}

Las ecuaciones de Friedmann se pueden expresar de una forma más general (\ref{eqn 1.28}) en términos de la densidad relativa a la densidad crítica. La densidad crítica se denota $\Omega$ y se le llama \textit{parámetro de densidad} o \textit{densidad relativa}, es decir
\begin{equation}
\Omega \equiv \frac{\rho}{\rho_{c}},\label{eqn 1.38}
\end{equation}
además de definir un parámetro de curvatura espacial
\begin{equation}
\Omega_{k} \equiv -\frac{k}{H^{2}a^{2}}.\label{eqn 1.39}
\end{equation}
Insertando estos valores en la ecuación de Friedmann (\ref{eqn 1.28}) se tiene lo siguiente
\begin{equation}
\Omega + \Omega_{k} = 1\label{eqn 1.40}
\end{equation}
donde $\Omega$ es la densidad total relativa de energía y materia. Dado que para un modelo de Universo abierto, $\Omega_{k} < 0$, un modelo plano $\Omega_{k} = 0 $ y un modelo cerrado $\Omega_{k} > 0$, se tienen los siguientes valores para $\Omega$
\begin{equation}
\Omega  \left\lbrace
\begin{array}{ll}
> 1, & \textup{para} \; k > 0, \\
= 1, & \textup{para} \; k = 0, \\
< 1, & \textup{para} \; k < 0. \\ \label{eqn 1.41}
\end{array}
\right.
\end{equation}
Así que, en principio se puede medir la cantidad de materia contenida en el Universo y determinar su geometría. En las siguientes secciones se describirán un par de modelos que utilizan estos parámetros para estudiar estas propiedades.
%---------------------------------------------------------------------------------%
\section{Modelos de Evolución Cosmológica}
El primer intento de aplicar la relatividad al Universo se debió al propio Einstein. Aunque con este primer intento se llegaba a la ``absurda'' conclusión de que el Universo estaba en expansión (o bien en contracción, que es una expresión negativa). Para conseguir un Universo estático, Einstein admitió el llamado \textit{término cosmológico} o \textit{constante cosmológica}, lo que hoy se interpretaría como una forma de energía oscura. Este término le daba al Universo una facultad expansiva que contrarrestaba la autogravitación de todo el Universo, evitando la coalescencia y consiguiendo una situación estática. Lo más novedoso de aquella deducción era que, al contrario de la gravitación newtoniana, que era generada por la masa, esta fuerza expansiva del término cosmológico era generada por el vacío, y quizá como consecuencia, constante en el tiempo.

La necesidad de crear estos modelos de evolución fue precisamente la detección de un tipo de materia ``faltante'' en el Universo. Para la década de 1930, el astrofísico Fritz Zwicky \cite{1.1.1} examinó la dinámica interna del cúmmulo de galaxias Coma Berenice. En dicha publicación, Zwicky proporciona evidencia de que la masa luminosa en el cúmulo era mucho menor que el total de masa  necesaria para mantener a estas galaxias unidas gravitacionalmente. Debía existir otro tipo de materia que permitiera que este conjunto de galaxias se mantuviese unido. En esa época ya se tenían los primeros indicios de la \textit{materia oscura}.

A pesar de numerosas contribuciones de la comunidad científica, el tema de la materia oscura no fue considerado seriamente hasta la época de 1970, cuando la astrónoma Vera Cooper Rubin \cite{1.1.2} indicó que la estabilidad gravitacional de las galaxias es por una cantidad de masa mayor a la observada. En su trabajo, calcula las curvas de rotación de distintas galaxias espirales, las cuales miden la velocidad radial de las entrellas dentro de las galaxias en función de su distancia hacia el centro de las mismas, como se observa en la siguiente ecuación
\begin{equation}
v (r)
=
\sqrt{\frac{G M (r)}{r}}.\label{eqn 1.42}
\end{equation} 
\begin{figure}
\centering
    \includegraphics[width=0.6\textwidth]{./Figuras/M33Rotation}
  \caption{\footnotesize{Curva de rotación de la galaxia M33 (Triangulum). Se observa una discrepancia entre la medición real y el cálculo usando las leyes newtonianas.}}
  \label{fig 1.2}
\end{figure}
De acuerdo a las leyes de Newton, se esperaría que dicho movimiento tuviese un comportamiento Kepleriano, es decir, que la velocidad de las estrellas fuese decayendo conforme la distancia era mayor hacia el centro. La gran sorpresa sobre estas observaciones fue que esta curva no obedecía el comportamiento Kepleriano, si no que la velocidad de las estrellas permanecía casi constante e incluso, en algunos casos, aumentaba (Figura \ref{fig 1.2}) . Si la teoría de Newton era correcta, entonces lo que hacía falta era materia para poder explicar este extraño comportamiento. Esto fue un gran impacto para la física y la astronomía, ya que esta evidencia conlleva a crear modelos que incluyan esta \textit{materia oscura} en las galaxias y, por tanto también en el Universo.

%---------------------------------------------------------------------------------%
\subsection*{Radiación del Fondo Cósmico de Microondas}
Otro fenómeno importante para el desarrollo de los modelos de evolución es la \textit{Radiación del Fondo Cósmico de Microondas} o por sus siglas en inglés \textit{Cosmic Microwave Background} (CMB). El CMB es un tipo de radiación de alrededor de 400,000 años después del comienzo del Universo. Antes de este tiempo, el Universo era tan caliente y denso que era opaco para toda la radiación. Ni siquiera los átomos simples podrían formarse sin ser instantáneamente desgarrados en sus protones y electrones constituyentes por la radiación intensa. El Universo estaba hecho de un "plasma", o gas ionizado, que es de lo que está hecha la superficie del Sol.

Esta radiación fue detectada por primera vez por Arno Penzias y Robert Wilson en 1965 y es una de las pruebas más contundentes a favor del Big Bang. En particular, la teoría del Big Bang predice ciertas características para la radiación en épocas primitivas que han sido confirmadas por el CMB:

\begin{enumerate}
\item La dispersión múltiple de fotones por un plasma caliente en el Universo temprano debería dar como resultado un espectro de cuerpo negro para los fotones una vez que han escapado en la época de reionización. Esto es exactamente lo que se observa para el CMB.
\item Los fotones del CMB se emitieron en la época de recombinación cuando el Universo tenía una temperatura de aproximadamente 3.000 Kelvin. Sin embargo, han sido desplazados cosmológicamente hacia el rojo a longitudes de onda más largas durante su viaje en un Universo en expansión, y ahora se detectan en la región de microondas del espectro electromagnético a una temperatura promedio de 2.725 Kelvin. Esto está de acuerdo con lo que predice la teoría del Big Bang. 
\end{enumerate}
\begin{figure}
\centering
  \includegraphics[width=0.5\textwidth]{./Figuras/SpectrumCMB}
  \caption{\footnotesize{Espectro de radiación del CMB medido por el satélite COBE.}}
  \label{fig 1.3}
\end{figure}
En la década de 1990, el satélite COBE midió el CMB  y ayudó a establecer varias cosas. En primer lugar, el CMB es casi completamente uniforme, con una temperatura casi constante. El que no sea constante es debido a que hubo pequeñas fluctuaciones en la temperatura, al nivel de una sola parte en 100,000. 

En las últimas dos décadas, muchos experimentos han medido las pequeñas fluctuaciones de CMB, tales como WMAP en 2007 \cite{1.1.3} . Estas pequeñas fluctuaciones están ahí debido a pequeñas variaciones en la densidad del Universo inmediatamente después del Big Bang. Cualquier región que sea ligeramente más densa tiende a atraer más materia, y se vuelve aún más densa y atrae más material. Este proceso fuera de control es lo que llevó a la formación de las primeras estrellas y galaxias. Las propiedades de las fluctuaciones se han utilizado para ayudar a determinar la edad del Universo, de qué está hecho e incluso cómo podría terminar. En el año 2013 la misión Planck \cite{1.1.4} ha proporcionado la imagen más detallada hasta ahora del Universo tal como apareció a solo 380,000 años después del Big Bang.
\begin{figure}
\centering
  \includegraphics[width=0.5\textwidth]{./Figuras/cmb1}
  \caption{\footnotesize{Comparación del CMB medido por las misiones COBE (1992), WMAP (2003) y Planck (2013).}}
  \label{fig 1.4}
\end{figure}


%---------------------------------------------------------------------------------%



\subsection{Lambda Cold Dark Matter ($\Lambda$CDM)}
Aunque la primera evidencia de materia oscura fue descubierta en la década de 1930, no fue hasta la década de 1980 que los astrónomos se convencieron de que esta es el componente responsable que mantiene unidas a las galaxias y los cúmulos de galaxias de manera gravitacional.

El modelo \textit{Lambda Cold Dark Matter} ($\Lambda$CDM) es una parametrización del modelo del Big Bang Cosmológico. Su aceptación ha sido tal que ha llegado a ser denominado  el ``modelo estándar de la cosmología'' se  fundamenta,  principalmente, sobre las siguientes bases teóricas y experimentales. 
\begin{enumerate}
\item Un marco teórico basado en la teoría general de la relatividad, que proporciona la teoría del campo gravitatorio en escalas cosmológicas.
\item El principio cosmológico. Requisito indispensable para cualquier modelo cosmológico.
\item El modelo de fluidos, que considera a las galaxias como constituyentes básicos del universo, las incluye en la teoría mediante la ecuación de fluido (ecuación \ref{eqn 1.31}).
\item La Ley de Hubble, que establece la expansión del Universo con una velocidad de recesión de las galaxias proporcional a su distancia.
\item La Radiación del Fondo Cósmico de Microondas. Los resultados del CMB ayudan a resolver paradigmas sin resolver del modelo del Big Bang cosmológico.
\item La concordancia de los distintos métodos de estimación de la edad del Universo \cite{1.1.5}. 
\item La determinación de la abundancia relativa de elementos primigenios $^{1}$H, $^{2}$D, $^{3}$He, $^{4}$He y $^{7}$Li formados en las reacciones nucleares en la época de Big Bang Nucleosíntesis (BBN)\cite{1.1.6, 1.1.7, 1.1.8}.
\item El análisis de la estructura a gran escala del Universo, mediante experimentos como el SDSS \cite{1.1.9} , que atestiguan la homogeneidad y ayudan a la determinación de los distintos parámetros del modelo estándar.

\end{enumerate}

\begin{figure}
\centering
  \includegraphics[width=0.6\textwidth]{./Figuras/sdss}
  \caption{\footnotesize{Mapa tridimensional captado por SDSS de la distribución de galaxias, con la Tierra en el centro. Cada punto indica una galaxia mientras que el color representa la edad de las estrellas en las galaxias, siendo las rojas las estrellas más viejas.}}
  \label{fig 1.5}
\end{figure}

\subsubsection*{Otras características del modelo estándar}
Además de basarse en los anteriores pilares básicos, incorpora algunas características especiales a fin de explicar la evolución y la estructura actual del Universo:
\begin{itemize}
\item Perturbaciones a la densidad. También conocidas como fluctuaciones de densidad o fluctuaciones cuánticas, son las responsables de la formación de las grandes estructuras del Universo \cite{1.2.3}.

\item La \textit{Inflación} \cite{1.2.1}, una expansión acelerada, propuesta originalmente por Alan Guth, y que explica la planitud y la homogeneidad actuales del Universo.

\item El Hot Big Bang, origen extremadamente caliente que da lugar a BBN.

\item La \textit{constante cosmológica} $\Lambda$, que Einstein introdujo en las ecuaciones de la relatividad general, originalmente para forzar un Universo estático. Hoy, al saber que el Universo está expandiéndose y de forma acelerada, se le denomina \textit{energía del vacío} o \textit{energía oscura} \cite{1.2.2}. Recordando la ecuación (\ref{eqn 1.18}) al introducir el parámetro $\Lambda$ se tiene lo siguiente:
\begin{equation}
H^{2}(t) = \left(\frac{\dot{a}}{a}\right)
= 
\frac{8 \pi G}{3} - \frac{k}{a^{2}} + \frac{\Lambda}{3}.\label{eqn 1.43}
\end{equation}
\item La \textit{materia oscura fría}, Cold Dark Matter (CDM). Un tipo de materia que debe actuar de forma exclusivamente gravitatoria, que es oscura o \textit{transparente} (no interactúa con ningún tipo de materia bariónica o radiación) y que no debe moverse a velocidades relativistas (es fría).


\end{itemize}

\begin{figure}
\centering
  \includegraphics[width=0.6\textwidth]{./Figuras/BBCosmology}
  \caption{\footnotesize{Ilustración de la línea de tiempo que detalla el origen del Universo según la teoría del Big Bang. Se observan diferentes épocas, tales como inflación, formación de estructura y expansión acelerada.}}
  \label{fig 1.6}
\end{figure}



\subsubsection*{Problemas con el modelo}
El modelo $\Lambda$CDM describe satisfactoriamente la expansión acelerada del Universo, explica la radiación del Fondo Cósmico de Microondas y otorga un marco de referencia dentro del cual es posible entender la homogeneidad e isotropía en el Universo, también describe las características del origen, naturaleza y evolución de las fluctuaciones de densidad que se creen son las responsables de la formación de las galaxias o otras estructuras cósmicas, la distribución de materia a gran escala, y los aspectos principales de la formación y evolución de objetos cosmológicos virializados. Hasta ahora $\Lambda$CDM es consistente con la abundancia de cúmulos observados en $z \sim 0$, predice un cambio relativamente pequeño en la densidad de número de cúmulo como función del corrimiento al rojo pues, dada la baja densidad de materia, escaso crecimiento de estructuras se ha visto desde $z \sim 1$. El modelo $\Lambda$CDM puede ``forzarse'' a concordar de manera aproximada con la abundancia de cúmulos en escalas pequeñas y con las fluctuaciones del CMB a grandes escalas modificando el espectro de potencias de su forma habitual. Este cambio en el modelo tiene consistencia con las observaciones, el espectro de potencias de $\Lambda$CDM puede normalizarse para así coincidir con el CMB y las observaciones de cúmulos. Pero a medida que las estimaciones de la densidad de materia oscura se hacen más y más precisas, es necesario saber cuál es su composición.

Existen, sin embargo, ciertos problemas con el modelo a escalas más pequeñas, tales como los perfiles cusp de densidades de halos galácticos, la sobrepoblación de subestructuras predicha por simulaciones de $N$-cuerpos, entre otras. Hasta hoy, la naturaleza de la materia oscura que mantiene unida a las galaxias y cúmulos de galaxias es una discusión abierta.

\subsubsection*{El problema CUSP-CORE} 
Una de las predicciones fundamentales del modelo $\Lambda$CDM es que la materia oscura debido a su naturaleza autogravitante, colapsa en halos que, en ausencia de efectos causados por materia bariónica, desarrollan un perfil de densidad que aumenta de manera abrupta. Este importante resultado surge de simulaciones de $N$-cuerpos, que serán descritas en el capítulo siguiente. Estas simulaciones mostraron que la distribución de densidad de un halo de materia oscura de cualquier masa es perfectamente descrita por el perfil de densidad Navarro-Frenk-White o $NFW$ (Navarro et al. 1996, 1997) \cite{b1}, independientemente de condiciones iniciales o de parámetros cosmológicos. Por ejemplo, la pendiente interna principal de un perfil NFW cumple que la densidad $\rho$ es proporcional al inverso de la distancia $r$ es decir $\rho \propto r^{-1}$, un resultado similar a la pendiente principal externa mostró que la densidad debía ser proporcional a $r^{-3}$. Navarro et al. (1997) llamaron a esto el ``perfil de densidad universal"  que viene dado por
\begin{equation}
\rho_{NFW}(r)= \frac{\rho_{i}}{(r/R_{s})(1 + r/R_{s})^{2}},\label{eqn 1.44}
\end{equation}
donde $\rho_{i}$ se relaciona a la densidad del Universo en la época del colapso del halo y $R_{s}$ es el radio característico del halo. Simulaciones hechas por Moore et al. (1999) \cite{Moore 1999} mostraron un perfil de densidad incluso más pronunciado, pues encontraron que los halos que ellos simularon pueden ser descritos mejor con el siguiente perfil de densidad
\begin{equation}
\rho_{M99}(r)= \frac{\rho_{i}}{(r/R_{s})^{1.5}(1 + r/R_{s})^{1.5}},\label{eqn 1.45}
\end{equation} 
es decir con una proporción interna de $r^{-1.5}$ y porporción externa de $r^{-3}$. La diferencia entre estos dos resultados indicaba que detalles como la convergencia numérica, condiciones iniciales, análisis o interpretación aún podían ser un reto al definir la pendiente interna. A medida que el poder de cómputo fue creciendo y las simulaciones tuvieron mejor resolución, el valor y comportamiento de la pendiente interna del los halos de CDM ha sido discutido de manera extendida en los últimos años.
\begin{figure}
\centering
  \includegraphics[width=0.6\textwidth]{./Figuras/NFW}
  \caption{\footnotesize{Perfiles de densidad de los halos más y menos masivos de una simulación hecha con los modelos $\Lambda$CDM y SCDM (Navarro et al.; 1997). En los paneles superiores, los radios están dados en kpc y las densidades en unidades de $10^{10} M\odot / kpc^{3}$. En el resto, las unidades son arbitrarias.}}
  \label{fig 1.7}
\end{figure}
  
Pero las mediciones hechas para las curvas de rotación y modelos de galaxias esferoidales enanas requieren una densidad más suave, casi superficial, que son consistentes con un núcleo de densidad constante en el centro (Moore, 1994)\cite{b2}. Esta discrepancia es conocida como el problema \textit{cusp-core}.  Para tener una idea de las muchas publicaciones que se han hecho al respecto Klypin et al. (2001) derivaron pendientes proporcionales a $r^{-1.5}$ en sus simulaciones. De argumentos de la densidad del espacio-fase, Taylor \& Navarro (2001) argumentaron que el perfil de densidad debe parecerse al del perfil NFW, pero con convergencia a $r^{-0.75}$ en lugar del valor de $r^{-1}$. Colín et al. (2004) investigaron halos de baja masa y encontraron que se describían mejor usando perfiles de densidad NFW. Diemand et al. (2005) encontraron que los halos de CDM tenían perfiles cusp con pendiente $r^{-1.2}$. 
Muchos estudios suponen que el cusp central consiste de una región donde la densidad de masa se comporta como una ley de potencias con pendiente constante aunque se ha sugerido que este no tendría que ser el caso (Navarro et al. 2004; Hayashi et al. 2004) \cite{Navarro Hayashi} dado que no encuentran evidencia de una pendiente que se comporte como una ley de potencias, si no que esta pendiente sigue una línea que a medida que el radio se hacía más pequeño, ésta no converge a un solo valor asintótico.
\begin{figure}
\centering
  \includegraphics[width=0.6\textwidth]{./Figuras/CUSP_CORE}
  \caption{\footnotesize{Perfil de densidad parametrizado como $\rho(r) \sim r^{-\alpha}$. Las observaciones muestran que $\alpha \sim 0$ (núcleo de densidad constante). Las simulaciones predicen que $1 \leq \alpha \leq 1.5$ (perfil cusp o pico).}}
  \label{fig 1.8}
\end{figure}


\subsubsection*{Satélites Faltantes}
Otra serie de observaciones parece estar en contradicción con $\Lambda$CDM. Utilizando simulaciones de alta resolución, Moore et al. (1999) \cite{Moore 1999} y Klypin et al. (2001) \cite{1.2.4} hicieron notar que el número de subhalos masivos predichos por estas simulaciones excede el número observado de satélites luminosos de la Vía Láctea en al menos un orden de magnitud. Esto se le conoce como el problema de los \textit{satélites faltantes}. Este tipo de resultado sigue siendo una discrepancia considerable entre el número de satélites observados en la Vía Láctea y el número predicho por simulaciones de $\Lambda$CDM.

Las simulaciones predicen que una galaxia, como la Vía Láctea debería tener alrededor de 10 veces más galaxias satélites que las que se observan. Lo mismo sucede para galaxias de mayor tamaño. Así que, ¿Cuáles son las posibles soluciones? Lo primero sería que la física utilizada en simulaciones esté fallando, es decir, no toman en cuenta física suficiente. Sin embargo, estas simulaciones han mostrado resultados bastante satisfactorios al explicar el resto del Universo \cite{1.2.5}, aunque es posible que la física utilizada necesite más detalle. Además, muchas de estas simulaciones solo utilizan modelos de materia oscura y no toman en cuenta materia bariónica, pero incluso al añadir estos componentes a las simulaciones, el problema persiste.

Otra alternativa es que el poder de observación sea muy limitado, pero las sensibilidad de los instrumentos está mejorando década con década, se han encontrado más galaxias satélites \cite{1.2.6}, aún así, el orden de satélites observados es mucho menor al obtenido en simulaciones.

Una tercera posibilidad es la existencia de ``galaxias oscuras''. Todas las galaxias tienen un halo de materia oscura. En simulaciones, estos halos representan a su galaxia y muchas de las galaxias satélites son sub-halos de materia oscura. Cada halo tiene muchos sub-halos. 

Estas discrepancias dentro del modelo estándar pueden ser evidencia de la importancia de procesos físicos en la materia bariónica. Pero también pueden ser indicativos de un nuevo tipo de materia oscura, con propiedades diferentes a las propuestas por $\Lambda$CDM y con la posibilidad de resolver estas dificultades mencionadas.





\subsection{Scalar Field Dark Matter (SFDM)}
Con los problemas que presenta el modelo $\Lambda$CDM parece necesario introducir alternativas al paradigma de la formación de estructura. Estas son algunas razones pors las que deben buscarse propuestas diferentes que puedan explicar las formación de estructura a un nivel cosmológico, la cantidad observada de galaxias enanas y los perfiles de densidad de materia oscura en los núcleos galácticos.
Una propuesta es la de un campo escalar como materia oscura en el Universo. Este modelo supone que la materia oscura es un campo escalar real o complejo $\Phi$ mínimamente acoplado a la gravedad, dotado de un potencial escalar $V(\Phi)$ y que a cierta temperatura la interacción  del campo es puramente gravitacional junto con el resto de la materia. Este campo escalar puede agregarse al lagrangiano de las partículas del modelo estándar o al de la relatividad general, suponiendo que la constante de acoplamiento con el resto de la materia sea muy pequeña.

Muchos autores han propuesto alternativas de interés en las cuales tratan de resolver las dificultades que $\Lambda$CDM no ha podido resolver hasta ahora. En el modelo de Campo Escalar (Guzmán, F. \& Matos, T. (2000)) \cite{Siddhartha Matos}, se propone que los halos galácticos se forman de condensados de Bose-Einstein de un campo escalar (SF) cuyo bosón tiene una masa ultra ligera del orden de $m \sim 10^{-22}$eV. De este valor se sigue qe la temperatura crítica de condensación $T_{c} \sim 1/m^{5/3} \sim $ TeV, es muy alta, por lo tanto, se forman semillas de Condensados de Bose-Einstein (BEC) en épocas tempranas en el Universo. Además, la longitud de Compton $\lambda_{c} = 2\pi \hbar / m$ asociada a este bosón es del orden de kpc que corresponde al tamaño de los halos de materia oscura de las galaxias en el Universo. Por otra parte, las grandes estructuras del Universo se forman al igual que en el modelo $\Lambda$CDM, por lo que todas las predicciones correctas del modelo estándar se reproducen de buena manera por el modelo SFDM. En otras palabras, en el modelo SFDM los halos de galaxias no son formados de manera jerárquica, son formados en  la misma época y del mismo modo en que el Universo alcanza la temperatura crítica de condensación del SF. De esto se sigue que todas las galaxias deben ser similares porque son formadas de la misma forma y en el mismo momento.  


\subsubsection*{Descripción Física del Modelo}
Para estudiar la dinámica de SFDM en el Universo e utiliza la métrica de Friedmann-Lemaître-Robertson-Walker (FLRW) con factor de escala $a(t)$. El background del Universo está compuesto de un campo escalar SFDM ($\Phi_{0}(t)$) dotado de un potencial escalar $V \equiv V(\Phi_{0})$, radiación ($z$), neutrinos ($\nu$), bariones ($b$) y una constante cosmológica ($\Lambda$) (Magaña \& Matos, (2012)). Recordando las ecuaciones del background, del tensor energía-momento \textbf{T} para un campo escalar, la densidad de energía escalar $T_{0}^{0}$ y la presión escalar $T_{j}^{i}$ están dadas por
\begin{equation}
T_{0}^{0}=-\rho_{\Phi_{0}}=-\left(\frac{1}{2}\dot{\Phi}_{0}^{2} + V \right),\label{eqn 1.46}
\end{equation}
y
\begin{equation}
T_{j}^{i}=P_{\Phi_{0}}=\left(\frac{1}{2} \dot{\Phi}_{0}^{2}-V \right)\delta_{j}^{i},\label{eqn 1.47}
\end{equation}
donde el punto se entiende como la derivada respecto al tiempo cosmológico y $\delta_{j}^{i}$ es la delta de Kronecker. Así, la Ecuación de Estado para el campo escalar es $P_{\Phi_{0}}=\omega_{\Phi_{0}}\rho_{\Phi_{0}}$ con
\begin{equation}
\omega_{\Phi_{0}} = \frac{\frac{1}{2}\dot{\Phi}_{0}^{2}-V}{\frac{1}{2}\dot{\Phi}_{0}^{2}+V}.\label{eqn 1.48}
\end{equation}
Para resolver las ecuaciones de Friedmann con métodos analíticos con la aproximación $m >> H$ ellos utilizaron una transformación que compararon después con resultados analíticos. Aquí el campo escalar y las variables del background dependen solamente del tiempo, i.e. $\Phi=\Phi_{0}(t)$.

Calcularon el crecimiento de las sobredensidades de SFDM $\delta\rho_{\Phi}$ en el régimen lineal, el contraste de densidad $\delta \equiv \delta\rho_{\Phi}/\rho\Phi_{0}$ es mucho más pequeño qe la unidad. Se piensa que el Universo era casi uniforme después de la inflación, con un contraste de densidad muy pequeño. A medida que el Universo se expande, las pequeñas sobredensiades crecieron hasta el punto que empezaron a colapsar, llevando a la formación de estructura del Universo. Así, solo pequeñas desviaciones del modelo FRWL se consideran, para que puedan ser tratada con la teoría lineal de perturbaciones. Dentro de la teoría de perturbaciones escalares, la evolución del contraste de densidad puede escribirse como 
\begin{equation}
\dot{\delta} + 3H\left(<\frac{\delta P_{\Phi}}{\delta \rho_{\Phi}}> 
- <w_{\Phi_{0}}>\right)\delta
=
3\dot{\Phi}_{k}<F_{\Phi}> - <G_{\Phi}>\label{eqn 1.49}
\end{equation}
donde
\begin{equation}
  \begin{array}{ll}
    F_{\Phi} = 1 + w_{\Phi_{0}} \\
    G_{\Phi} = \frac{2 k^{2}}{a^{2}k^{2}}\frac{\dot{\phi}_{k}+ H\phi_{k}}{\rho_{\phi_{0}}}\label{eqn 1.50}
  \end{array}
\end{equation}

\subsection{Otros Candidatos a Materia Oscura}
Con el paso de los años, las observaciones del Universo son cada vez más precisas y con éstas, la presencia de la materia oscura es más evidente \cite{1.3.2.1}. Se sabe que se agrupa formando halos galácticos y que es la responsable de la formación a gran escala del Cosmos. Descifrar la naturaleza de la materia oscura es una tarea para físicos de partículas y cosmólogos por igual, ya que las partículas elementales son los principales candidatos a materia oscura en el Universo. 

En las secciones anteriores se han descrito de dos modelos de materia oscura, el modelo estándar $\Lambda$CDM y el modelo de materia oscura escalar SFDM. Estos no son los únicos modelos que se han desarrollado. Existe una gran variedad de candidatos que no por ser menos conocidos, son menos interesantes. Se describirán, algunos de ellos, brevemente:

\begin{itemize}
\item Materia oscura auto-interactuante (SIDM): Las partículas de materia oscura fría tienen auto-interacción con poca disipación o aniquilación \cite{1.3.1}.
\item Materia oscura tibia (WDM): Las partículas se mueven a velocidades altas pero no relativistas, los halos de materia oscura se forman en épocas similares a CDM pero se forma menos subestructura en simulaciones de $N$-cuerpos \cite{1.3.2}.
\item Materia oscura repulsiva (RDM): la materia oscura se comporta como un condensado de bosones masivos que interactúan por un potencial repulsivo entre partículas además de la gravedad, lo cual conduce a un comportamiento de superfluidez \cite{1.3.3}.
\item Materia oscura difusa (FDM): Las partículas están compuestas de partículas ultra-ligeras, similares a materia oscura escalar \cite{1.3.4}.
\item Materia oscura auto-aniquilante (SADM): La aniquilación de materia oscura permite suavizar los perfiles cusp de halos galácticos \cite{1.3.5}.
\item Materia oscura que decae (DDM):  La formación de estructura en $z \sim 2$ mejora para el modelo de DDM \cite{1.3.6}.
\end{itemize}

Por mencionar algunos más.

\subsubsection*{WIMP}
Los \textit{Weak Interactive Massive Particles} (WIMP) son cadidatos a materia oscura fría. Estas partículas solo interactúan de manera gravitacional con la materia bariónica y están predichas por teorías de unificación. En la mayoría de los modelos de partículas, la partícula supersimétrica más conocida es el \textit{neutralino}, el cual posee  características que coinciden con las de un WIMP: Es estable, no tiene carga eléctrica, sus interacciones son solo de tipo débil, su masa está en un rango adecuado para que se produzca con abundancia necesaria y da lugar a materia oscura fría \cite{1.3.7}.

\subsubsection*{Modificaciones a la teoría newtoniana}

En 1983, Mordehai Milgrom propone que la teoría newtoniana debe modificarse para aceleraciones pequeñas ($a_{0} \approx 1.2 \pm 0.1 \times 10^{-10}$m/s$^{2}$), y que la física de Newton es sólo una buena aproximación para aceleraciones mayores a $a_{0}$ \cite{1.3.8}. Esta modificación conduce a que la segunda ley de Newton debe replantearse para pequeñas aceleraciones de la siguiente manera 
\begin{equation}
\vec{F} = m \mu (\frac{a}{a_{0}})\vec{a}.\label{eqn 1.51}
\end{equation}
Esta modificación permite explicar muchos datos observados sin recurrir a postular materia oscura no--bariónica. Su rango de aplicabilidad y éxito es muy amplio: desde galaxias enanas esferoidales hasta supercúmulos galácticos.

\subsubsection*{Dimensiones extra}

Entre las ideas propuestas por la comunidad científica, la de dimensiones extra es algo intrigante. Se postula que nuestro Universo está inmerso en un sub--espacio de (3+1) dimensiones, el cuál a su vez está inmerso en un espacio de mayor dimensión. La idea de postular esto es que la materia oscura no es visible, pero su presencia en las galaxias se detecta a través de efectos gravitacionales en estrellas visibles.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Simulaciones de $N$-cuerpos}\label{cap.nudo}
En el capítulo anterior, se llega a la conclusión de que la naturaleza de la materia oscura es incierta. El crear teorías que expliquen esa naturaleza y además concuerden con las observaciones actuales del Universo no es tarea fácil. Al no conocer su composición, una de las soluciones que se proponen es el de emplear simulaciones que involucren toda la física desarrollada en la teoría y que a su vez permitan tener resultados comparables con observaciones. Las simulaciones de $N$-cuerpos son uno de los enfoques más amplios para comprender la formación a gran escala del Universo. En años recientes, el poder computacional ha permitido crear simulaciones de alta resolución y que muestran la evolución del Universo desde épocas extremadamente tempranas ($z \sim 1100$). Aproximadamente 13 Gyr, dependiendo del modelo que se esté simulando.

La evolución de estructura se aproxima con aglomeramiento gravitacional  no lineal a partir de condiciones iniciales específicas de partículas de materia oscura y puede refinarse introduciendo efectos de dinámica de gases, procesos químicos, transferencia radiativa y otros procesos astrofísicos. La fiabilidad de una simulación se mide por su resolución en masa, longitud y tiempo. La resolución de masa es especificada por la masa de la partícula más pequeña considerada, siendo la escala por debajo de la cual las fluctuaciones son despreciables. La resolución en longitud está limitada por una escala de ``suavizado'' (softening), introducida para evitar infinitos en la fuerza gravitacional cuando las partículas colisionan.

La formación de estructura en el Universo es originada por pequeñas perturbaciones en la densidad de materia, o fluctuaciones cuánticas que se expanden a escalas cosmológicas en la época de inflación. Al simular materia oscura se debe enfocar en su colapso gravitacional, al haber más colapso, las perturbaciones crecen. La teoría de perturbaciones lineal es una excelente primera aproximación a la evolución temprana del Universo. El resultado de este conjunto de consideraciones es una red de halos que se forman a lo largo de paredes y filamentos, creando un entramado cósmico. Este entramado es consistente con mediciones de aglomeraciones de galaxias en un amplio intervalo de escalas.

Existe una gran variedad de códigos que involucran teoría de simulaciones de $N$-cuerpos, incluyendo dinámica de gases, conocida como Smoothed Particle Hydrodynamics (SPH) y que han sido utilizados en numeradas ocasiones para obtener resultados consistentes con observaciones. Por mencionar algunos: ART \cite{2.1.1}, ENZO \cite{2.1.2}, RAMSES \cite{2.1.3}, GADGET \cite{b4} etc.

Este capítulo está dedicado a describir las bases teóricas para simulaciones de $N$-cuerpos e Hidrodinámica de Partículas Suavizadas (SPH) que utiliza el código GADGET.

\section{Modelos de Fluidos Sin Colisión Autogravitantes}
Para este tipo de interacciones se hace uso de la ecuación de Boltzmann no colisional acoplada en conjunto con la ecuación de Poisson que describe el comportamiento y evolución de un gas sujeto a fuerzas externas y que tiene la siguiente forma 
\begin{equation}
\frac{\partial f}{\partial t} + \vec{v}\cdot\vec\nabla_{r} + \frac{\vec{F}}{m}\cdot\vec\nabla_{v}=0,\label{eqn2.1}
\end{equation}
donde $f= f(\vec{r}, \vec{p}, t)$ es una función de la densidad de probabilidad, $\vec{v}$ es la velocidad, $\vec{r}$ es la posición, $\vec{F}$ es la fuerza y $m$ la masa que describen completamente al fluido \cite{b3}.

En el caso de que esta fuerza $\vec{F}$ se derive de un potencial, tal que 
\begin{equation}
\vec{F} = -m\nabla\Phi,\label{eqn2.2}
\end{equation}
donde $m$ es la masa de la partícula del sistema. Sustituyendo (\ref{eqn2.2}) en (\ref{eqn2.1}) se encuentra
\begin{equation}
\frac{\partial f}{\partial t} + \vec{v}\cdot\vec\nabla_{r} - \vec\nabla\Phi\cdot\vec\nabla_{v}=0\label{eqn2.3}
\end{equation} 
Este potencial $\Phi$ debe satisfacer la ecuación de Poisson
\begin{equation}
\nabla^{2} \Phi (\vec{r},t) = 4\pi \int_{S} f(\vec{r},\vec{v},t)d^{3}v\label{eqn2.4}
\end{equation}
donde $S$ es todo el espacio y $f$ se define mediante la siguiente expresión
\begin{equation}
f = f(\vec{r},\vec{v},t)d^{3}v d^{3}r\label{eqn 2.5}
\end{equation}
que viene dada por la masa total de las partículas que se encuentran en un cubo de volumen $d^{3}r$ centrado en $\vec{r}$ y velocidad ubicada en un cubo de volumen $d^{3}v$ centrado en $\vec{v}$. Al integrar en el espacio, lo que se obtiene es la densidad de masa que puede depender del tiempo $\rho(t)$, con esto la ecuación de Poisson presentada en la Ec. (\ref{eqn2.4}) se reduce a la conocida.

Las expresiones (\ref{eqn2.1}) y (\ref{eqn2.4}) conforman la totalidad de las ecuaciones necesarias para describir la dinámica de un gas sin colisiones autogravitante dentro de un Universo meramente Newtoniano. Sin embargo, dada la complejidad para resolver las ecuaciones acopladas se utiliza un método conocido como el de $N$-cuerpos, gracias a esto, la función $f$ definida en la ecuación (\ref{eqn 2.5}) pasa de ser continua a discreta, dada por funciones deltas de Dirac (Springel et al., 2001) \cite{b4}, esto permite realizar cálculos numéricos de forma más eficiente.

Para este propósito se introduce un parámetro $\epsilon$ conocido como “suavizamiento gravitacional” que permite evitar una divergencia repentina en el cálculo de la fuerza. La idea es la siguiente: En un caso estrictamente Newtoniano en donde se tienen dos partículas $i$ y $j$, la fuerza entre ellas debe ser simplemente

\begin{equation}
   \vec{F_{ij}}
  = G\frac{m_{i}m_{j}}{||\vec{r_{i}}-\vec{r_{j}}||},\label{eqn2.6}
\end{equation}
dado que si $\vec{r_{i}}$ se acerca mucho a $\vec{r_{j}}$ se tendría una divergencia, pues la fuerza aumentaría indefinidamente si la distancia entre las partículas se aproxima al cero, lo que provocaría una aceleración muy alta. Esto se soluciona si se agrega un parámetro $\epsilon^{2}$ de manera que 

\begin{equation}
 \vec{F_{ij}}
  = G\frac{m_{i}m_{j}}{||\epsilon^{2} + \vec{r_{i}}-\vec{r_{j}}||},\label{eqn2.7}
\end{equation} 
donde $\epsilon$ es el parámetro de suavización o “softening length” (Bodenheimer et al., 2007) \cite{b5}. Físicamente, se puede interpretar a este parámetro $\epsilon$ como la distancia entre los centros de dos partículas que están “unidas".

En el caso descrito al comienzo de la sección, el potencial puede escribirse de la siguiente manera

\begin{equation}
  \Phi(\vec{r},t)
  = -G
  \int_{S}\int_{S}
  \frac{f(\vec{r}, \vec{v}, t)d^{3}v'd^{3}r'}{||\vec{r}-\vec{r'}||},\label{eqn2.8}
\end{equation}
e introduciendo el parámetro $\epsilon$ se obtiene

\begin{equation}
 \Phi(\vec{r},t)
  = -G
  \int_{S}\int_{S}
  \frac{f(\vec{r}, \vec{v}, t)d^{3}v'd^{3}r'}{||\epsilon^{2} + \vec{r}-\vec{r'}||}.\label{eqn2.9}
\end{equation}

Estos resultados son válidos para el caso de un Universo Newtoniano.

Al considerar el modelo de Friedman--Lemaître--Robertson--Walker, es decir, el de un Universo homogéneo e isótropo en expansión, la dinámica de las partículas se describe mejor con el siguiente Hamiltoniano

\begin{equation}
  H 
  = \sum_{i=1}^{N} \frac{\vec{p_{i}}^{2}}{2 m_{i} a^{2}(t)} 
  +
  \frac{1}{2} \sum_{i\not=1,i\not=j}^{N}\sum_{j=1,j\not=i}^{N}
  \frac{m_{i}m_{j}\Phi(\vec{x_{i}}-\vec{x_{j}})}{a(t)},\label{eqn2.10}
\end{equation}
donde $\vec{p_{k}}$ y $\vec{x_{k}}$ son los vectores de momento y posición en el sistema de coordenadas comóviles, $a$ es el factor de escala de la métrica FLRW. El caso Newtoniano se recupera al tomar $a = 1$. El momento canónico viene dado por $\vec{p_{k}} = a^{2}(t)m_{k}\vec{x_{k}}$.

Se suponen además condiciones periódicas a la frontera para una caja de volumen $L^{3}$. Así el potencial de interacción $\Phi(\vec{x})$ será solución de la ecuación

\begin{equation}
 \nabla^{2}\Phi(\vec{x})
 =
 4\pi G
 \left[
 -\frac{1}{L^{3}}
 +
 \sum_{\vec{n}} \tilde{\delta}(\vec{x}-\vec{n}L)
 \right],\label{eqn2.11}
\end{equation}
aquí $\vec{n}$ simboliza un vector de números naturales. Esta solución corresponde a un “potencial peculiar”
\begin{equation}
 \Phi
 =
 \sum_{i=1}^{N} m_{i} \phi(\vec{x}-\vec{x_{i}}),\label{eqn2.12}
\end{equation}
cuya dinámica la gobierna la ecuación

\begin{equation}
  \nabla^{2}\Phi(\vec{x})
  =
  4 \pi G
  [\rho(\vec{x}-\bar{\rho})]\label{eqn2.13}
\end{equation}

la Ec. (\ref{eqn2.13}) es la ecuación de Poisson con un campo de fluctuaciones de densidad $\rho(\vec{x})$ y densidad media $\bar{\rho}$.
El softening gravitacional es normalizado en forma de kernel con factor de escala comóvil $\epsilon$, para esto se aplica el kernel de Spline (Monaghan \& Lattanzio, 1985) \cite{b8.1} usado en SPH y se toma $\tilde{\delta} = W(\vec{x}-\vec{n}L,2.8\epsilon)$ (véase sección 2.2 Hidrodinámica de Partículas Suavizadas), la Ec. (\ref{eqn2.11}) se convierte en

\begin{equation}
 \nabla^{2}\Phi(\vec{x})
 =
 4\pi G
 \left[
 -\frac{1}{L^{3}}
 +
 \sum_{\vec{n}}W(\vec{x}-\vec{n}L,2.8\epsilon)
 \right].
\end{equation}\label{eqn2.14}
La dinámica descrita en esta sección es la que se utiliza para describir a las partículas de materia oscura fría (CDM). Se observa que se calcula solo la fuerza entre partículas de materia oscura. Si se utilizara un método tradicional de cálculo,  requeriría $N(N-1)$ fuerzas para $N$ partículas. Si $N$ es grande, la fuerza será de un orden de $\mathcal{O}(N^{2})$. La ventaja de el método descrito aquí es que reduce ese orden a un cálculo de $N \ln N$. 

Esto es debido a que se considera un cubo mínimo que reúne a todas las partículas. Al calcular la expansión multipolar del potencial de las partículas, cosiderando el suavizamiento y el centro de masas, se ubica una partícula y se hace la pregunta : ¿Es la distancai del centro de masa del conjunto agrupado mayor que el tamaño del cubo inicial dividido por algún parámetro a escoger?

Es decir, se pregunta si se cumple la relación 
\begin{equation}
r > \frac{l}{\theta}, \label{eqn 2.15}
\end{equation}
donde $r$ es la distancia de la partícula al centro de masa del agrupamiento, $l$ es el largo del cubo inicial y $\theta$ es un parámetro de precisión. Si la expresión (\ref{eqn 2.15}) resulta ser cierta para todas las partículas de la simulación, ésta sigue su evolución, si una o más de ellas no satisface esa condición, el cubo inicial se divide en un cubo pequeño de lado $l/2$ y se repite el proceso. Se calculan las expansiones multipolares y los centros de masa para cada cubo y la pregunta se vuelve a repetir para cada proceso. Lo anterior es lo que se conoce como un \textit{Tree algorithm}, algoritmo tipo árbol o algoritmo Barnes--Hut \cite{b8.2}.
 
\begin{figure}
\centering
  \includegraphics[width=0.6\textwidth]{./Figuras/BHAlgorithm}
  \caption{\footnotesize{Una simulación de $100$-cuerpos utilizando el algoritmo Barnes--Hut visualmente como cajas azules.}}
  \label{fig 2.1}
\end{figure}

Las simulaciones de $N$--cuerpos requieren de gran poder computacional, pues cada cálculo de fuerza se efectúa para cada una de las partículas dentro de la simulación. Con el paso del tiempo han surgido nuevos métodos para calcular estas fuerzas. 

Ejemplo de esto es el \textit{Particle Mesh algorithm}. El principio básico es que un sistema de partículas se convierte en una rejilla (o ``malla'') de valores de densidad. El potencial se resuelve luego para esta cuadrícula de densidad, y las fuerzas se aplican a cada partícula en función de en qué celda se encuentra y en qué parte de la celda se encuentra. Una vez que se encuentra la distribución de densidad, la energía potencial de cada punto en la malla se puede determinar a partir de la forma diferencial de la ley de Gauss, que después da lugar a una ecuación de Poisson que se resuelve fácilmente después de aplicar transformadas de Fourier (Klypin \& Shadarin 1983; White, Frenk \& Davis 1983) \cite{b5.1, b5.2}.




\section{Hidrodinámica de Partículas Suavizadas (SPH)}

El método de Hidrodinámica de Partículas Suavizadas, por sus siglas en inglés, Smoothed Particle Hydrodynamics (SPH) utiliza un conjunto de partículas discretas para describir el estado de un fluido con cantidades continuas asociadas a la dinámica de fluidos definidas por un método de kernel de interpolación (Gingold \& Monaghan, 1977; Lucy, 1977; Monaghan 1997)\cite{b6,b7}. Las partículas se mueven como elementos de un fluido que representa al gas en un sentido Lagrangiano. Respecto al medio intergaláctico, se trata como fluido perfecto y está regido por las ecuaciones de Euler de hidrodinámica 
\begin{equation}
 \frac{\partial\rho}{\partial t}
 +
 \vec{\nabla}\cdot(\rho\vec{v})
 = 0,\label{eqn2.15}
\end{equation}

\begin{equation}
 \frac{\partial\vec{v}}{\partial t}
 +
 (\vec{v}\cdot\vec{\nabla})\vec{v}
 =
 -\frac{1}{\rho} \vec{\nabla}\cdot\vec{P} - \vec{\nabla}\Phi,\label{eqn2.16}
\end{equation}

\begin{equation}
 \nabla^{2}\Phi = 4 \pi G \rho.\label{eqn2.17}
\end{equation}
Estas ecuaciones ofrecen una visión global del fluido. En la representación de Lagrange, se elige un punto del campo vectorial obtenido por el esquema de Euler en algún tiempo $t = t_{0}$ y se analiza su evolución temporal, lo que permite estudiar la dinámica de las partículas de manera individual que conforman al fluido. Expresando la derivada total como
\begin{equation}
 \frac{d}{dt}
 =
 \frac{\partial }{\partial t} 
 +
 \vec{v}\cdot\vec{\nabla},\label{eqn2.18}
\end{equation}
entonces la Ec. (\ref{eqn2.15}) será
\begin{equation}
 \frac{d \rho}{d t}
 =
 - \rho \vec{\nabla}\cdot\vec{v},\label{eqn2.19}
\end{equation}
y la Ec. (\ref{eqn2.16})
\begin{equation}
 \frac{d \vec{v}}{d t} 
 =
 -\frac{1}{\rho}\vec{\nabla}\cdot\vec{P} - \vec{\nabla}\Phi.\label{eqn2.20}
\end{equation}

El modelo de SPH es el siguiente (Monaghan, 1992; Price, D., 2004) \cite{b8, b9} se comienza definiendo la interpolación integral de una función $A(r)$ como
\begin{equation}
 A_{I}(\vec{r})
 =
 \int_{S} 
 A(\vec{r'})W(\vec{r}- \vec{r'})d^{3}r'\label{eqn2.21}
\end{equation} 
W es el núcleo o kernel de interpolación y debe satisfacer
\begin{equation}
 \int_{S}W(\vec{r}- \vec{r'},h)d^{3}r' = 1\label{eqn2.22}
\end{equation}
\begin{equation}
\lim_{h \to 0} W(\vec{r}-\vec{r'},h) = \delta(\vec{r}-\vec{r'}).\label{eqn2.23}
\end{equation}
En el caso de partículas expresadas como deltas de Dirac, la densidad en todo el espacio se define como 
\begin{equation}
 \rho(\vec{r})
 =
 \sum_{j=1}^{N} m_{j}\delta(\vec{r}-\vec{r_{j}})\label{eqn2.24}
\end{equation}
para el modelo de SPH, se suaviza el campo de densidad de la siguiente manera
\begin{equation}
\rho(\vec{r})
=
\sum_{j=1}^{N} m_{j} W(\vec{r}-\vec{r'},h).\label{eqn2.25}
\end{equation}
Donde $h$ es un parámetro con dimensiones de longitud.
En este ambiente, las smoothing lengths adaptivas se definen de tal manera que el volumen del kernel contenga una masa constante para la densidad estimada
\begin{equation}
\frac{4 \pi }{3}h_{i}^{3}\rho_{i}
= N_{SPH}\bar{m},\label{eqn2.26}
\end{equation} 
donde $N_{SPH}$ es el número de vecinos de smoothing y $\bar{m}$ es la masa promedio de las partículas. Los cálculos originales de Gingold \& Monaghan (1977) \cite{b9.1} utilizan un término Gaussiano unidimensional
\begin{equation}
  W(x,h)
  =
  \frac{1}{h \pi^{\frac{1}{2}}} e^{-(x^{2}/h^{2})}.\label{eqn2.27}
\end{equation}
En general, el kernel basado en funciones de Spline se obtuvo de los cálculos hechos por Monaghan \& Lattanzio (1985) \cite{b8.1} y tiene la siguiente forma
\begin{equation}
W(\vec{r},h) = \frac{\sigma}{h^{\nu}} \left\lbrace
\begin{array}{ll}
1 - \frac{3}{2}\left(\frac{r}{h}\right)^{2} + \frac{3}{4}\left(\frac{r}{h}\right)^{3} & \textup{si } 0 \leq \frac{r}{h} \leq 1 \\
\frac{1}{4}\left(2-\frac{r}{h}\right)^{2} & \textup{si } 1 \leq \frac{r}{h} \leq 2 \\
0 & \textup{otra forma }
\end{array} 
\right., \label{eqn2.28}
\end{equation}
donde $\nu$ es el número de dimensiones y $\sigma$ es una constante de normalización, con valores $\frac{2}{3}$, $\frac{10}{7 \pi}$, $\frac{1}{\pi}$ en una, dos y tres dimensiones respectivamente. Este kernel es de soporte compacto, su segunda derivada es continua y el término dominante del error en la integral de interpolación es $\mathcal{O}(h^{2})$. Que sea de soporte compacto significa que las interacciones son exactamente cero para $r>2h$ y la continuidad de la segunda derivada permite que el kernel no sea sensible ante errores al aproximar la integral por medio de la suma.
El resultado es el de un suavizamiento de la densidad, lo que permite, por ejemplo, en el caso de un núcleo gaussiano como el anterior, obtener una densidad continua en todo el espacio. Al tener expresada la densidad, el cálculo numérico de la interpolación integral de la Ec. (\ref{eqn2.21}) se hace utilizando la siguiente aproximación 
\begin{equation}
 A_{I}(\vec{r})
 =
 \sum_{j} m_{j} \frac{A_{j}}{\rho_{j}} W(\vec{r}- \vec{r_{j}},h)\label{eqn2.29}
\end{equation}
donde $A_{j}=A(\vec{r_{j}})$ y $\rho_{j}=\rho(\vec{r_{j}})$. El punto esencial de este método es que puede construir un interpolador diferenciable de una función a partir de sus valores (en este caso, las partículas) usando un kernel diferenciable. 

La ecuación de movimiento para el fluido discretizado (Springel \& Hernquist, 2002) es
\begin{equation}
 \frac{d \vec{v_{i}}}{d t}
 =
 -\sum_{j=1}^{N} m_{j}
 \left[f_{i} \frac{P_{i}}{\rho_{i}^{2}}\vec{\nabla_{i}}W_{ij}(h_{i})
 +
 f_{j} \frac{P_{j}}{\rho_{j}^{2}}\vec{\nabla_{i}}W_{ij}(h_{j})\right]\label{eqn2.30}
\end{equation}
los coeficientes $f_{i}$ se definen por:
\begin{equation}
  f_{i}
  =
  \left(
  1 + \frac{h_{i}}{3\rho_{i}} \frac{\partial \rho_{i}}{\partial h_{i}}
  \right)\label{eqn2.31}
\end{equation}
y $W_{ij}(h) = W(|\vec{r_{i}}-\vec{r_{j}}|,h)$.
\\\\

Si no hay fuentes externas de calor, estas ecuaciones describen completamente la dinámica de un fluido en SPH con procesos reversibles.Definiendo una función de la entropía $A\equiv P / \rho^{\gamma}$, esta permanece constante para cada partícula. Se necesita además una viscosidad artificial para evitar discontinuidad en el flujo de gases ideales 
\begin{equation}
  \frac{d \vec{v_{i}}}{d t}|_{visc} 
  =
  -\sum_{j=1}^{N} m_{j} \Pi_{ij} \vec{\nabla_{i}}\overline{W_{ij}}\label{eqn2.32}
\end{equation}
donde $\Pi_{ij}$ es diferente de cero solo cuando las partículas se acercan unas a otras en el espacio físico. La entropía de esta viscosidad se crea a una razón
\begin{equation}
 \frac{d A_{i}}{d t} 
 =
 \frac{1}{2}
 \frac{\gamma - 1}{\rho_{i}^{\gamma -1}}
 \sum_{j=1}^{N} m_{j} \Pi_{ij} \vec{v_{ij}}\cdot \vec{\nabla_{i}}\overline{W_{ij}}\label{eqn2.33}
\end{equation}
que transforma energía cinética del movimiento del gas de manera irreversible en calor. $\overline{W_{ij}}$ es la media aritmética de los dos kernel $W_{ij}(h_{i})$ y $W_{ij}(h_{j})$. La forma artificial de la viscosidad se obtiene del cálculo de Monaghan \& Lattanzio (1985) \cite{b8.1}
\begin{equation}
\Pi_{ij} = \left\lbrace
\begin{array}{ll}
(-\alpha c_{ij} \mu_{ij} + \beta_{ij}^{2})/ \rho_{ij} & \textup{si } \vec{v_{ij}}\cdot \vec{r_{ij}}<0 \\
0 & \textup{otra forma }\label{eqn2.34}
\end{array}
\right.
\end{equation}
con
\begin{equation}
 \mu_{ij}
 =
 \frac{h_{ij} \vec{v_{ij}} \cdot \vec{r_{ij}}}{|\vec{r_{ij}}|^{2}}\label{eqn2.35}
\end{equation}
y $c_{ij}$ es la velocidad media del sonido. Esta visosidad tiene 3 ventajas: 1.- Es invariante ante transformaciones de Galileo, 2.- Desaparece para rotación de cuerpo rígido y 3.- Se conserva el momento angular. Se han hecho muchos cálculos y pruebas que confirman que, con esta viscosidad, los frentes de choque se esparcen alrededor de $~ 3h$. Los valores de $\alpha$ y $\beta$ no son críticos y rondan $\alpha\approx 1$ y $\beta \approx 2\alpha$.
\subsection{Dinámica de Gases}
La ecuación para el cambio en la razón de la energía térmica por unidad de masa 
\begin{equation}
\frac{d u}{d t} 
+ 
\frac{P}{\rho} \vec{\nabla} \cdot \vec{v}=0.\label{eqn2.36}
\end{equation} 
donde $u$ es la energía por unidad de masa y del lado derecho de la Ec.(\ref{eqn2.36}) se puede agregar un término correspondiente a una fuente. LA energía térmica para una partícula $i$
\begin{equation}
\frac{d u_{i}}{d t}
=
\left(\frac{P_{i}}{\rho_{i}^{2}}\right)
\sum_{j} m_{j} \vec{v_{ij}} \cdot \vec{\nabla_{i}} W_{ij}.\label{eqn2.37}
\end{equation}
 Esto es
\begin{equation}
\frac{d u}{d t} 
=
-\vec{\nabla} \left(\frac{P\vec{v}}{\rho}\right)
+
\vec{v}\cdot\vec{\nabla}\left(\frac{P}{\rho}\right)\label{eqn2.38}
\end{equation}
la ecuación de energía térmica para la partícula $i$ será
\begin{equation}
\frac{d u_{i}}{d t}
=
\sum_{j} m_{j} \left(\frac{P_{j}}{\rho_{j}^2}\right) \vec{v_{ij}} \cdot \vec{\nabla_{i}} W_{ij}\label{eqn2.39}
\end{equation}
tomando el promedio de las dos ecuaciones anteriores, se obtiene
\begin{equation}
\frac{d u_{i}}{d t}
=\frac{1}{2}
\sum_{j} m_{j} \left(\frac{P_{j}}{\rho_{j}^2} + \frac{P_{i}}{\rho_{i}^2}\right) \vec{v_{ij}} \cdot \vec{\nabla_{i}} W_{ij}.\label{eqn2.40}
\end{equation}
Cualquiera de las formas de las ecuaciones de energía presentadas arriba, al ser interpretadas usando un kernel Gaussiano, muestran que la energía térmica de una partícula $i$ incrementa cuando la partícula $j$ se acerca a ella.
Al considerar que la energía es conservada, para un gas ideal se cumple
\begin{equation}
 P
 =
 (\gamma - 1)\rho u
\end{equation}
que para un gas monoatómico $\gamma = 5/3$.

El método SPH describe la dinámica de un gas de partículas, en este caso, materia visible o bariónica, junto con la dinámica de fluidos sin colisión autogravitantes, se tiene lo necesario para llevar a cabo una simulación cosmológica que pueda incluir ambos componentes. En el capítulo 3 se describe la función lógica, aunque de manera breve, del código GADGET-2.



\chapter{GADGET}\label{GADGET}
GAlaxies with Dark matter and Gas intEracT (GADGET) es un código libre que utiliza el método de $N$-cuerpos en conjunto con SPH para el cálculo de simulaciones cosmológicas y que ha tenido varias etapas y modificaciones desde su primer etapa pública en 2001. El código fue desarrollado en su mayoría por Volker Springel \cite{b4} como parte de su tesis de doctorado en el Max Planck Institute for Astrophysics. El código puede utilizarse para analizar sistemas aislados o para simulaciones que involucren la expansión del espacio. En ambos casos con o sin condiciones periódicas a la frontera. En todas las simulaciones, GADGET sigue la evolución de un sistema de $N$-cuerpos sin colisión autogravitante, descrito en el capítulo 2 y permite la inclusión de dinámica de gases, descrita por el método SPH.
GADGET es capaz de simular sistemas aislados, tales como la colisión y formación de galaxias hasta la formación a gran escala del Universo. La versión pública del código, GADGET-2 \cite{b10}, lanzada en 2005 es la que se utilizó para las diversas simulaciones de este trabajo.

En la sección 2.1, se comenta que GADGET hace uso de distintos algoritmos para calcular fuerzas entre partículas de materia oscura y la dinámica de gases para materia bariónica. Se describe de forma breve dos algoritmos para calcular la fuerza entre partículas, los algoritmos tree y PM. GADGET-2 utiliza una combinación de ambos algoritmos, el \textit{TreePM method} (Bode, Ostriker \& Xu (200); Bagla 2002) \cite{3.0.1, 3.0.2}. Este método costruye un campo de densidades de masa en la malla, en la cual se efectúa una transformada de Fourier discreta. Se deja evolucionar en el tiempo y se aplica una transformada de Fourier inversa para obtener el potencial gravitacional de la malla.

Una simulación cosmológica requiere de un poder computacional más allá del de un simple ordenador, se necesita un arreglo de computadoras que permitan el cálculo de manera paralela. Esto es un clúster computacional. Este es un conjunto de ordenadores unidos entre sí normalmente por una red de alta velocidad y que se comportan como si fuesen una única computadora. El clúster es un recurso vital para llevar a cabo una simulación de tal magnitud. GADGET-2 utiliza una serie de algoritmos de descomposición. Este arreglo permite distribuir la carga de memoria en procesadores individuales, reduciendo el tiempo de cálculo de manera jerárquica, es decir, se le da prioridad a los cálculos que requieran mayor memoria, por ejemplo en el método TreePM, que divide el espacio en celdas cada vez más pequeñas. Los cálculos que requieren mayor memoria son distribuidos a más procesadores, se les da más prioridad, un proceso como esto se observa mejor en la figura \ref{fig 3.1}
\begin{figure}
\centering
  \includegraphics[width=0.8\textwidth]{./Figuras/TreePM}
  \caption{\footnotesize{Ilustración entre un algoritmo BH y una descomposición de procesos Peano-Hilbert. Esta es una curva que recorre cada malla de la simulación solo una vez. El volumen de la simulación se reparte en dominios al segmentar esta curva en puntos arbitrarios entre los límites de la celda. Esto genera una manera de distribuir el conjunto de partículas en procesadores individuales.}}
  \label{fig 3.1}
\end{figure}

\section{Modificación del Código: Axion-GADGET}
Axion-GADGET \cite{3.1} es una modificación del código de simulaciones de $N$-cuerpos/SPH de GADGET-2. Está basado en un modelo diferente de materia oscura, el Axion Ultra--Ligero o Ultra--Light Axion DM, también llamado Fuzzy DM (Guzmán \& Ureña-López, 2003) sugiere la utilización del modelo SFDM para resolver los problemas que se han encontrado en simulaciones usando diversos códigos para simular las estructuras a gran escala. el FDM es un bosón escalar, ya discutido en la sección 1.2.3., con una masa ultra ligera $(m \sim 10^{-22})$ eV, la cuál es requerida debido a una reciente observación de la época de reionización del Universo. 

Algunos de los valores discutidos entre los que debe valer esta masa dicen que su masa debe estar en el orden de 100 km s$^{-1}$, y que la longitud de onda de de Broglie del FDM debe rondar $\sim \mathcal{O}$(kpc). Este FDM se produce de manera no térmica y en el régimen no relativista se comporta como CDM. La característica más llamativa del FDM es que el halo tiene un núcleo solitónico de tamaño $\sim \mathcal{O} $(kpc) resultante de la presión cuántica de las partículas FDM, que puede ser más grande que su propia gravedad. Por lo tanto, la presión cuántica juega un papel esencial en la resolución de la crisis de pequeña escala. Por otra parte, si la estructura de pequeña escala de halo se puede medir con mayor precisión en el futuro, la masa de partículas FDM puede restringirse. 

La modificación propone un nuevo esquema de la interacción efectiva Partícula--Partícula del algoritmo PM para simular el modelo FDM, mediante el cual se puede calcular el efecto cuántico del FDM en la simulación de $N$-cuerpos con alta resolución.

\subsection{Propiedades Físicas}
La naturaleza del FDM se describe mediante las ecuaciones de Schrödinger-Poisson C. (Bardos et al., 2002) \cite{3.1.1}
\begin{equation}
i\hbar \frac{d \Psi}{dt} 
=
-\frac{\hbar^{2}}{2m^{2}_{\chi}} \vec{\nabla}^{2}\Psi + m_{\chi}V\Psi,\label{eqn 3.1}
\end{equation}
y
\begin{equation}
\vec{\nabla}^{2} = 4\pi G m_{\chi}|\Psi|^{2},\label{eqn 3.2}
\end{equation}
donde $\hbar$, $m\chi$ y $V$ son la constante de Planck, la masa de la partícula y el potencial gravitacional actuando sobre la partícula, respectivamente. La función de onda puede escribirse como 
\begin{equation}
\Psi = \sqrt{\frac{\rho}{m_{\chi}}}\exp(\frac{iS}{\hbar})\label{eqn 3.3}
\end{equation}
en términos de la densidad de número $\frac{\rho}{m_{\chi}}$, mientras que se pudede definir el gradiente de $S$ como el momento lineal de la DM
\begin{equation}
\vec{\nabla}S = m_{\chi}\vec{v}.\label{eqn 3.4}
\end{equation}
Después de resolver las ecuaciones de Schrödinger-Poisson, de las partes real e imaginaria, se obtiene la ecuación de continuidad
\begin{equation}
\frac{d\rho}{dt} + \vec{\nabla}\cdot(\rho\vec{v})\label{eqn 3.5}
\end{equation}
y la ecuación de conservación de momento
\begin{equation}
\frac{d\vec{v}}{dt} + (\vec{v}\cdot\vec{\nabla})\vec{v} 
=
-\vec{\nabla}(Q + V) \label{eqn 3.6}
\end{equation}
y la presión cuántica viene definida por 
\begin{equation}
Q 
=
-\frac{\hbar^{2}}{2m^{2}_{\chi}}\frac{\vec{\nabla}^{2}\sqrt{\rho}}{\sqrt{\rho}}\label{eqn 3.7}
\end{equation}
Estas dos últimas son llamadas las ecuaciones de Madelung (Spiegel 1980; Uhleman et al. 2014, Marsh 2015) \cite{3.2, 3.3, 3.4}. Se puede ver que esta presión solo está definida por la densidad de masa $\rho$ y puede identificarse como una fuerza adicional ejercida sobre las partículas.

Para discutir el efecto de la presión cuántica, se inicia con el Hamiltoniano sin el término de gravedad
\begin{equation}
H = \int \frac{\hbar^{2}}{2 m_{\chi}} |\vec{\nabla}\Psi|^{2}d^{3}x
  = \int \frac{\rho}{2} |\vec{v}|^{2}d^{3}x + \int \frac{\hbar^{2}}{2 m_{\chi}} (\vec{\nabla}\sqrt{\rho})^{2}d^{3}x.\label{eqn 3.8}
\end{equation}
Entonces la energía cinética en forma discreta con índice $j$ para identificar a cada partícula se escribe como
\begin{equation}
T = \int \frac{\rho}{2} |\vec{v}|^{2}d^{3}x = \sum_{j} \frac{1}{2} m_{j} \left(\frac{d q_{j}}{dt}\right)^{2}, \label{eqn 3.9}
\end{equation}
donde $q_{j}$ es la coordenada de la $j$--ésima artícula y el potencial efectivo de la presión cuántica es 
\begin{equation}
K_{p} = \int \frac{\hbar^{2}}{2 m_{\chi}} (\vec{\nabla}\sqrt{\rho})^{2}d^{3}x, \label{eqn 3.10}
\end{equation}
el Lagrangiano del sistema será entonces 
\begin{equation}
L = T - K_{p}
  =
\sum_{j} \frac{1}{2} m_{j} \left(\frac{d q_{j}}{dt}\right)^{2}
-
 \int \frac{\hbar^{2}}{2 m_{\chi}} (\vec{\nabla}\sqrt{\rho})^{2}d^{3}x,\label{eqn 3.11}  
\end{equation}
y las ecuaciones de Euler-Lagrange tendrán la forma
\begin{equation}
\frac{d}{dt}\frac{\partial L}{\partial \dot{q}_{j}} - \frac{\partial L }{\partial q_{j}} = 0 
\Rightarrow 
m_{j} \ddot{q}_{j} = - \frac{\partial K_{p}}{\partial q_{j}}.\label{eqn 3.12}
\end{equation}
$K_{p}$ es una función continua y no puede usarse en el método Particle-Particle (PP). Para eso debe implementarse una aproximación numérica con funciones delta de Kronnecker que discreticen a la densidad de número de cada partícula individual
\begin{equation}
\rho(\vec{r})
=
\sum_{i}m_{i}\delta(\vec{r}-\vec{r}_{i}).\label{eqn 3.13}
\end{equation}
Para hacer este método todavía mejor y con mucho más ventaja, la función $\delta$ puede aproximarse a una función tipo Gaussiana que esté muy estrecha. Las ventajas de esta aproximación son que:

i) Mantiene naturalmente el suavizamiento del kernel, es diferenciable y esféricamente simétrico.

ii) La interacción PP evita singularidades en posiciones donde no haya densidad.

Debido al tamaño infinito de la red, esa singularidad puede hacer que numéricamente, el resultado no tenga sentido físico.
Con esto en mente, se escribe la función $\delta$ como una Gaussiana de la forma
\begin{equation}
\delta (\vec{r}-\vec{r}_{i}) = 
\frac{2\sqrt{2}}{\lambda ^{3} \pi ^{3/2}} \exp \left(-\frac{2|\vec{r}-\vec{r}_{i}|^{2}}{\lambda ^{2}}\right).\label{eqn 3.14}
\end{equation}
El valor de $\lambda$ no es arbitrario, debe ser del mismo orden de la longitud de onda de deBroglie puesto que una partícula de FDM debe tener probabilidad alta de ser encontrada dentro de un paquete de onda descrito por la ecuación (\ref{eqn 3.3}). Con estos valores, la probabilidad de encontrar una partícula de FDM en una longitud de onda es de $95 \%$. Tomando la masa del FDM del orden $\mathcal{O}(10^{-22})$eV como ejemplo, su longitud de onda $\lambda$ es del orde de kpc. Utilizando la ecuación (\ref{eqn 3.14}) en el término $(\vec{\nabla}\sqrt{\rho})^{2}$ de la ecuación (\ref{eqn 3.10}) usando la función kernel
\begin{equation}
\begin{array}{ll}
\left[\vec{\nabla}\sqrt{\rho (\vec{r})}\right]^{2} &=
\frac{1}{4\rho(\vec{r})}\left[\sum_{i} m_{i}\vec{\nabla}\delta(\vec{r}-\vec{r}_{i})\right]^{2}, \\\\\\ 
&=
\frac{1}{4\rho(\vec{r})} 
\left[\sum_{i}
m_{i}\delta(\vec{r}-\vec{r}_{i})(-\frac{4}{\lambda^{2}})(\vec{r}-\vec{r}_{i})\right]^{2}, \\\\\\
&=
\frac{4}{\lambda^{4}\rho(\vec{r})}
\left[
\sum_{i} m_{i}\delta(\vec{r}-\vec{r}_{i})(\vec{r}-\vec{r}_{i})
\right]^{2}. \label{eqn 3.15}

\end{array}
\end{equation}
En la simulación, esas partículas de FDM se agrupan en un cúmulo masivo en el espacio. La densidad de masa (\ref{eqn 3.13}) se vuelve
\begin{equation}
\rho(\vec{r})
=
\sum_{j}\sum_{i}m_{i}\delta(\vec{r}-\vec{r}_{j}),\label{eqn 3.16}
\end{equation} 
con el índice $j$ para cada agrupación de partículas. 

Matemáticamente, se puede pensar que la densidad de masa se expande alrededor de $\vec{r}_{j}$ para incluir todas las partículas de FDM: $\vec{r} \rightarrow \vec{r}-\vec{r}_{j}$ y $\vec{r}_{i} \rightarrow \vec{r}_{i} - \vec{r}_{j}$. Tomando eso en consideración, la suma de partículas individuales de FDM es efectivamente la misma que sumando sobre todos los puntos y la ecuación (\ref{eqn 3.15}) puede reescribirse como 
\begin{equation}
\left[\vec{\nabla}\sqrt{\rho (\vec{r})}\right]^{2} \simeq 
\frac{4}{\lambda^{4}}
\left[
\sum_{i}m_{i}\delta(\vec{r}-\vec{r}_{j})(\vec{r}-\vec{r}_{j})
\right]^{2}
\left[
\sum_{j}m_{j}\delta(\vec{r}-\vec{r}_{j})
\right]^{-1}. \label{eqn 3.17}
\end{equation}
Las ecuaciones (\ref{eqn 3.15}) y (\ref{eqn 3.17}) son prácticamente iguales pero su significado no debe confundirse en este punto; el paquete de onda Gaussiano se vuelve un kernel imaginario de suavizamiento de partículas.

Para discretizar completamente $\partial K_{p}/\partial q_{j}$ debe integrarse la ecuación (\ref{eqn 3.17}) en todo el espacio; dada la naturaleza de la propia función $\delta$, se hace énfasis en el volumen que rodea los puntos imaginarios de las partículas. Así, la integración total con la aproximación del kernel da
\begin{equation}
\int|\vec{\nabla}\sqrt{\rho (\vec{r})}|^{2}  \simeq 
\int \frac{4 d^{3}x}{\lambda^{4}}
\left[
\sum_{j} m_{j}\delta(\vec{r}-\vec{r}_{j})(\vec{r}-\vec{r}_{j})
\right]^{2}
\left[
\sum_{j}m_{j}\delta(\vec{r}-\vec{r}_{j})
\right]^{-1} \label{eqn 3.18}
\end{equation} \\\\
\begin{equation}
\simeq
4\lambda ^{-4} 
\sum_{j}m_{j}\delta(\vec{r}-\vec{r}_{j})(\vec{r}-\vec{r}_{j})^{2}\Delta V_{j}B_{j},\label{eqn 3.19}
\end{equation}
\begin{equation}
\simeq
4\lambda^{-4}
\sum_{j}m_{j}
\frac{\Delta V_{j}B_{j}}{\lambda^{3}\pi^{3/2}}
\exp\left[-\frac{(\vec{r}-\vec{r}_{j})^{2}}{\lambda^{2}}\right]
(\vec{r}-\vec{r}_{j})^{2}, \label{eqn 3.20}
\end{equation}
donde $V_{j}$ y $B_{j}$ son el volumen efectivo y el factor de corrección de la $j$--ésima partícula. 

Se propone un  factor de corrección $B_{j}$ para la $j$--ésima partícula en la simulación para que numéricamente pueda distinguirse entre los resultados de la integración de la función $\delta$ como un kernel Gaussiano. Cuando se trata a esta función como kernel cuya anchura es igual a una longitud de onda de una partícula, no se comporta como una función $\delta$ en la  región donde la distancia entre dos centros del kernel es menor a una longitud de onda. En rangos tan pequeños, la superposición entre dos Gaussianas puede contribuir significativamente, especialmente al hacer integraciones con alta densidad de partículas.

Teóricamente, el volumen efectivo $V_{j}$ para cada partícula en la simulación es del orden de $\lambda^{3}\pi^{3/2}$, resultado de una integral del kernel Gaussiano; el valor exacto de $\Delta V_{j}$ puede diferir de  sistema a sistema por la propia complejidad de la región central del kernel. Se trata de un parámetro libre fenomenológico o constante, pero se ajusta su valor para hacer coincidir el resultado dentro del núcleo del solitón obtenido con otras aproximaciones. (Schieve et al. 2014) \cite{3.5}.

Finalmente; la ecuación (\ref{eqn 3.10}) se reacomoda
\begin{equation}
\sum_{j} \frac{\partial K_{p}}{\partial q_{j}}
=
\frac{4\hbar^{2}}{m_{\chi}^{2}\lambda^{4}}
\sum_{j}m_{j}\Delta V_{j}B_{j}
\exp\left[
-\frac{2|\vec{r}-\vec{r}_{j}|^{2}}{\lambda^{2}}\right]
\left(1-\frac{2|\vec{r}-\vec{r}_{j}|^{2}}{\lambda^{2}}\right)
(\vec{r}-\vec{r}_{j})\label{eqn 3.21}
\end{equation}
al igual que la ecuación de movimiento (\ref{eqn 3.12})
\begin{equation}
\sum_{j}m_{j}\ddot{q}_{j}
=
\frac{4\hbar^{2}}{m_{\chi}^{2}\lambda^{4}}
m_{j}\Delta V_{j}B_{j}
\exp\left[
-\frac{2|\vec{r}-\vec{r}_{j}|^{2}}{\lambda^{2}}\right]
\left(1-\frac{2|\vec{r}-\vec{r}_{j}|^{2}}{\lambda^{2}}\right)
(\vec{r}-\vec{r}_{j}).\label{eqn 3.22}
\end{equation}
Sustituyendo $q$ con $\vec{r}$, la aceleración adicional de la presión cuántica en la simulación se describe como
\begin{equation}
\ddot{\vec{r}}
=
\frac{4M\hbar^{2}}{M_{0}m_{\chi}^{2}\lambda^{4}}
\sum_{j}B_{j}
\exp\left[
-\frac{2|\vec{r}-\vec{r}_{j}|^{2}}{\lambda^{2}}\right]
\left(1-\frac{2|\vec{r}-\vec{r}_{j}|^{2}}{\lambda^{2}}\right)
(\vec{r}_{j}-\vec{r}).\label{eqn 3.23}
\end{equation}
$M$ es la masa de la partícula en la simulación y $M_{0}$ es un factor de normalización que involucra a $\Delta V_{j}$, cuyo valor se elige $M_{0} = 10^{6} M_{\odot}$. Si se coloca cualquier partícula solitaria de prueba alrededor de fuentes de presión cuántica, la energía adicional dada al sistema por parte de esta presión es cero. El trabajo total, es decir la integración de la ecuación (\ref{eqn 3.23}) de $r=0$ a $r=\infty$ se anula. La presión cuántica es una interacción de rango corto mostrado en la ecuación (\ref{eqn 3.23}) por el término exponencial que decrece.


\appendix

%---------------------------------------------------------------------------------%
\cleardoublepage
\addcontentsline{toc}{chapter}{Bibliografía}
\bibliographystyle{acm} % estilo de la bibliografía.
\bibliography{yyyy} % yyyy.bib es el fichero donde está salvada la bibliografía.
\begin{thebibliography}{a}

%1%
\bibitem{1.01} \textsc{Ryden, B. S. (2003)},
\textit{Introduction To Cosmology},
San Francisco: Addison-Wesley

%1%
\bibitem{1.02} \textsc{Battaner, E. (2015)},
\textit{Grandes estructuras del universo: El cosmos a gran escala},
RBA Contenidos Editoriales y Audiovisuales, S.A.U.
%2%
\bibitem{1.1} \textsc{Hubble, E. (1929)}
\textit{A Relation between Distance and Radial Velocity among Extra-Galactic Nebulae}
Proceedings of the National Academy of Sciences of the United States of America, vol. 15, Issue 3, pp. 168-173
%3%
\bibitem{1.1.1} \textsc{Zwicky, F. (1937)},
\textit{On the Masses of Nebulae and of Clusters of Nebulae},
Astrophysical Journal, vol. 86, p.217
%4%
\bibitem{1.1.2} \textsc{Rubin, V. C.; Ford, W. K. (1970)},
\textit{Rotation of the Andromeda Nebula from a Spectroscopic Survey of Emission Regions},
Astrophysical Journal, vol. 159, p.379 
%5%
\bibitem{1.1.3} \textsc{Spergel, D.N. et al. (2007)},
\textit{Wilkinson Microwave Anisotropy Probe (WMAP) Three Year
Observations: Implications for Cosmology},
ArXiv preprint, arXiv:astro-ph/0603449v2
%6%
\bibitem{1.1.4} \textsc{Mandolesi, N.; Burigana, C.; Gruppuso, A.; Natoli, P. (2013)},
\textit{The Planck Mission: Recent Results, Cosmological and Fundamental Physics Perspectives},
International Journal of Modern Physics D, vol. 22, Issue 14, id. 1330029
%7%
\bibitem{1.1.5} \textsc{Spergel, D. N.; Bolte, M.; Freedman, W. (1997)},
\textit{The age of the universe},
Proceedings of the National Academy of Sciences of the United States of America, vol. 94 pp. 6579-6584
%8%
\bibitem{1.1.6} \textsc{Sarkar, S. (1996)},
\textit{Big Bang nucleosynthesis and physics beyond the Standard Model},
ArXiv preprint, arXiv:hep-ph/9602260v2
%9%
\bibitem{1.1.7} \textsc{Burles, S.; Nollet, K. M.; Turner, M. S. (2000)},
\textit{What Is The BBN Prediction for the Baryon Density and How Reliable Is It?},
ArXiv preprint, arXiv:astro-ph/0008495v4
%10%
\bibitem{1.1.8} \textsc{Olive, K. A.; Stelgman G.; Walker, T. P.; (1999)},
\textit{Primordial Nucleosynthesis: Theory and Observations},
ArXiv preprint arXiv:astro-ph/9905320v1 
%11%
\bibitem{1.1.9} \textsc{Blanton, M. R. et al. (2017)},
\textit{Sloan Digital Sky Survey IV: Mapping the Milky Way, Nearby Galaxies, and the Distant Universe},
The Astronomical Journal, vol. 154, Issue 1, pp. 35 (2017)
%12%
\bibitem{1.2.1} \textsc{Guth, A. H. (1981)},
\textit{Inflationary universe: A possible solution to the horizon and flatness problems},
Physical Review D (Particles and Fields), vol. 23, Issue 2, 15 January 1981, pp.347-356
%13%
\bibitem{1.2.2} \textsc{Peebles, P. J. E.; Ratra, B. (2002)},
\textit{The Cosmological Costant and Dark Energy},
ArXiv preprint arXiv:astro-ph/0207347v2
%14%
\bibitem{1.2.3} \textsc{Sasaki, M. (1986)},
\textit{Large Scale Quantum Fluctuations in the Inflationary Universe},
Progress of Theoretical Physics, vol. 76, Issue 5, pp. 1036–1046
%15%
\bibitem{1.2.4} \textsc{Springel, V. et al. (2005)},
\textit{Simulations of the formation, evolution and clustering of galaxies and quasars},
Nature, vol 435, Issue 7042, pp. 629-636
%16%
\bibitem{1.2.5} \textsc{Klypin, A. A.; Kravstov, A. V.; Bullock, J. S.; Primack, J. R. (2001)},
\textit{Resolving the Structure of Cold Dark Matter Halos},
The Astrophysical Journal, vol. 554, Issue 2, pp. 903-915
%17%
\bibitem{1.2.6} \textsc{Homma, D.; Chiba, M.; Okamoto, S. et al. (2016)},
\textit{A New Milky Way satellite discovered in the SUBARU/HYPER SUPRIME-CAM survey},
The Astrophysical Journal, vol. 832, 1
%18%
\bibitem{1.2} \textsc{ Grøn, O. Hervik, S. (2004)},
Dynamics of Homogeneus and Isotropic cosmologies. In
\textit{Einstein's General Theory of Relativity},
University of Oslo, pp. 265-267
%19%
\bibitem{1.3} \textsc{Schutz, B. (2009)},
Perfect fluids in special relativity. In 
\textit{A first Course in General Relativity},
pp. 84-110, Cambridge: Cambridge University Press
%20%
\bibitem{1.4} \textsc{Schutz, B. (2009)},
The Einstein field equations. In
\textit{A first Course in General Relativity},
pp. 184-202, Cambridge: Cambrige University Press
%21%
\bibitem{b1} \textsc{Navarro, J. F.; Frenk, C. S.; White, S. D. M. (1996)},
\textit{The Structure of Cold Dark Matter Halos},
Astrophysical Journal vol. 462, p.563
%22%
\bibitem{b2} \textsc{Moore, B. (1994)},
\textit{Evidence against dissipation-less dark matter from observations of galaxy haloes},
Nature, vol. 370, pp. 629-631 
%23%
\bibitem{Moore 1999} \textsc{Moore, B., Quinn, T., Governato, F., Stadel, J., Lake, G (1999)},
\textit{Cold collapse and the core catastrophe}
Monthly Notices of the Royal Astronomical Society, vol. 310, Issue 4, pp. 1147-1152
%24%
\bibitem{Navarro Hayashi} \textsc{Navarro, J. F.; Hayashi, E.; Power, C.; Jenkins, A. R.; Frenk, C. S.; White, S. D. M.; Springel, V.; Stadel, J.; Quinn, T. R. (2004)}, 
\textit{The inner structure of $\Lambda$CDM haloes - III. Universality and asymptotic slopes}, 
Monthly Notices of the Royal Astronomical Society, vol. 349, Issue 3, pp. 1039-1051
%25%
\bibitem{Siddhartha Matos} \textsc{Guzmán, F. S.; Matos T. (2000)}, 
\textit{Scalar fields as dark matter in spiral galaxies},
Classical and Quantum Gravity, vol. 17, Issue 1, pp. L9-L16 
%26%
\bibitem{1.3.1} \textsc{Spergel, D. N.; Steinhardt P. J. (2000)},
\textit{Observational Evidence for Self-Interacting Cold Dark Matter},
Physical Review Letters, vol. 84, Issue 3760
%27%
\bibitem{1.3.2} \textsc{Colín, P.; Avila-Reese, V.; Valenzuela, O. (2000)},
\textit{Substructure and halo density profiles in a Warm Dark Matter Cosmology},
ArXiv preprint arXiv:astro-ph/0004115
%28%
\bibitem{1.3.2.1} \textsc{Clowe, D.; et al. (2006)},
\textit{A Direct Empirical Proof of the Existence of Dark Matter},
The Astrophysical Journal, vol. 648, Issue 2, pp L109-L113
 
\bibitem{1.3.3} \textsc{Goodman, J. (2000)},
\textit{Repulsive Dark Matter},
ArXiv preprint arXiv:astro-ph/0003018
%29%
\bibitem{1.3.4} \textsc{Hu, W.; Barkana, R.; Gruzinov, A. (2000)},
\textit{Cold and Fuzzy Dark Matter}
ArXiv preprint arXiv:astro-ph/0003365
%30%
\bibitem{1.3.5} \textsc{Kaplinghat, M.; Knox, L. Turner, M. S. (2000)},
\textit{Annihilating Cold Dark Matter}
ArXiv preprint arXiv:astro-ph/0005210
%31%
\bibitem{1.3.6} \textsc{Cen, R. (2000)},
\textit{Decaying Cold Dark Matter Model and Small-Scale Power},
ArXiv preprint arXiv:astro-ph/0005206
%32%
\bibitem{1.3.7} \textsc{Ellis, J. (2007)},
\textsc{Beyond the standard model with the LHC},
Nature, vol. 448, Issue 7151, pp. 297-301
%33%
\bibitem{1.3.8} \textsc{Milgrom, M. (2002)},
\textit{MOND--theoretical aspects}
ArXiv preprint arXiv:astro-ph/0207231
%34%
\bibitem{2.1.1} \textsc{Kravstov, A. V. (1999)},
\textit{High-resolution simulations of structure formation in the universe}
Thesis (PhD). NEW MEXICO STATE UNIVERSITY, Source DAI-B 60/11, p. 5564, May 2000, 256 pages
%35%
\bibitem{2.1.2} \textsc{O'Shea, B. W.; Bryan, G.; Bordner, J.; Norman, M. L.; Abel, T.; Harkness, R.; Kritsuk, A. (2004)},
\textit{Introducing Enzo, an AMR Cosmology Application}
ArXiv preprint arXiv:astro-ph/0403044
%36%
\bibitem{2.1.3} \textsc{Teyssier, R. (2002)},
\textit{Cosmological hydrodynamics with adaptative mesh refinement. A new high resolution code called RAMSES},
Astronomy and Astrophysics, vol.385, pp.337-364
%38%
\bibitem{b3} \textsc{Reif, F.; Scott, H. L.,(1998)},
\textit{Fundamentals of Statistical and Thermal Physics}
American Journal of Physics, vol. 66, Issue 2, pp. 164-167
%39%
\bibitem{b4} \textsc{Springel, V.; Yoshida, N.; White, S. D. M., (2001)}
\textit{GADGET: a code for collisionless and gasdynamical cosmological simulations },
New Astronomy Volume 6, pp. 79-117
%40%
\bibitem{b5} \textsc{Bodenheimer, P.; Laughlin, G. P.; Rózyczka, M.; Yorke, H. W., (2007)} 
\textit{Numerical Methods in Astrophysics: An Introduction},
CRC Press, December 2006

\bibitem{b5.1} \textit{Klypin, A. A.; Shadarin, S. F. (1983)},
\textit{Three--dimensional numerical model of the formation of large--scale structure in the Universe}
Monthly Notices of the Royal Astronomical Society (ISSN 0035-8711), vol. 204, pp. 891-907

\bibitem{b5.2} \textit{White, S. D. M.; Frenk, C. S.; Davis, M. (1983)},
\textit{Clustering in a neutrino--dominated universe},
Astrophysical Journal, Part 2 - Letters to the Editor (ISSN 0004-637X), vol. 274, pp. L1-L5


%41%
\bibitem{b6} \textsc{Gingold, R. A.; Monaghan, J.J. (1977)}
\textit{Smoothed Particle Hydrodynamics: Theory and applications to non-spherical stars},
Monthly Notices of the Royal Astronomical Society, vol. 181, pp. 375-389
%42%
\bibitem{b7} \textsc{Monaghan, J. J., (1997)}
\textit{SPH and Riemman Solvers},
Journal of Computational Physics, vol. 136, Issue 2 pp. 298-307 
%43%
\bibitem{b8} \textsc{Monaghan, J. J. (1992)}
\textit{Smoothed Particle Hydrodynamics},
%44%
\bibitem{b8.1} \textsc{Monaghan, J.J.; Lattanzio, J. C. (1985)},
\textit{A refined particle method for astrophysical problems},
Astronomy and Astrophysics (ISSN 0004-6361), vol. 149, no. 1, pp. 135-143
Annual review of astronomy and astrophysics, vol. 30 (A93-25826 09-90), pp. 543-574
%45%
\bibitem{b8.2} \textsc{Barnes, J.; Hut, P. (1986)},
\textit{A hierarchical $\mathcal{O}N\log N$ force--calculation algorithm}
Nature, vol. 324, Issue 4, pp. 446-449

\bibitem{b9} \textsc{Price, D. J. (2004)}
\textit{Smoothed Particle Magnetohydrodynamics-II. Variational principles and variable smoothing-length terms},
Monthly Notices of the Royal Astronomical Society, vol. 348, Issue 1, pp. 139-152
%46%
\bibitem{b9.1} \textsc{Gingold, R. A.; Monaghan, J.J. (1977)},
\textit{Smoothed particle hydrodynamics - Theory and application to non-spherical stars},
Monthly Notices of the Royal Astronomical Society, vol. 181, pp. 375-389
%47%
\bibitem{b10} \textsc{Springel, V. (2005)},
\textit{The cosmological simulation code: GADGET-2},
Monthly Notices of the Royal Astronomical Society, vol. 364, pp. 1105-1134
%47%
\bibitem{3.0.1} \textsc{Bode, P.; Ostriker, J. P.; Xu, G. (2000)}
\textit{The Tree-Particle-Mesh N-body Gravity Solver}
ArXiv preprint arXiv:astro-ph/9912541 

\bibitem{3.0.2} \textsc{Bagla, J. S. (2002)},
\textit{TreePM: A code for cosmological N-body simulations}
Journal of Astrophysics and Astronomy, vol. 23, Issue 3-4, pp.185-196

\bibitem{3.1} \textsc{Zhang, J., Tsai, Y.-L. S., Kuo, J.-L, Cheung, K., Chu, M.-C (2017)},
\textit{Ultra-Light Axion Dark Matter and its Impacts on Dark Halo Structure in $N$-body Simulation},
ArXiv preprint  arXiv:1611.00892v6
%48%
\bibitem{3.1.1} \textsc{Bardos, C., Erdös, L., Goise, F., Mauser, N., Yau, H.-T (2002)},
\textit{Derivation of the Schrödinger–Poisson equation from the quantum
$N$-body problem}
Comptes Rendus Mathematique, vol. 334, Issue 6, pp. 515-520
%49%
\bibitem{3.2} \textsc{Spiegel, E. A. (1980)},
\textit{Fluid form of the linear and nonlinear Schrödinger equations},
Physica D: Nonlinear Phenomena vol. 1 Issue 2, pp. 236-240 
%50%
\bibitem{3.3} \textsc{Uhleman, C., Kopp, M., Haugg, T. (2014)},
\textit{Schrödinger method as N-body double and UV completion of dust},
Physical Review D. vol. 90, Issue 2 
%51%
\bibitem{3.4}\textsc{Marsh, D. J. E. (2015)},
\textit{Nonlinear hydrodynamics of axion dark matter: Relative velocity effects and quantum forces},
Physical Review, vol. 91, Issue 12
%52%
\bibitem{3.5} \textsc{Schive, H.-Y.m Chiueh, T., Broadhurst, T. (2014)},
\textit{Cosmic structure as the quantum interference of a coherent dark wave}
Nature Physics, vol. 10, Issue 7, pp. 496

 
\end{thebibliography}
\end{document}