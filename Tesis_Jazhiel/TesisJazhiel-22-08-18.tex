\documentclass[a4paper,openright,10pt, oneside, final]{book}
\usepackage[spanish, es-tabla]{babel}
\usepackage[utf8]{inputenc} 
\usepackage{listings} %para poner codigos 
\usepackage{multirow} % para las tablas
\usepackage{amssymb, amsmath, amsbsy} % simbolitos
\usepackage{upgreek} % para poner letras griegas sin cursiva
\usepackage{cancel} % para tachar
\usepackage{mathdots} % para el comando \iddots
\usepackage{mathrsfs} % para formato de letra
\usepackage{stackrel} % para el comando \stackbin
\usepackage{graphicx} %para meter figuritas chavo
\usepackage{adjustbox}
\usepackage{subfigure} %para más figuritas
\usepackage{float} % para que las imágenes me obedezcan. Como sirve este pedo
\usepackage{enumerate} %para enumerar ps es obvio OBVIO
%\usepackage{afterpage}% para dejar paginas en blanco
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{tabulary}
\usepackage{tabularx}
\usepackage{colortbl}
\usepackage{array}
\usepackage{rotating}
\usepackage{tikz}
\usepackage{vmargin}
\setpapersize{A4}
\setmargins{2.5cm} 
{1.5cm}
{16.5cm}
{23.42cm}
{12pt}
{1cm} 
{0pt}
{2cm} 
\spanishdecimal{.}
\setcounter{secnumdepth}{3} %para que ponga 1.1.1.1 en subsubsecciones
\setcounter{tocdepth}{3} % para que ponga subsubsecciones en el indice


\begin{document}

%\begin{titlepage}
%\begin{center}
%\begin{Huge}
%\textsc{Modelos de Materia Oscura: Una Perspectiva Numérica}
%\end{Huge}
%\end{center}
%\end{titlepage}

% para crear una cara en blanco
%\newpage
%$\ $
%\thispagestyle{empty} % para que no se numere esta página

\thispagestyle{empty}

    \begin{titlepage}
        \thispagestyle{empty}
        \begin{minipage}[c][0.17\textheight][c]{0.25\textwidth}
            \begin{center}
                \includegraphics[width=3.5cm, height=4.5cm]{./Figuras/IPN}
            \end{center}
        \end{minipage}
        \begin{minipage}[c][0.17\textheight][t]{0.65\textwidth}
            \begin{center}
                \vspace{.3cm}
                \textsc{\large Instituto Politécnico Nacional}\\[0.5cm]
                \vspace{.3cm}
                \hrule height2.5pt
                \vspace{.1cm}
                \hrule height1pt
                \vspace{.8cm}
                \textsc{\large Escuela Superior de Física y Matemáticas}\\[0.5cm] %
            \end{center}
        \end{minipage}

        \begin{minipage}[c][0.81\textheight][t]{0.25\textwidth}
            \vspace*{5mm}
            \begin{center}
                \hskip2pt
                \vrule width2.5pt height13cm
                \hskip1mm
                \vrule width1pt height13cm \\
                \includegraphics[height=4.5cm]{./Figuras/ESFM}
            \end{center}
        \end{minipage}
        \begin{minipage}[c][0.81\textheight][t]{0.65\textwidth}
            \begin{center}
                \vspace{2cm}

                {\LARGE\scshape Modelos de Materia Oscura: Una Perspectiva Numérica}\\[.2in]

                \vspace{2cm}            

                \textsc{\LARGE TESIS}\\[0.5cm]
                \textsc{\large que para obtener el t\'itulo de}\\[0.5cm]
                \textsc{\large Licenciatura en Física y Matemáticas}\\[0.7cm]
                \textsc{\large presenta}\\[0.5cm]
                \textsc{\large \textbf{Jazhiel Chacón Lavanderos}}\\[2cm]          

                \vspace{0.5cm}

                {\large\scshape Directores de Tesis:\\[0.2cm] {Dr. Tonatiuh Matos Chassin \\ Dr. Francisco Javier Turrubiates Saldívar}}\\[.2in]

                \vspace{0.5cm}

                {Ciudad de México,} {Agosto} {2018}
            \end{center}
        \end{minipage}
    \end{titlepage}

% para crear una cara en blanco
\newpage
$\ $
\thispagestyle{empty} % para que no se numere esta página

\chapter*{}
\thispagestyle{empty}
\pagenumbering{Roman} % para comenzar la numeración de paginas en números romanos
\begin{flushright}
\textit{A Dios, creador del Universo \\\
Y a mis padres, que me dieron la vida para observarlo}
\end{flushright}

\chapter*{Agradecimientos} % si no queremos que añada la palabra "Capitulo"
\addcontentsline{toc}{chapter}{Agradecimientos} % si queremos que aparezca en el índice
%\markboth{AGRADECIMIENTOS}{AGRADECIMIENTOS} % encabezado
\begin{itemize}
\item A mis directores, el Dr. Tonatiuh y el Dr. Francisco por darme su confianza y permitirme realizar este trabajo.
\item A todo el grupo de cosmología del Departamento de Física del CINVESTAV, cuyos nombres no menciono para evitar alguna omisión, gracias por su apoyo en todo momento y por sus grandes enseñanzas.
\item Al Dr. José Alberto Vázquez González y al grupo de cosmología en el ICF de la UNAM en Cuernavaca, quienes han expresado su apoyo hacia este proyecto.
\item Especialmente al Dr. Ruslan Gabbasov, quien fue un apoyo fundamental para el desarrollo de este trabajo fuera del CINVESTAV y de E.S.F.M.
\item A Malú, quien me ha dado consejos y sobre todo ``zapes'' emocionales para seguir adelante.
\item A todos mis profesores de E.S.F.M., difícil, pero no imposible.
\item A mis compañeros de E.S.F.M.: David, Jaime, Claudia, Fernando, Daniel, Miguel. Si se pudo muchachos.
\item A mis amigos de toda una vida: Stephano, Melissa, Gaby, Missael; gracias por su apoyo incondicional durante casi 10 años. Sin duda serán muchos más.
\item A mi familia: mi padre, mi madre y mi hermana. Gracias por su apoyo y fuerza en momentos difíciles, esto lo hice por ustedes.
\end{itemize}



\chapter*{Resumen} % si no queremos que añada la palabra "Capitulo"
\addcontentsline{toc}{chapter}{Resumen} % si queremos que aparezca en el índice
%\markboth{RESUMEN}{RESUMEN} % encabezado

La cosmología ha tomado un papel muy importante en el desarrollo de la ciencia y la tecnología en las últimas dos décadas. Datos recabados de observaciones al entorno y al firmamento sugieren que nuestro entendimiento del Cosmos está en una etapa inicial. Uno de los descubrimientos más impresionantes fue que la materia observable del Universo, es decir, los planetas, las estrellas, las nubes de gas, las galaxias etc., comprende tan solo alrededor del 5\% de la materia total que compone al Universo, mientras que el otro 95\% tiene aún un comportamiento desconocido.

Este 95\% de materia exótica se compone de dos tipos de materia, denominados \textit{materia oscura}, cuyo comportamiento es gravitacionalmente atractivo y ocupa $\sim 27\% $ y  la \textit{energía oscura}, con comportamiento gravitacionalmente repulsivo, ocupa el $\sim 68\%$ restante. 

Diversos modelos de evolución cosmológica han sido propuestos y estudiados desde inicios del siglo XX, siendo el modelo $\Lambda$CDM el que mejor concuerda con los datos recabados de observaciones hechas en el Cosmos a gran escala. Sin embargo, $\Lambda$CDM presenta una serie de problemas a escalas pequeñas (galácticas) que al día de hoy siguen sin tener respuesta objetiva. Una alternativa a este modelo es el de la materia oscura como campo escalar (SFDM), el cual ofrece solucionar los problemas de $\Lambda$CDM y que ha obtenido gran reconocimiento dentro de la comunidad científica, especialmente entre astrofísicos y cosmólogos en las últimas décadas.

Las simulaciones numéricas de $N$-cuerpos permiten tener una idea más clara de la dinámica del Universo a gran escala y su comportamiento a pequeña escala, y con estos dos modelos de materia oscura mencionados, el propósito de este trabajo es compararlos de forma numérica para obtener así un mejor comprendimiento de la naturaleza de la materia oscura.
\thispagestyle{empty}

\chapter*{Abstract} % si no queremos que añada la palabra "Capitulo"
\addcontentsline{toc}{chapter}{Abstract} % si queremos que aparezca en el índice
%\markboth{ABSTRACT}{ABSTRACT} % encabezado

Cosmology has taken a great step in science and technology development during the last two decades. Observational data from the enviroment and firmament suggests that our understanding of the Cosmos it's on its very first steps. One of the most outstanding detections was that visible matter; that is, planets, stars, gas clouds, galaxies etc., is just only about 5\% of the total matter in the Universe, whereas 95\% of the matter has an unknown behaviour.

This 95\% of exotic matter is compounded of two types of matter, \textit{dark matter}, whose behaviour is gravitationally attractive occupies $\sim$ 27\%, and \textit{dark energy}, with a gravitational push behaviour, occupies the rest 68\%.

Diverse cosmological evolutionary models has been proposed and studied since the beggining of the XX century, and the $\Lambda$CDM model has proven to be the very best model that fits observational data from large scale structure (clusters of galaxies). Nevertheless, $\Lambda$CDM has a series of incovenients at small scales (galactic scales) that seem to not have a very objective answer nowadays. One model proposal is the scalar field dark matter model (SFDM), which offers a solution to the $\Lambda$CDM problems and has taken great acknowledgment throughout scientific community, specially to astrophysicists and cosmologists in the last couple of decades.

Numerical $N$-body simulations allow to have a clearer idea of the large scale Universe dynamics and its nature on small scales, the objective of this work is to compare the two models mentioned above numerically and get a better understanding of dark matter behaviour.
\thispagestyle{empty}

\tableofcontents % indice de contenidos
%\thispagestyle{empty}

\cleardoublepage
%\thispagestyle{empty}
\addcontentsline{toc}{chapter}{Lista de figuras} % para que aparezca en el indice de contenidos
\listoffigures % indice de figuras
%\thispagestyle{empty}

%\thispagestyle{empty}
%\cleardoublepage
%\thispagestyle{empty}
%\addcontentsline{toc}{chapter}{Lista de tablas} % para que aparezca en el indice de contenidos
%\listoftables % indice de tablas
%thispagestyle{empty}




\chapter{Introducción a la Cosmología}
\pagenumbering{arabic}
La cosmología es la ciencia que estudia y busca explicar el origen y la evolución del Universo como un todo, la física fundamental detrás de esos procesos y por lo tanto obtener un entendimiento más profundo de las leyes de la física que se supone que gobiernan a todo el Universo. Sin embargo existe solo un Universo que se puede estudiar y no se puede  experimentar con el, sólo hacer observaciones. Esto conlleva bastantes limitantes sobre lo que se puede conocer acerca de su origen \cite{1.01}. 

\textbf{El Universo es homogéneo e isótropo en un espacio tridimensional a gran escala}. Esta pequeña pero poderosa frase se conoce como \textbf{\textit{principio cosmológico}}. Que sea homogéneo se refiere a que la materia está uniformemente distribuida en todo el espacio, mientras que isótropo hace referencia a que tiene las mismas propiedades en todas las direcciones espaciales. Así, en un Universo homogéneo e isótropo la distribución de materia sería la misma para cualquier observador en cualquier ubicación del espacio, es decir, ningún lugar sería preferencial de acuerdo a este principio.

Suponer que el principio cosmológico implica un Universo infinito es un poco ingenuo. La teoría de la relatividad nos dice que el espacio puede ser curvo y que, por tanto, es imaginable un Universo finito que no tenga bordes. Una imagen intuitiva utilizada por Einstein y Hubble, que permite la captación de la posibilidad de un Universo finito compatible con el principio cosmológico es la de un Universo bidimensional formando una superficie esférica. Sobre ella, un observador bidimensional podría recorrer todo el Universo, por ser finito, y nunca encontrarse con el borde. Esta imagen, llevada a las tres dimensiones espaciales de nuestro Universo real, nos permite comprender el Universo finito y sin bordes.

\begin{figure}
\centering
\includegraphics[width=0.7\textwidth]{./Figuras/HubbleXDF}
\caption{\footnotesize{Hubble eXtreme Deep Field (XDF). Es una composición de imágenes tomadas por el telescopio espacial Hubble tras 10 años de observaciones. Contiene alrededor de 5,500 galaxias en total.}}
\end{figure}

Pero la concepción de un Universo finito y cerrado conlleva a un problema de \textit{coalescencia}. Esto es, la gravedad haría que, con tiempo suficiente, todas las galaxias se atrajeran, amontonando toda la masa del Universo en un solo punto. ¿Hay alguna forma de evitar la coalescencia? La relatividad nos enseña que todo movimiento es siempre en referencia de algo; no hay movimiento absoluto. Si se introduce un Universo en expansión, ciertamente se evitaría la coalescencia. Las galaxias no se abalanzarían unas sobre otras si inicialmente hubo una ``explosión'' y estuvieran alejándose por su efecto. La autogravitación del Universo iría frenando la expansión y podría llegar a detenerla, o no podría, dependiendo de la violencia de la expansión inicial y de la densidad de galaxias.

Estas ideas están muy cercanas a la modelación del Big Bang, modelo del Universo aceptado hoy día. La idea intuitiva, aunque básica y simple, debe ajustarse a unas bases físicas más firmes. Por ejemplo, la homogeneidad del principio cosmológico anula los gradientes de parámetros termodinámicos, lo que simplifica las expresiones de las ecuaciones que gobiernan el Universo.

Se requieren algunas precisiones más para entender el principio cosmológico. Si un observador ve el Universo isótropo, otro que se mueva a gran velocidad con respecto a él ya no podrá verlo isótropo. Este segundo observador vería un \textit{desplazamiento Doppler} hacia el azul de las galaxias en la dirección de su movimiento, y verá desplazadas hacia el rojo las galaxias que se alejan de él. Por lo tanto si el principio cosmológico se cumple para el primer observador, no lo haría para el segundo.

La teoría de la relatividad general permite resolver el problema. Esta teoría establece que en todo punto del espacio, en un sistema cualquiera (no forzosamente el Universo) existe un observador que ve su microentorno plano, en el sentido de que para él no hay gravedad, de que para él se cumplen las leyes de la relatividad restringida. ¿Quién es ese individuo que goza de tan grande privilegio? Es muy sencillo: cualquiera puede adquirir ese título de observador inimaginable dejando de lado a la gravedad.

En uno de los experimentos mentales de Einstein, un observador en un ascensor que cayera libremente no pesaría sobre el suelo del ascensor ni notaría ningún efecto gravitatorio. Por eso, a dichos observadores privilegiados se les puede llamar \textit{observadores cayentes}. Para ellos se cumple el principio cosmológico. En cuanto al Universo, estos observadores cayentes se les llama \textit{observadores fundamentales}.

Otra precisión importante para entender el principio cosmológico es la de \textit{tiempo cósmico}. La teoría de la relatividad dice que cada observador tiene su tiempo. Por tanto, podría pensarse que no todos los observadores fundamentales tienen el mismo tiempo. El principio cosmológico equivale a decir que sí, que todos los observadores fundamentales pueden tener el mismo tiempo. Todos los observadores ven el mismo Universo si lo hacen en ese tiempo común a todos ellos. Este tiempo común se le conoce como \textit{tiempo cósmico}. El principio cosmológico, para atenerse a las premisas relativistas, debe entenderse así: \textit{todos los observadores fundamentales ven lo mismo cuando utilizan ese tiempo cósmico común a todos ellos} \cite{1.02}.

%-----------------------------------------------------------------------------%

\section{La Expansión del Universo}
La década de 1920 tuvo uno de los descubrimientos más impresionantes en el área de la física. Edwin Hubble combinó medidas de distancias de galaxias a partir del corrimiento al rojo al alejamiento relativo entre ellas según el Efecto Doppler y  descubrió que cuanto más se aleja una galaxia, mayor es su desplazamiento hacia el rojo, esta relación fue una prueba de que el Universo estaba en expansión. La \textit{ley de Hubble} \cite{1.1} establece que la velocidad ``aparente'' $\vec{v}$ de alejamiento entre galaxias es porporcional a su distancia $\vec{r}$, esto es
\begin{equation}
\vec{v} = H\vec{r}.\label{eqn 1.1}
\end{equation}
Las tres cantidades de la ecuación cambian con el tiempo, por lo que se escriben como funciones $\vec{v}(t), H(t), \vec{r}(t)$. Para ser precisos $\vec{r}(t)$ es la \textit{distancia propia}, esto es, la distancia que sería medida entre una galaxia y nosotros en un tiempo $t$. La velocidad de recesión $\vec{v}$ es el ritmo al cual $\vec{r}$ incrementa, y $H$, el \textit{parámetro de Hubble}, es constante en todo el espacio debido a la homogeneidad. Muchas teorías predicen que cambia con el tiempo, $H = H(t)$. En cosmología se le da al valor de la época actual el subíndice cero. Así el parámetro de Hubble al día de hoy, a un tiempo $t= t_{0}$ es $H(t_{0})= H_{0}$. A esta cantidad se le conoce como \textit{constante de Hubble}.

Para dar un poco más de claridad, es de gran utilidad introducir las llamadas \textit{coordenadas comóviles}. Un sistema de referencia comóvil de una partícula es un sistema de referencia que se mueve junto con una partícula, y por tanto, respecto a un sistema de referencia comóvil una partícula siempre está en reposo. Las coordenadas comóviles se expanden junto con el Universo. Si nuestra galaxia tiene una coordenada comóvil $\vec{x}=0$ y otra galaxia tiene una coordenada comóvil $\vec{x}$, entonces, la distancia propia hasta ella es
\begin{equation}
\vec{r} = a(t)\vec{x},\label{eqn 1.2}
\end{equation}
donde $a(t)$ es llamado el \textit{factor de escala} que depende del tiempo, no de la posición. Puede definirse ahora la velocidad $\vec{v}$ como 
\begin{equation}
\vec{v} = \dot{\vec{r}} = H\vec{r},\label{eqn 1.3}
\end{equation}
así,
\begin{equation}
\frac{d}{dt}(a\vec{x})= Ha\vec{x}.\label{eqn 1.4}
\end{equation} 
Por definición, la coordenada comóvil no depende del tiempo, por lo que todo el cambio en $(a\vec{x})$ se debe solo al factor de escala $a$. Esto lleva a cancelar $\vec{x}$ de nuestra ecuación (\ref{eqn 1.4}) y se tiene entonces la siguiente expresión para el parámetro de Hubble
\begin{equation}
H(t) = \frac{\dot{a}(t)}{a(t)}.\label{eqn 1.5}
\end{equation}
Por otro lado, la luz de las galaxias y estrellas distantes no es monótona, sino que tiene diferentes características espectrales propias de los átomos de los gases de alrededor de las estrellas. Cuando se examinan las líneas de emisión, se encuentra que están desplazadas hacia el extremo rojo del espectro. Este cambio es por un desplazamiento Doppler y se debe a la expansi\'on del Universo, e indica que esencialmente todas las galaxias se están alejando del observador. Así, el llamado redshift o corrimiento al rojo se define entonces como 
\begin{equation}
 z \equiv \frac{\lambda - \lambda_{0}}{\lambda_{0}}\label{eqn 1.6}
\end{equation}
siendo $\lambda_{0}$ la longitud de onda de una línea espectral de la galaxia y $\lambda$, la longitud de onda de esa misma línea espectral medida en la Tierra. Las velocidades se infieren con una fórmula aproximada tal que
\begin{equation*}
z \approx \frac{v}{c}.
\end{equation*}
En la actualidad, se observan galaxias con corrimiento al rojo mucho mayor que el indicado en la ecuación (\ref{eqn 1.6}). Para entender esto, se requiere un análisis más profundo sobre la naturaleza del mismo. Al considerar un fotón emitido desde una galaxia hacia una galaxia cercana con una distancia propia $dr$ (por cercana entiéndase lo bastante próxima para suponer que la diferencia de velocidades entre las galaxias $dv$ está dada por la fórmula $dv = cz$) entonces el fotón hace su viaje en un tiempo $dt = dr/c$, durante este período, el factor de escala incrementa una pequeña cantidad $da = \dot{a} dt$. La velocidad relativa entre las galaxias es entonces
\begin{equation}
d\vec{v}=Hd\vec{r}=\frac{\dot{a}}{a}cdt=c\frac{da}{a}.\label{eqn 1.7}
\end{equation}
El pequeño cambio en la longitud de onda se escribe como $ \lambda - \lambda_{0} = d\lambda$; sustituyendo esto y la fórmula de velocidad-redshift, se obtiene
\begin{equation}
c\frac{da}{a}=d\vec{v}=cz=c\frac{d\lambda}{\lambda}.\label{eqn 1.8}
\end{equation}
Esto es, en el pequeño intervalo de tiempo $dt$, el cambio fraccional en la longitud de onda es la misma que el crecimiento fraccional en el Universo. Ahora, suponga que el fotón rebasa a la segunda galaxia y viaja un largo camino a través del Universo antes de ser detectado en una tercera galaxia (la Vía Láctea, por ejemplo). La misma formulación de las ecuaciones (\ref{eqn 1.7}) y (\ref{eqn 1.8}) puede hacerse para cualquier segmento pequeño de su camino, la longitud de onda y el factor de escala seguirán siendo proporcionales $\lambda \propto a$, es decir
\begin{equation}
\frac{\lambda}{\lambda_{0}}= \frac{t_{0}}{t_{em}}.\label{eqn 1.9}
\end{equation}
¡El fotón se expande en la misma proporción que lo hace el Universo! El significado profundo del corrimiento al rojo cosmológico escrito como
\begin{equation}
z = \frac{\lambda}{\lambda_{0}} - 1\label{eqn 1.10}
\end{equation} 
es que $(1+z)$ indica cuánto se ha expandido el Universo desde que la luz fue emitida. Aunque se hizo uso del efecto Doppler en el argumento, el resultado de añadir todos los efectos infinitesimales es muy diferente al de uno muy grande. Por ejemplo, el corrimiento al rojo no depende de la velocidad $v(t)$, ni en el presente $t_{0}$ ni en la época de emisión $(t_{em})$. Para comprobarlo, suponga que el Universo no estuvo expandiéndose cuando el fotón fue emitido, i.e. $H(t_{em}=0)$, así, $\vec{v}(t_{em})=0$. El Universo empieza su expansión, pero se detiene nuevamente antes de que el fotón llegue a su destino, es decir $\vec{v}(t_{0})=0$. El fotón aún tendría un corrimiento al rojo porque la expansión ocurrió mientras estaba en movimiento.

Todo esto indica que altos corrimientos de galaxias distantes no necesariamente implica que las velocidades de recesión son mayores a la velocidad de la luz. Como se esperaría, la ecuación $cz = H\vec{r}$ es sólo válida para corrimientos pequeños. Examinando nuevamente la ecuación (\ref{eqn 1.1}), que como se puntualizó, siempre es cierta para \textit{cualquier} separación, entonces si un observador fuese suficientemente lejos, $\vec{v}$ sería más rápida que la velocidad de la luz. Los fotones emitidos desde esa distancia no lo alcazarían, a menos que el Universo empezara a desacelerar en algún tiempo en el futuro. Esto supone un problema, ya que el observador no podría ser capaz de observar los fotones emitidos desde la galaxia hace miles de millones de años.

Algunos cosmólogos trataron de evitar esta conclusión diciendo que el valor del incremento en la distancia propia no es una velocidad ``real'' \cite{1.1.01}; argumentan que es el espacio entre las galaxias el que se está expandiendo, mientras las galaxias están más o menos en reposo \cite{1.1.02}. En efecto, esta aproximación prefiere distancia comóvil a distancia propia. A veces es útil pensar de esta manera, pero no hay diferencia, almenos físicamente entre dos galaxias ``realmente'' separándose unas de otras y dos galaxias estacionarias con la intervención de la expansión del espacio. Ambas son descripciones equivalentes de la Relatividad General.

%----------------------%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%-----------------------------------------------------------%
\subsection*{Ecuaciones de Einstein}

La Relatividad General está conformada esencialmente por 10 ecuaciones diferenciales parciales no lineales y acopladas, las cuales rigen la física de los sistemas gravitacionales. Para trabajar en el marco de la relatividad general, se inicia introduciendo una variedad 4--dimensional con vectores base $e_{\mu}$, dotada de una métrica (espacio pseudo--riemanniano) de la forma
\begin{equation}
ds^{2}=g_{\alpha \beta}dx^{\alpha}dx^{\beta},\label{eqn 1.11}
\end{equation}
la cual definirá los símbolos de Christoffel $\Gamma^{\alpha}_{\mu \nu}$, los cuales describen la variación de los vectores de una base $e_{\mu}$. Es decir, la derivada covariante del vector de la base $e_{\mu}$ a lo largo del vector de la base $e_{\nu}$, es un nuevo vector de componentes $\nabla_{e_{\nu}}e_{\mu}$ = $\Gamma^{\alpha}_{\mu \nu} e_{\alpha}$. En una variedad con una métrica definida, los símbolos de Christoffel se determinan completamente a partir de la métrica $g_{\alpha \beta}$ \cite{1.4} como

\begin{equation*}
\Gamma^{\alpha}_{\mu \nu} = 
\frac{1}{2}g^{\alpha \beta}\left(\partial_{\mu}g_{\nu \beta} +
\partial_{\nu}g_{\mu \beta} - \partial_{\beta}g_{\mu \nu}\right), 
\end{equation*}

a partir de los cuales se define el tensor de Riemann $R^{\alpha}_{\beta \mu \nu}$

\begin{equation*}
R^{\alpha}_{\beta \mu \nu}
=
\partial_{\mu}\Gamma^{\alpha}_{\beta \nu}
-
\partial_{\nu}\Gamma^{\alpha}_{\beta \mu}
+
\Gamma^{\rho}_{\beta \nu}\Gamma^{\alpha}_{\rho \mu}
-
\Gamma^{\rho}_{\beta \mu}\Gamma^{\alpha}_{\rho \nu},
\end{equation*}
así como el tensor de curvatura y el escalar de curvatura de Ricci que son contracciones del tensor de Riemann y que respectivamente están dados por
\begin{equation*}
R_{\mu \nu} = \sum_{\alpha}R^{\alpha}_{\mu \alpha \nu},
\end{equation*}
\begin{equation*}
R = \sum_{\mu \nu}g^{\mu \nu}R_{\mu \nu}.
\end{equation*}
Las ecuaciones de Einstein determinan las características del espacio--tiempo definido por la métrica
\begin{equation}
R_{\alpha \beta} - \frac{1}{2} R g_{\alpha \beta} + \Lambda g_{\alpha \beta} = 0,\label{eqn 1.12}
\end{equation}
donde $R_{\alpha \beta}$ es el tensor de Ricci, $R$ es el escalar de curvatura de Ricci, $g_{\alpha \beta}$ es el tensor métrico y $\Lambda$ es la constante cosmológica. En presencia de materia y energía, las ecuaciones de campo de Einstein se convierten en 
\begin{equation}
R_{\alpha \beta} - \frac{1}{2} R g_{\alpha \beta} + \Lambda g_{\alpha \beta} = \kappa T_{\alpha \beta}\label{eqn 1.13}
\end{equation}
donde $T_{\alpha \beta}$ es el tensor de energía-momento y $\kappa$ es una constante, cuyo valor es $\kappa = 8 \pi G / c^{4}$.

%---------%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%-%%%%%%%%%%%-------------------------------------------------------
%%%%%%%%%%%------------------------------------------------------------------%

\subsection*{Métrica de Friedmann-Lemaître-Robertson-Walker}
Basados en la suposición de homogeneidad e isotropía, las ecuaciones de movimiento del Universo se pueden deducir de la siguiente forma. Sean dos eventos en el espacio--tiempo, uno ocurriendo en el punto localizado en $(t,r,\theta , \phi)$ y otro ocurriendo en el punto localizado en $(t +dt, r + dr, \theta + d\theta, \phi + d\phi)$. La separación espacio-temporal entre estos dos eventos es
\begin{equation}
ds^{2}=-c^{2}dt^{2} + dr^{2} +r^{2}d\Omega^{2},\label{eqn 1.14}
\end{equation}
donde
\begin{equation*}
d\Omega^{2} \equiv d\theta^{2} + \sin^{2}\theta d\phi^{2}.
\end{equation*}
La métrica descrita por la ecuación (\ref{eqn 1.14}) es llamada \textit{métrica de Minkowski}, y el espacio--tiempo que ella describe es el de Minkowski. De la teoría de la relatividad general se sabe que el camino que describe un fotón en un espacio-tiempo es una \textit{geodésica} y que para cualquier espacio--tiempo, ésta debe ser \textit{nula}, es decir $ds=0$. En un espacio--tiempo de Minkowski, la trayectoria de un fotón obedece la relación
\begin{equation}
ds^{2}=0 = -c^{2}dt^{2} + dr^{2} +r^{2}\Omega^{2}.\label{eqn 1.15}
\end{equation}
Si el fotón se mueve de forma radial alejándose del origen, lo que significa que $\theta$ y $\phi$ son constantes, entonces
\begin{equation}
c^{2}dt^{2}=dr^{2},\label{eqn 1.16}
\end{equation}
es decir
\begin{equation}
\frac{dr}{dt}=\pm c. \label{eqn 1.17}
\end{equation}
La métrica de Minkowski dada por la ecuación (\ref{eqn 1.14}) aplica solamente dentro del contexto de la relatividad especial, sin efectos gravitacionales, el resultado será una  métrica que es plana. Al añadir la gravedad, sin embargo, el espacio--tiempo toma una forma más interesante. En la década de 1930 los físicos Howard Robertson y Arthur Walker llegaron a un resultado, de manera independiente, que se conoció como la \textit{métrica de Robertson--Walker} y cuya forma es generalmente conocida como
\begin{equation}
ds^{2}
=
-c^{2}dt^{2} + a^{2}(t)
\left[
\frac{dr^{2}}{1-k r^{2}} + r^{2}d\Omega^{2}
\right],\label{eqn 1.18}
\end{equation}
donde $k > 0$, $k = 0$ o $k < 0$. Todos los modelos homogéneos e isótropos tienen esta forma. Para $k > 0$ se tiene un espacio--tiempo con curvatura positiva y se llaman modelos \textit{cerrados}. Para $k = 0$ se tiene un espacio--tiempo Euclideano o \textit{plano}. Por último, para $k < 0$ se tiene un espacio--tiempo con curvatura negativa y a estos modelos se les llama \textit{abiertos} (Figura \ref{Fig. 1.02}).


A escalas pequeñas, sin embargo, se ha observado que el Universo \textit{no} es homogéneo. Por lo que la métrica de Robertson--Walker es sólo una aproximación que es buena para escalas mayores. En un sentido cosmológico, las ecuaciones de Einstein pueden usarse para encontrar una relación entre el factor de escala $a(t)$, la curvatura $\kappa$, y los contenidos de densidad de energía $\epsilon(t)$ y presión $p(t)$ del Universo. Las ecuaciones que hacen esto posible son las \textit{Ecuaciones de Friedmann}, encontradas por Alexander Alexandrovich Friedmann en 1922, sorprendentemente 7 años antes de los trabajos publicados por Hubble y en ellas ya consideraba que un Universo homogéneo e isótropo se expandía como función del tiempo. 

\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{./Figuras/geometry}
\caption{\footnotesize{Geometría del espacio--tiempo según el tipo de curvatura.}}\label{Fig. 1.02}
\end{figure}

Recordando la ley de Hubble (\ref{eqn 1.1}) la ecuación de Friedmann puede escribirse de la siguiente manera
\begin{equation}
H^{2}(t) = \frac{8 \pi G}{3}\rho(t) 
-\frac{k c^{2}}{a^{2}(t)},\label{eqn 1.19}
\end{equation}
con $H(t) \equiv \dot{a}/a$.

En la época actual, el valor del parámetro de Hubble es
\begin{equation}
H_{0} = H(t_{0}) = \left(\frac{\dot{a}}{a}\right) 
_{t=t_{0}} = 70 \pm 7 \textup{km s}^{-1} \textup{Mpc}^{-1},\label{eqn 1.20}
\end{equation}
a esta cantidad $H_{0}$ se le conoce como constante de Hubble. Así, la ecuación de Friedmann en la época actual es $(a(t) = 1)$ 
\begin{equation}
H_{0}^{2} = \frac{8 \pi G}{3}\rho_{0} 
-k c^{2}. \label{eqn 1.21}
\end{equation}
La expresión anterior ofrece una relación entre $H_{0}$, la cual dice la rapidez de expansión, $\epsilon_{0}$, la densidad de energía actual, y $\kappa$, que indica la curvatura actual. Esta ecuación es válida para todo Universo con una métrica de Robertson--Walker gobernada por las reglas de la relatividad general. En un Universo plano $(k = 0)$ la ecuación de Friedmann se reduce a
\begin{equation}
H^{2}(t)=\frac{8 \pi G}{3}\rho(t).\label{eqn 1.22}
\end{equation}
Así, para un valor dado del parámetro de Hubble, existe una \textit{densidad de energía crítica} dada por
\begin{equation}
\epsilon_{c}(t) \equiv \frac{3 c^{2}}{8 \pi G} H^{2}(t).\label{eqn 1.23}
\end{equation}
Si la densidad de energía $\epsilon(t)$ es mayor a este valor, el Universo tiene curvatura positiva $(k = +1)$. Si $\epsilon(t)$ es menor a este valor, el Universo tiene curvatura negativa. Dado que se tiene un valor actual del parámetro de Hubble, se puede calcular la densidad crítica directamente de (\ref{eqn 1.23})
\begin{equation}
\epsilon_{c,0} = \frac{3 c^{2}}{8 \pi G}H_{0}^{2}
=
(8.3 \pm 1.7) \times 10^{-10} \textup{J m} ^{-3}
=
5200 \pm 1000 \textup{MeV m} ^{-3},\label{eqn 1.24}
\end{equation}
que suele escribirse de manera más común en términos de la \textit{densidad de masa crítica} como
\begin{equation}
\rho_{c,0} \equiv \epsilon_{c,0}/c^{2}
=
(9.2 \pm 1.8) \times 10^{-27} \textup{kg m}^{-3}
=
(1.4 \pm 0.3) \times 10^{11} \textup{M}_{\odot} \textup{Mpc}^{-3},\label{eqn 1.25}
\end{equation}
donde $M_{\odot}$ denota una cantidad conocida como \textit{Masa solar} y su valor es $M_{\odot} = 1.989 \times 10^{30}$kg. Se ha supuesto, basados en el principio cosmológico, que el Universo es homogéneo e isótropo. Para resolver las ecuaciones de campo de Einstein bajo esa suposición se requiere un tensor de energía--momento que sea también homogéneo e isótropo. La forma más general para tal tensor es la de un tensor para un fluido perfecto, que se escribe como \cite{1.2, 1.3}
\begin{equation}
T_{\alpha \beta} =
(\rho + p)u_{\alpha}u_{\beta} + pg_{\alpha \beta},\label{eqn 1.26}
\end{equation}
donde $\rho$ es la densidad de masa propia del fluido, $u_{\mu}$ es la cuadrivelocidad y $p$ es la presión $(p > 0)$ o la tensión $(p < 0)$. La homogeneidad implica que la presión y la densidad deberían ser independientes de la posición y sólo deberían depender del tiempo. Para la métrica descrita en la ecuación (\ref{eqn 1.18}), este tensor es diagonal 
\begin{equation}
T_{\alpha \beta} = \textup{diag}(-\rho, p, p, p).\label{eqn 1.27}
\end{equation}
Insertando este resultado en las ecuaciones de campo de Einstein (\ref{eqn 1.13}), tomando además $\Lambda = 0$ y normalizando $(c = 1)$ se tiene que\\\\
\begin{equation*}
 3\frac{\dot{a}^{2} + k}{a^{2}}  = 8 \pi G \rho
 \end{equation*}
\begin{equation} 
-2\frac{\ddot{a}}{a} - \frac{\dot{a}^{2} + k}{a^{2}}= 8 \pi G p.\label{eqn 1.28}
\end{equation}\\\\
Esta es otra forma de escribir las ecuaciones de Friedmann, sin la constante cosmológica. Al combinar ambas ecuaciones se tiene
\begin{equation}
\frac{\ddot{a}}{a} = -\frac{4 \pi G}{3}(\rho + 3p), \label{eqn 1.29}
\end{equation}
donde la energía gravitacional efectiva viene dada por $(\rho + 3p)$, de donde se observa que la presión también contribuye a la gravitación. Se puede deducir también una ecuación que relacione a la energía, la presión y el factor de escala. Usando la conservación de la energía, al diferenciar la ecuación (\ref{eqn 1.28}) conduce a la expresión siguiente
\begin{equation}
\dot{\rho} + 3\frac{\dot{a}}{a}(\rho + p) = 0,\label{eqn 1.30}
\end{equation}
que puede reescribirse como
\begin{equation}
\frac{d}{dt} (\rho a^{3}) + p\frac{d}{dt}a^{3} = 0.\label{eqn 1.31}
\end{equation}
Considerando un volumen comóvil $V = a^{3}$ e interpretando $\rho a^{3} = U$ como la energía en el volumen comóvil, se obtiene que
\begin{equation}
dU + pdV = 0. \label{eqn 1.32}
\end{equation}
Recordando que la primera ley de la termodinámica, establece que para un fluido en equilibrio se cumple la relación
\begin{equation}
TdS = dU +pdV, \label{eqn 1.33}
\end{equation}
donde $T$ es la temperatura y $S$ es la entropía del fluido. Un proceso en el cual el cambio en la entropía es $dS = 0$ es llamado \textit{adiabático}. La ecuación (\ref{eqn 1.32}) muestra que el modelo homogéneo e isotrópico se expande de forma adiabática. Esto no es extraño ya que la propia homogeneidad e isotropía implican que no haya gradientes de temperatura y no haya flujo de calor.

Si además se asume que el fluido perfecto obedece la ecuación de estado barotrópica, es decir, que la presión sea proporcional a la densidad
\begin{equation}
p = w\rho, \label{eqn 1.34}
\end{equation}
la ecuación (\ref{eqn 1.31}) se reescribe como sigue
\begin{equation}
\frac{d}{dt}(\rho a^{3}) + w p \frac{d}{dt} a^{3} = 0,\label{eqn 1.35}
\end{equation}
cuya solución es
\begin{equation}
\rho a^{3(w + 1)} = \rho _{0}, \label{eqn 1.36}
\end{equation}
donde $\rho _{0}$ es el valor de la densidad en la época presente. De esta forma, $w$ puede tomar diferentes valores que dependen de la época en la cual se esté considerando, esto es, existe una única presión para cada densidad dependiendo de la época:
\begin{itemize}
\item Época actual (polvo) $\rightarrow$ $p=0$.
\item Época dominada por la radiación $\rightarrow$ $p = 1/3 \rho$.
\end{itemize}
Las ecuaciones de Friedmann (\ref{eqn 1.28}) para un Universo dominado por un fluido perfecto con ecuación de estado dada por (\ref{eqn 1.34}) pueden escribirse entonces como
\begin{equation}
\left(\frac{\dot{a}}{a}\right)^{2}
=
\frac{8 \pi G}{3} \frac{\rho _{0}}{a^{3(w + 1)}} - \frac{k}{a^{2}}.\label{eqn 1.37}
\end{equation}
Si $w > -1/3$ esta última ecuación indica que la evolución y posible destino del Universo dependerá de la curvatura espacial. Un Universo plano y uno con curvatura negativa se expanderán indefinidamente, mientras que un Universo con curvatura positiva detendrá su expansión y empezará a contraerse en algún punto. Si $w < -1/3$ la expansión seguirá para cualquier tiempo independientemente de la curvatura. Y el caso límite $w = - 1/3$, representa un Universo con velocidad de expansión $\dot{a}$ constante (Figura \ref{fig 1.1}).
\begin{figure}
\centering
    \includegraphics[width=0.6\textwidth]{./Figuras/ScaleFactor}
  \caption{\footnotesize{El factor de escala cosmológico $a(t)$ para modelos de Universo abierto $(k = -1)$, plano $(k = 0)$ y cerrado $(k = 1)$.}}
  \label{fig 1.1}
\end{figure}
Las ecuaciones de Friedmann  (\ref{eqn 1.28}) se pueden expresar de una forma más general en términos de la densidad relativa a la densidad crítica. La densidad crítica se denota como $\Omega$ y se le llama \textit{parámetro de densidad} o \textit{densidad relativa}, es decir
\begin{equation}
\Omega \equiv \frac{\rho}{\rho_{c}},\label{eqn 1.38}
\end{equation}
además se puede definir un parámetro de curvatura espacial dado por
\begin{equation}
\Omega_{k} \equiv -\frac{k}{H^{2}a^{2}}.\label{eqn 1.39}
\end{equation}
Insertando estos valores en la ecuación de Friedmann (\ref{eqn 1.28}) se tiene lo siguiente
\begin{equation}
\Omega + \Omega_{k} = 1\label{eqn 1.40}
\end{equation}
donde $\Omega$ es la densidad total relativa de energía y materia. Dado que para un modelo de Universo abierto, $\Omega_{k} < 0$, un modelo plano $\Omega_{k} = 0 $ y un modelo cerrado $\Omega_{k} > 0$, se tienen entonces los siguientes valores para $\Omega$
\begin{equation}
\Omega  \left\lbrace
\begin{array}{ll}
> 1, & \textup{para} \; k > 0, \\
= 1, & \textup{para} \; k = 0, \\
< 1, & \textup{para} \; k < 0.  \label{eqn 1.41}
\end{array}
\right.
\end{equation}
Las ecuaciones de Friedmann describen la cantidad de materia contenida en el Universo y determinan su geometría. En las siguientes secciones se describirán un par de modelos que utilizan estos parámetros para estudiar estas propiedades.
%---------------------------------------------------------------------------------%
\section{Modelos de Evolución Cosmológica}
El primer intento de aplicar la relatividad al Universo se debió al propio Einstein. Aunque con este primer intento se llegaba a la ``absurda'' conclusión de que el Universo estaba en expansión (o bien en contracción, que es una expansión negativa). Para conseguir un Universo estático, Einstein admitió el llamado \textit{término cosmológico} o \textit{constante cosmológica}, lo que hoy se interpretaría como una forma de energía oscura. Este término le daba al Universo una facultad expansiva que contrarrestaba la autogravitación de todo el Universo, evitando la coalescencia y consiguiendo una situación estática. Lo más novedoso de aquella deducción era que, al contrario de la gravitación newtoniana, que era generada por la masa, esta fuerza expansiva del término cosmológico era generada por el vacío, y quizá como consecuencia, constante en el tiempo.

La necesidad de crear estos modelos de evolución fue precisamente la detección de un tipo de materia ``faltante'' en el Universo. Para la década de 1930, el astrofísico Fritz Zwicky \cite{1.1.1} examinó la dinámica interna del cúmmulo de galaxias Coma Berenice. En dicha publicación, Zwicky proporciona evidencia de que la masa luminosa en el cúmulo era mucho menor que el total de masa  necesaria para mantener a estas galaxias unidas gravitacionalmente. Debía existir otro tipo de materia que permitiera que este conjunto de galaxias se mantuviese unido. En esa época ya se tenían los primeros indicios de la \textit{materia oscura}.

A pesar de numerosas contribuciones de la comunidad científica, el tema de la materia oscura no fue considerado seriamente hasta la época de 1970, cuando la astrónoma Vera Cooper Rubin \cite{1.1.2} indicó que la estabilidad gravitacional de las galaxias es debido a una cantidad de masa mayor a la observada. En su trabajo, calcula las curvas de rotación de distintas galaxias espirales, las cuales miden la velocidad radial de las estrellas dentro de las galaxias en función de su distancia hacia el centro de las mismas, como se observa en la siguiente ecuación
\begin{equation}
v (r)
=
\sqrt{\frac{G M (r)}{r}}.\label{eqn 1.42}
\end{equation} 
\begin{figure}
\centering
    \includegraphics[width=0.6\textwidth]{./Figuras/M33Rotation}
  \caption{\footnotesize{Curva de rotación de la galaxia M33 (Triangulum). Se observa una discrepancia entre la medición real y el cálculo usando las leyes newtonianas.}}
  \label{fig 1.2}
\end{figure}
De acuerdo a las leyes de Newton, se esperaría que dicho movimiento tuviese un comportamiento Kepleriano, es decir, que la velocidad de las estrellas fuese decayendo conforme la distancia era mayor hacia el centro. La gran sorpresa sobre estas observaciones fue que esta curva no obedecía el comportamiento Kepleriano, si no que la velocidad de las estrellas permanecía casi constante e incluso, en algunos casos, aumentaba (Figura \ref{fig 1.2}). Si la teoría de Newton era correcta, entonces lo que hacía falta era materia para poder explicar este extraño comportamiento. Esto fue un gran impacto para la física y la astronomía, ya que esta evidencia conlleva a crear modelos que incluyan esta \textit{materia oscura} en las galaxias y, por tanto también en el Universo.

%---------------------------------------------------------------------------------%
\subsection*{Radiación del Fondo Cósmico de Microondas}
Otro fenómeno importante para el desarrollo de los modelos de evolución es la \textit{Radiación del Fondo Cósmico de Microondas} o por sus siglas en inglés \textit{Cosmic Microwave Background} (CMB). El CMB es un tipo de radiación de alrededor de 380,000 años después del comienzo del Universo. Antes de este tiempo, el Universo era tan caliente y denso que era opaco para toda la radiación. Ni siquiera los átomos simples podrían formarse sin ser instantáneamente desgarrados en sus protones y electrones constituyentes por la radiación intensa. El Universo estaba hecho de un tipo de``plasma", o gas ionizado.

Esta radiación fue detectada por primera vez por Arno Penzias y Robert Wilson \cite{1.1.2.1} en 1965 y es una de las pruebas más contundentes a favor del Big Bang. En particular, la teoría del Big Bang predice ciertas características para la radiación en épocas primitivas que han sido confirmadas por el CMB:

\begin{enumerate}
\item La dispersión múltiple de fotones por un plasma caliente en el Universo temprano debería dar como resultado un espectro de cuerpo negro para los fotones una vez que han escapado en la época de reionización. Esto es exactamente lo que se observa para el CMB.
\item Los fotones del CMB se emitieron en la época de recombinación cuando el Universo tenía una temperatura de aproximadamente 3.000 Kelvin. Sin embargo, han sido desplazados cosmológicamente hacia el rojo a longitudes de onda más largas durante su viaje en un Universo en expansión, y ahora se detectan en la región de microondas del espectro electromagnético a una temperatura promedio de 2.725 K. Esto está de acuerdo con lo que predice la teoría del Big Bang. 
\end{enumerate}
\begin{figure}
\centering
  \includegraphics[width=0.5\textwidth]{./Figuras/SpectrumCMB}
  \caption{\footnotesize{Espectro de radiación del CMB medido por el satélite COBE.}}
  \label{fig 1.3}
\end{figure}
En la década de 1990, el satélite COBE midió el CMB  y ayudó a establecer varias cosas. En primer lugar, el CMB es casi completamente uniforme, con una temperatura casi constante. El que no sea constante es debido a que hubo pequeñas fluctuaciones en la temperatura, al nivel de una sola parte en 100,000. 

En las últimas dos décadas, muchos experimentos han medido las pequeñas fluctuaciones de CMB, tales como WMAP en 2007 \cite{1.1.3} . Estas fluctuaciones están ahí debido a variaciones en la densidad del Universo inmediatamente después del Big Bang. Cualquier región que sea ligeramente más densa tiende a atraer más materia, lo que hace que se vuelva aún más densa, atrayendo más material. Este proceso fuera de control es lo que llevó a la formación de las primeras estrellas y galaxias. Las propiedades de las fluctuaciones se han utilizado para ayudar a determinar la edad del Universo, de qué está hecho e incluso cómo podría terminar. En el año 2013 la misión Planck \cite{1.1.4} proporcionó la imagen más detallada hasta ahora del Universo a solo 380,000 años después del Big Bang.
\begin{figure}
\centering
  \includegraphics[width=0.5\textwidth]{./Figuras/cmb1}
  \caption{\footnotesize{Comparación del CMB medido por las misiones COBE (1992), WMAP (2003) y Planck (2013).}}
  \label{fig 1.4}
\end{figure}


%---------------------------------------------------------------------------------%



\subsection{Lambda Cold Dark Matter ($\Lambda$CDM)}
Aunque la primera evidencia de materia oscura fue deducida en la década de 1930, no fue hasta la década de 1980 que los astrónomos y físicos predijeron que la materia oscura es necesaria para explicar la dinámica de las galaxias y los cúmulos de galaxias de manera gravitacional.

El modelo \textit{Lambda Cold Dark Matter} ($\Lambda$CDM) es una parametrización del modelo del Big Bang Cosmológico. Su aceptación ha sido tal que ha llegado a ser denominado  el ``modelo estándar de la cosmología'' y se  fundamenta principalmente, sobre las siguientes bases teóricas y experimentales. 
\begin{enumerate}
\item Un marco teórico basado en la teoría general de la relatividad, que proporciona la teoría del campo gravitatorio en escalas cosmológicas.
\item El principio cosmológico. Requisito indispensable para cualquier modelo cosmológico.
\item El modelo de fluidos, que considera a las galaxias como constituyentes básicos del Universo, las incluye en la teoría mediante la ecuación de fluido (ecuación (\ref{eqn 1.31})).
\item La Ley de Hubble, que establece la expansión del Universo con una velocidad de recesión de las galaxias proporcional a su distancia.
\item La Radiación del Fondo Cósmico de Microondas. Los resultados del CMB coinciden con el principio cosmológico.
\item La concordancia de los distintos métodos de estimación de la edad del Universo \cite{1.1.5}. 
\item La determinación de la abundancia relativa de elementos primigenios $^{1}$H, $^{2}$D, $^{3}$He, $^{4}$He y $^{7}$Li formados en las reacciones nucleares en la época de Big Bang Nucleosíntesis (BBN) \cite{1.1.6, 1.1.7, 1.1.8}.
\item El análisis de la estructura a gran escala del Universo, mediante experimentos como el SDSS \cite{1.1.9}, que atestiguan la homogeneidad y ayudan a la determinación de los distintos parámetros del modelo estándar.

\end{enumerate}

\begin{figure}
\centering
  \includegraphics[width=0.6\textwidth]{./Figuras/sdss}
  \caption{\footnotesize{Mapa tridimensional captado por SDSS de la distribución de galaxias, con la Tierra en el centro. Cada punto indica una galaxia mientras que el color representa la edad de las estrellas en las galaxias, siendo las rojas las estrellas más viejas.}}
  \label{fig 1.5}
\end{figure}

\subsubsection*{Otras características del modelo estándar}
Además de basarse en los anteriores pilares básicos, $\Lambda$CDM incorpora algunas características especiales a fin de explicar la evolución y la estructura actual del Universo:
\begin{itemize}
\item Perturbaciones a la densidad. También conocidas como fluctuaciones de densidad o fluctuaciones cuánticas, son las responsables de la formación de las grandes estructuras del Universo \cite{1.2.3}.

\item La \textit{Inflación} \cite{1.2.1}, una expansión acelerada, propuesta originalmente por Alan Guth, y que explica la planitud y la homogeneidad actuales del Universo.

\item El Hot Big Bang, origen extremadamente caliente que da lugar a BBN.

\item La \textit{constante cosmológica} $\Lambda$, que Einstein introdujo en las ecuaciones de la relatividad general, originalmente para forzar un Universo estático. Hoy, al saber que el Universo está expandiéndose y de forma acelerada, se le denomina \textit{energía del vacío} o \textit{energía oscura} \cite{1.2.2}. Recordando la ecuación (\ref{eqn 1.18}) al introducir el parámetro $\Lambda$ se tiene que
\begin{equation}
H^{2}(t) = \left(\frac{\dot{a}}{a}\right)
= 
\frac{8 \pi G \rho}{3} - \frac{k}{a^{2}} + \frac{\Lambda}{3}.\label{eqn 1.43}
\end{equation}
\item La \textit{materia oscura fría}, Cold Dark Matter (CDM). Un tipo de materia que debe actuar de forma exclusivamente gravitatoria, que es oscura o \textit{transparente} (no interactúa con ningún tipo de materia bariónica o radiación) y que no debe moverse a velocidades relativistas (es fría).


\end{itemize}

\begin{figure}
\centering
  \includegraphics[width=0.6\textwidth]{./Figuras/BBCosmology}
  \caption{\footnotesize{Ilustración de la línea de tiempo que detalla el origen del Universo según la teoría del Big Bang. Se observan diferentes épocas, tales como inflación, formación de estructura y expansión acelerada.}}
  \label{fig 1.6}
\end{figure}



\subsubsection*{Problemas con el modelo}
El modelo $\Lambda$CDM describe satisfactoriamente la expansión acelerada del Universo, explica la radiación del CMB y otorga un marco de referencia dentro del cual es posible entender la homogeneidad e isotropía en el Universo. También describe las características del origen, naturaleza y evolución de las fluctuaciones de densidad que se cree son las responsables de la formación de las galaxias y cúmulos de galaxias además de las estructuras a gran escala en el Universo. Hasta ahora $\Lambda$CDM es consistente con la abundancia de los cúmulos observados en $z \sim 0$, predice un cambio relativamente pequeño en la densidad de número de cúmulos como función del corrimiento al rojo. Lo anterior se debe a que dada la baja densidad de materia, se ha visto escaso crecimiento de estructuras alrededor de $z \sim 1$. El modelo $\Lambda$CDM puede ``forzarse'' a concordar de manera aproximada con la abundancia de cúmulos a escalas pequeñas y con las fluctuaciones del CMB a grandes escalas modificando el espectro de potencias de su forma habitual. Este cambio en el modelo tiene consistencia con las observaciones, ya que el espectro de potencias de $\Lambda$CDM puede normalizarse para así coincidir con el CMB y las observaciones de cúmulos. Pero a medida que las estimaciones de la densidad de materia oscura se hacen más y más precisas, es necesario saber cuál es su composición.

Existen, sin embargo, ciertos problemas con el modelo a escalas más pequeñas, tales como los perfiles CUSP de densidades de halos galácticos, la sobrepoblación de subestructuras predicha por simulaciones de $N$-cuerpos, el problema de la concordancia, entre otros \cite{1.2.03}. Hasta hoy, la naturaleza de la materia oscura en las galaxias y cúmulos de galaxias es una discusión abierta.

\subsubsection*{El problema CUSP-CORE} 
Una de las predicciones fundamentales del modelo $\Lambda$CDM es que la materia oscura debido a su naturaleza autogravitante, colapsa en halos que, en ausencia de efectos causados por materia bariónica, desarrollan un perfil de densidad que aumenta de manera abrupta. Este importante resultado surge de simulaciones de $N$-cuerpos, las cuales serán descritas en el siguiente capítulo. Estas simulaciones mostraron que la distribución de densidad de un halo de materia oscura de cualquier masa es perfectamente descrita por el perfil de densidad Navarro-Frenk-White o $NFW$ (Navarro et al. 1996, 1997 \cite{b1}), independientemente de condiciones iniciales o de parámetros cosmológicos. Se predice que en los halos de materia oscura de las galaxias, la densidad tiene que tener un comportamiento CUSP o ``pico'' central, es decir, que en el bulbo galáctico, la materia oscura debería estar mayormente concentrada. Por ejemplo, la pendiente interna principal de un perfil NFW cumple que la densidad $\rho$ es proporcional al inverso de la distancia $r$ es decir $\rho \propto r^{-1}$, un resultado similar a la pendiente principal externa mostró que la densidad debía ser proporcional a $r^{-3}$. Navarro et al. 1997 \cite{b1} llamaron a esto el ``perfil de densidad universal"  que viene dado por
\begin{equation}
\rho_{NFW}(r)= \frac{\rho_{i}}{(r/R_{s})(1 + r/R_{s})^{2}},\label{eqn 1.44}
\end{equation}
donde $\rho_{i}$ se relaciona a la densidad del Universo en la época del colapso del halo y $R_{s}$ es el radio característico del halo. Simulaciones hechas por Moore et al. 1999 \cite{Moore 1999} mostraron un perfil de densidad incluso más pronunciado, pues encontraron que los halos que ellos simularon pueden ser descritos mejor con el siguiente perfil de densidad
\begin{equation}
\rho_{M99}(r)= \frac{\rho_{i}}{(r/R_{s})^{1.5}(1 + r/R_{s})^{1.5}},\label{eqn 1.45}
\end{equation} 
es decir con una proporción interna de $r^{-1.5}$ y porporción externa de $r^{-3}$. La diferencia entre estos dos resultados indicaba que detalles como la convergencia numérica, condiciones iniciales, análisis o interpretación aún podían ser un reto al definir la pendiente interna.
\begin{figure}{h}
\centering
  \includegraphics[width=0.6\textwidth]{./Figuras/NFW}
  \caption{\footnotesize{Perfiles de densidad de los halos más y menos masivos de una simulación hecha con los modelos $\Lambda$CDM y SCDM (Navarro et al.; 1997). En los paneles superiores, los radios están dados en kpc y las densidades en unidades de $10^{10} M\odot / kpc^{3}$. En el resto, las unidades son arbitrarias.}}
  \label{fig 1.9}
\end{figure}

\begin{figure}
\centering
  \includegraphics[width=0.9\textwidth, height=0.5\textwidth]{./Figuras/CORECUSP}
  \caption{\footnotesize{Perfiles de densidad medidos en Sculptor, Fornax, NGC 2366, entre otras. CDM predice un perfil CUSP. Se observa un perfil CORE en galaxias pequeñas.}}
  \label{fig 1.10}
\end{figure}
  
Pero las mediciones hechas para las curvas de rotación y modelos de galaxias enanas esferoidales predicen una densidad más suave, casi superficial o CORE, es decir que tenga un núcleo de densidad constante en el centro, como si la materia oscura fuera esparcida de manera homogénea en todo el halo galáctico, (Moore, 1994 \cite{b2}). Esta discrepancia es conocida como el problema \textit{CUSP-CORE}.  Para tener una idea de las muchas publicaciones que se han hecho al respecto, Klypin et al. 2001 \cite{1.2.4} derivaron pendientes proporcionales a $r^{-1.5}$ en sus simulaciones. De argumentos de la densidad del espacio-fase, Taylor \& Navarro 2001 \cite{b26} argumentaron que el perfil de densidad debe parecerse al del perfil NFW, pero con convergencia a $r^{-0.75}$ en lugar del valor de $r^{-1}$. Colín et al. 2004 \cite{b27} investigaron halos de baja masa y encontraron que se describían mejor usando perfiles de densidad NFW. Diemand et al. 2005 \cite{b28} encontraron que los halos de CDM tenían perfiles CUSP con pendiente $r^{-1.2}$. 
Muchos estudios suponen que el CUSP central consiste de una región donde la densidad de masa se comporta como una ley de potencias con pendiente constante aunque se ha sugerido que este no tendría que ser el caso (Navarro et al. 2004 \cite{Navarro Hayashi}) dado que no encuentran evidencia de una pendiente que se comporte como una ley de potencias, en cambio, esa pendiente no converge a un solo valor asintótico como se espera.



\subsubsection*{Satélites Faltantes}
Otra serie de observaciones parece estar en contradicción con $\Lambda$CDM. Utilizando simulaciones de alta resolución, Moore et al. 1999 \cite{Moore 1999} y Klypin et al. 2001 \cite{1.2.4} hicieron notar que el número de subhalos masivos predichos por estas simulaciones excede el número observado de satélites luminosos de la Vía Láctea en al menos un orden de magnitud. A esto se le conoce como el problema de los \textit{satélites faltantes}. Este tipo de resultado sigue siendo una discrepancia considerable entre el número de satélites observados en la Vía Láctea y el número predicho por simulaciones de $\Lambda$CDM.

Las simulaciones predicen que una galaxia del tamaño de la Vía Láctea debería tener alrededor de 10 veces más galaxias satélites que las que se observan. Lo mismo sucede para galaxias de mayor tamaño. Así que, ¿Cuáles son las posibles soluciones?
\begin{enumerate}
\item La física involucrada falla en distintas escalas: Las simulaciones numéricas permiten recrear distintos sistemas físicos, astrofísicos y cosmológicos. Las escalas involucradas difieren en el tipo de aproximación que se esté utilizando, por ejemplo, para simular la evolución cosmológica a gran escala ($>100$ Mpc), la interacción gravitacional puede aproximarse de manera lineal, sin embargo, en escalas galácticas $\mathcal{O}(\textup{Mpc})$, la interacción gravitacional ya no es lineal y  debe involucrarse entonces teoría de perturbaciones no lineal para aproximar efectos gravitacionales \cite{1.2.5}.

\item La potencia observacional es limitada: La sensibilidad en telescopios y otros instrumentos de medición puede ser poco sensible a la luz emitida por galaxias satélites y a otros efectos que pueden provenir de halos pequeños de materia oscura, tales como el \textit{lensing gravitacional}. Existen publicaciones recientes sobre que, en efecto, algunas galaxias satélites predichas por CDM no habían sido observadas porque hasta entonces la tecnología no lo permitía \cite{1.2.6}.
\end{enumerate}

Al ser el modelo estándar de la cosmología, $\Lambda$CDM está siempre bajo escrutinios que puedan confirmar o desmentir dicha teoría. En recientes estudios, se mostró que la galaxia NGC1052-DF2 (Figura \ref{fig 1.11}) tiene poca materia oscura \cite{1.2.6.1}, esto demuestra que la materia oscura no siempre está acoplada a la materia bariónica en escalas galácticas. Lo anterior es un gran reto para CDM, sin embargo, se requiere todavía de un número mayor de observaciones y mejores aproximaciones a simulaciones para tan solo confirmar o descartar este modelo.

Estas discrepancias dentro del modelo estándar pueden ser evidencia de la importancia de procesos físicos en la materia bariónica. Pero también pueden ser indicativos de un nuevo tipo de materia oscura, con propiedades diferentes a las propuestas por $\Lambda$CDM y con la posibilidad de resolver estas dificultades mencionadas.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\

\begin{figure}[htp]
\centering
\includegraphics[width=0.6\textwidth]{./Figuras/NGC1052}
\caption{\footnotesize{La galaxia NGC1052-DF2 es extremadamente difusa, las galaxias a su alrededor son prueba de que esta galaxia tiene poca materia oscura.}}\label{fig 1.11}
\end{figure}

\begin{figure}[hbp]
\centering
 \includegraphics[width=0.7\textwidth, height=0.5\textwidth]{./Figuras/Satellites}
 \caption{\footnotesize{Comparación entre las galaxias del grupo local y una simulación de $\Lambda$CDM.}}
\end{figure}




%\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\



\subsection{Scalar Field Dark Matter (SFDM)}
Con los problemas que presenta el modelo $\Lambda$CDM parece necesario introducir alternativas al paradigma de la formación de estructura en el Universo. Estas son algunas razones por las que deben buscarse propuestas diferentes que puedan explicar las formación de estructura a un nivel cosmológico, la cantidad observada de galaxias enanas y los perfiles de densidad de materia oscura en los núcleos galácticos.
Una propuesta, de la gran cantidad 	que existe \cite{1.3.001}, es la de un campo escalar como materia oscura en el Universo. Este modelo supone que la materia oscura es un campo escalar real o complejo $\Phi$ mínimamente acoplado a la gravedad, dotado de un potencial escalar $V(\Phi)$ y que a cierta temperatura la interacción  del campo es puramente gravitacional junto con el resto de la materia. Este campo escalar puede agregarse al Lagrangiano de las partículas del modelo estándar o al de la relatividad general, suponiendo que la constante de acoplamiento con el resto de la materia sea muy pequeña.

\subsection*{Campo Escalar}
Un campo escalar asocia una cantidad escalar a cualquier punto del espacio. Su valor puede ser un número matemático o una cantidad física. Físicamente un campo escalar representa la distribución espacial de una magnitud escalar. Matemáticamente un campo escalar es una función escalar de las coordenadas.

En la teoría clásica de campos, la dinámica de procesos y fenómenos físicos macroscópicos se representa mediante un campo físico. El concepto de campo abarca los campos de fuerza clásicos, así como la mecánica de medios continuos, es decir, la de sólidos rígidos y deformables, además de líquidos y la propagación de ondas. Normalmente en la teoría clásica de campos se restringe al estudio de campos de fuerza clásica en su tratamiento relativista, es decir: 
\begin{itemize}
\item Campo electromagnético,
\item Campo gravitacional,
\item Campos cuánticos tratados de manera clásica, que ayudan a formular la evolución de campos cuánticos sin interacción entre ellos.
\end{itemize}

Por otro lado la teoría cuántica de campos surgió de la necesidad de cuantizar el campo electromagnético, y con ello describir de forma adecuada los fenómenos cuánticos de la radiación. A esta construcción se le conoce como la electrodinámica cuántica y la partícula asociada con el campo electromagnético es el fotón. Hoy en día todas las partículas elementales son descritas en principio por cuantos de un campo asociado a ellas.

La descripción de un campo escalar libre en la teoría cuántica de campos, está dada por la ecuación de Klein-Gordon. Esta ecuación describe correctamente partículas bosónicas de espín cero. La ecuación se deduce de la siguiente forma utilizando la densidad Lagrangiana y el principio de mínima acción (los detalles pueden ser consultados en el Apéndice \ref{Apend. A})
\begin{equation}
\mathcal{L} = \frac{1}{2}(\hbar^{2}\partial^{\mu}\phi\partial_{\mu}\phi -m^{2}c^{2}\phi^{2}),\label{eqn 1.46}
\end{equation}
donde $\hbar$, $m$ y $c$ son la constante reducida de Planck, la masa del campo y la velocidad de la luz respectivamente. Utilizando el principio de Hamilton y realizando un análisis variacional a esta densidad Lagrangiana se obtiene
\begin{equation*}
\int d^{4}x\delta\mathcal{L}
=
\frac{1}{2} \int d^{4}x\delta(\hbar^{2}\partial^{\mu}\phi\partial_{\mu}\phi -m^{2}c^{2}\phi^{2}) = 0
\end{equation*}\
\begin{equation}
= \frac{1}{2}\int d^{4}x(\hbar^{2}\partial_{\mu}\phi\partial^{\mu}\delta\phi 
+ \partial^{\mu}\phi\partial_{\mu}\delta\phi 
-2m^{2}c^{2}\phi\delta\phi)
= 0.
\label{eqn 1.47}
\end{equation}
Al realizar la integración por partes en el primer término de la ecuación (\ref{eqn 1.47}) se encuentra
\begin{equation}
\int d^{4}x\hbar^{2}\partial_{\mu}\phi\partial^{\mu}\delta\phi 
=
\int d^{4}x\hbar^{2}\partial^{\mu}(\partial_{\mu}\phi\delta\phi)
-
\int d^{4}x\hbar^{2}\partial^{\mu}\partial_{\mu}\phi\delta\phi.\label{eqn 1.48}
\end{equation}
Utilizando el teorema de Stokes en el primer término y considerando que en la frontera la variación se anula, entonces
\begin{equation}
\int d^{4}x\hbar^{2}\partial^{\mu}(\partial_{\mu}\phi\delta\phi)=0.\label{eqn 1.49}
\end{equation}
LLevando a cabo un procedimiento análogo para el segundo término de la ecuación (\ref{eqn 1.47}) se tiene que
\begin{equation*}
\frac{1}{2} \int d^{4}x (-\hbar^{2}\partial_{\mu}\partial^{\mu}\phi\delta\phi
- \hbar^{2}\partial^{\mu}\partial_{\mu}\phi\delta\phi
- 2m^{2}c^{2}\phi\delta\phi)
\end{equation*}
\begin{equation}
= \frac{1}{2} \int d^{4}x (-2\hbar^{2}\partial_{\mu}\partial^{\mu}\phi
- 2m^{2}c^{2}\phi)\delta\phi = 0,\label{eqn 1.50}
\end{equation}
entonces
\begin{equation}
\hbar^{2}\partial_{\mu}\partial^{\mu}\phi + m^{2}c^{2}\phi = 0.\label{eqn 1.51}
\end{equation}
Esta es la ecuación de Klein-Gordon o ecuación de movimiento para campos. Introduciendo el operador d'Alambertiano $\Box$ definido por
\begin{equation}
\Box = \partial_{\mu}\partial^{\mu},\label{eqn 1.52}
\end{equation}
reduciendo el segundo término como $\mu^{2}\equiv\frac{m^{2}c^{2}}{\hbar^{2}}$, la ecuación (\ref{eqn 1.51}) se escribe de la siguiente forma
\begin{equation}
\left(\Box + \mu^{2}\right)\phi = 0,\label{eqn 1.53}
\end{equation}
cuya signatura es $(+,-,-,-)$, si se utiliza la signatura $(- +,+,+)$ aparecerá un signo $-$ antes de $\mu^{2}$.

Muchos autores han propuesto alternativas de interés en las cuales se abordan las dificultades que $\Lambda$CDM no ha podido resolver hasta ahora. En el modelo de Campo Escalar (Guzmán \& Matos, 1999 \cite{Siddhartha Matos}) , se propone que los halos galácticos se forman de condensados de Bose-Einstein de un campo escalar (SF) cuyo bosón tiene una masa ultra ligera del orden de $m \sim 10^{-22}$eV. De este valor se sigue que la temperatura crítica de condensación $T_{c} \sim 1/m^{5/3} \sim $ TeV, es muy alta, por lo tanto, se forman semillas de Condensados de Bose-Einstein (BEC) en épocas tempranas en el Universo. Además, la longitud de Compton $\lambda_{c} = 2\pi \hbar / m$ asociada a este bosón es de $\mathcal{O}(\textup{kpc})$ que corresponde al tamaño de los halos de materia oscura de las galaxias enanas del Universo. Por otra parte, las grandes estructuras del Universo se forman al igual que en el modelo $\Lambda$CDM, por lo que todas las predicciones correctas del modelo estándar se reproducen de buena manera por el modelo SFDM. En este modelo, las partículas escalares con esa masa ultra ligera son tales que sus propiedades ondulatorias evitan el problema del perfil CUSP y reducen el alto número de galaxias satélite por medio del principio de incertidumbre.

La idea del tratamiento de materia oscura como campo escalar se introduce para solucionar dos de los problemas presentes en el modelo estándar cosmológico, el CUSP-CORE y los satélites faltantes. Fue considerada primero por Ji \& Sin 1994 \cite{1.3.01}, y de forma independiente por Guzmán \& Matos 1999 \cite{Siddhartha Matos} y Lee \& Koh 1996 \cite{1.3.02}. Matos \& Guzmán 2000 \cite{1.3.03} sugieren el modelo de materia oscura como campo escalar para formación de halos galácticos. En el modelo de BEC, los halos de materia oscura pueden describirse, en el límite no relativista, como potenciales Newtonianos, hechos de condensados de Bose-Einstein ultra ligeros y con una sola función de onda asociada. Los halos hechos de BEC pueden describirse como un campo escalar $\Phi$ coherente.


\subsection{Descripción Física de SFDM}
\subsubsection{Lagrangiano del campo escalar}
Para efectos de este trabajo, la materia oscura se describe como un campo escalar complejo, el cual es una función continua del espacio y del tiempo definida en cada punto por $\Phi(x^{\mu}) = \Phi(x, y, z, t) $. La acción relativista de este campo escalar viene dada por \cite{1.3.03.1} \begin{equation}
S_{\Phi} = \int d^{4}x\sqrt{\textbf{-} g}\mathcal{L}_{\Phi},\label{1.54}
\end{equation}
donde $\mathcal{L}_{\Phi} = \mathcal{L}_{\Phi}(\Phi, \Phi^{*},\partial_{\mu}\Phi,\partial_{\mu}\Phi^{*})$ es la densidad Lagrangiana y $g= \textup{det}(g_{\mu\nu})$ es el determinante del tensor métrico. La densidad Lagrangiana adopta la siguiente forma
\begin{equation}
\mathcal{L}_{\Phi} = \frac{1}{2}g^{\mu\nu}\partial_{\mu}\Phi^{*}\partial_{\nu}\Phi - V(|\Phi|^{2}),\label{1.55}
\end{equation}
con el potencial escalar dado por la expresión 
\begin{equation}
V(|\Phi|^{2}) = \frac{m^{2}c^{2}}{2\hbar^{2}}|\Phi|^{2} + \frac{m^{2}}{2\hbar^{4}}\lambda|\Phi|^{4},\label{1.56}
\end{equation}
donde el término cuadrático es el término de masa en reposo y el térmico cuártico es una autointeracción. Anteriormente se mencionó que a temperaturas bajas, este campo escalar puede comportarse como un Condensado de Bose-Einstein (BEC), en este estado, todas las partículas estarán en el mismo estado base. En ese caso, la constante de autointeracción $\lambda$ puede escribirse en términos de la longitud de dispersión  de los bosones $a_{s}$ y de su masa $m$ como $\lambda = 4\pi a_{s}\hbar^{2}/m $. El potencial escalar se reescribe entonces como
\begin{equation}
V(|\Phi|^{2}) = \frac{m^{2}c^{2}}{2\hbar^{2}}|\Phi|^{2} + \frac{2\pi a_{s}m}{\hbar^{2}}\lambda|\Phi|^{4}.\label{1.57}
\end{equation}
La autointeracción es repulsiva cuando $a_{s} > 0$ y atractiva cuando $a_{s} < 0$.
\subsubsection{Ecuación de Klein-Gordon}
El campo escalar puede describirse mediante una ecuación de movimiento que se obtiene del principio de mínima acción. Imponiendo que $\delta S_{\Phi}$ = 0 para variaciones arbitrarias de $\delta \Phi$ y $\delta \Phi^{*}$ se obtiene la ecuación de Euler-Lagrange
\begin{equation}
D_{\mu}\left[\frac{\partial\mathcal{L}_{\Phi}}{\partial(\partial_{\mu}\Phi)^{*}}\right] - \frac{\partial\mathcal{L}_{\Phi}}{\partial\Phi^{*}} = 0,\label{1.58}
\end{equation}
donde $D$ es la derivada covariante. Para el Lagrangiano de la ecuación (\ref{1.55}), se obtiene la ecuación de Klein-Gordon
\begin{equation}
\Box\Phi + 2V(|\Phi|^{2}),_{\Phi^{*}} = 0,
\end{equation}
donde el operador d'Alambertiano se define como
\begin{equation}
\Box \equiv D_{\mu}(g^{\mu\nu}\partial_{\nu})
=
\frac{1}{\sqrt{\textbf{-}g}}\partial_{\mu}(\sqrt{\textbf{-}g}g^{\mu\nu}\partial_{\nu}),
\end{equation}
y
\begin{equation}
V(|\Phi|^{2}),_{\Phi^{*}} = \frac{d V}{d |\Phi|^{2}}\Phi.
\end{equation}
Para el caso específico del potencial escalar definido en (\ref{1.57}), la ecuación de Klein-Gordon toma la siguiente forma
\begin{equation}
\Box\Phi + \frac{m^{2}c^{2}}{\hbar^{2}}\Phi + \frac{8\pi a_{s}m}{\hbar^{2}}|\Phi|^{2}\Phi = 0.
\end{equation}
\subsubsection{Tensor de energía-momento}
Al tomar la variación de la acción del campo escalar (\ref{1.54}) con respecto a $g^{\mu\nu}$, se obtiene
\begin{equation}
\delta S_{\Phi} = \frac{1}{2} \int d^{4}x\sqrt{\textbf{-}g}T_{\mu\nu}\delta g^{\mu\nu},
\end{equation}
donde
\begin{equation}
T_{\mu\nu} = 2\frac{\partial\mathcal{L}_{\Phi}}{\partial g^{\mu\nu}} - g_{\mu\nu}\mathcal{L}_{\Phi}
\end{equation}
es el tensor de energía-momento del campo escalar. Para el Lagrangiano (\ref{1.55}), este tensor toma la forma
\begin{equation}
T_{\mu\nu} = \frac{1}{2}(\partial_{\mu}\Phi^{*}\partial_{\nu}\Phi + \partial_{\nu}\Phi^{*}\partial_{\mu}\Phi)
-
g_{\mu\nu}\left[
\frac{1}{2}g^{\rho\sigma}\partial_{\rho}\Phi^{*}\partial_{\sigma}\Phi
-
V(|\Phi|^{2})\right]
\end{equation}
De forma análoga que para el tensor de energía-momento de un fluido perfecto, los tensores de  densidad de energía y presión del campo escalar se definen por $\rho = T^{0}_{0}$ y $P^{i}_{j} = -T^{i}_{j}$.

Para estudiar la dinámica de SFDM en el Universo se utiliza la métrica de Friedmann-Lemaître-Robertson-Walker (FLRW) con factor de escala $a(t)$. El \textit{background} o fondo del Universo se compone de un campo escalar ($\Phi_{0}(t)$) dotado de un potencial escalar $V \equiv V(\Phi_{0})$, radiación ($z$), neutrinos ($\nu$), bariones ($b$) y una constante cosmológica ($\Lambda$) (Magaña et al., 2012 \cite{1.3.02.1}). Al recordar las ecuaciones de FLRW, el tensor de energía-momento T seguirá siendo homogéneo e isótropo para un campo escalar,  en donde ahora la densidad pasa a ser una densidad de energía escalar $T_{0}^{0}$ y la presión, será una presión escalar $T_{j}^{i}$. Estas componentes tendrán la siguiente forma utilizando la signatura ($+,-,-,-$)
\begin{equation}
T_{0}^{0}=-\rho_{\Phi_{0}}=-\left(\frac{1}{2}\dot{\Phi}_{0}^{2} + V \right),\label{eqn 1.54}
\end{equation}
y
\begin{equation}
T_{j}^{i}=P_{\Phi_{0}}=\left(\frac{1}{2} \dot{\Phi}_{0}^{2}-V \right)\delta_{j}^{i},\label{eqn 1.55}
\end{equation}
es importante observar que ambas son el equivalente del tensor de energía-momento para fluidos perfectos, donde el punto se entiende como la derivada respecto al tiempo cosmológico y $\delta_{j}^{i}$ es la delta de Kronecker. Así, la ecuación de sstado para el campo escalar es $p_{\Phi_{0}}=\omega_{\Phi_{0}}\rho_{\Phi_{0}}$ con
\begin{equation}
\omega_{\Phi_{0}} = \frac{\frac{1}{2}\dot{\Phi}_{0}^{2}-V}{\frac{1}{2}\dot{\Phi}_{0}^{2}+V}.\label{eqn 1.56}
\end{equation}
Para simplificar el análisis, resulta conveniente introducir las siguientes variables adimensionales
\begin{equation}
x\equiv \frac{\kappa}{\sqrt{6}}\frac{\Phi_{0}}{H}, \;\;\; u\equiv\frac{\kappa}{\sqrt{3}}\frac{\sqrt{V}}{H}\label{eqn 1.57}
\end{equation}
donde $\kappa^{2}\equiv 8\pi G$ y $H \equiv \dot{a}/a$ es el parámetro de Hubble. El potencial escalar se elige como $V = m^{2}\Phi^{2}/2\hbar^{2} + \lambda\Phi^{4}/4$, y si se toma $c = 1$, para un bosón ultra ligero se tendrá que $\mu_{\Phi} \sim 10^{-22} $eV. Con estas variables, el parámetro de densidad para el fondo $\Omega_{\Phi}$ se escribe como
\begin{equation}
\Omega_{\Phi_{0}}= x^{2}+u^{2},\label{eqn 1.58}
\end{equation}
además, la ecuación de estado del campo escalar toma la forma
\begin{equation}
\omega_{\Phi_{0}}= \frac{x^{2}-u ^{2}}{\Omega_{\Phi_{0}}}.\label{eqn 1.59}
\end{equation}
Dado que $\omega_{\Phi_{0}}$ es una función del tiempo, si su promedio temporal tiende a cero, implicaría que la materia oscura $\Phi^{2}$ se comporta de igual manera que la ecuación de estado para CDM.
\subsubsection{Fondo del Universo: Aproximación Hidrodinámica}
En la llamada aproximación hidrodinámica, se hace una transformación para resolver las ecuaciones de Friedmann de manera analítica con la condición $H<<m$. Se toma el potencial escalar como $V = m^{2}\Phi^{2}/2\hbar^{2} + \lambda\Phi^{4}/4$. Así, para el bosón ultra ligero se tiene que $m \sim 10^{22}$ eV.

El campo escalar, $\Phi_{0}$ se expresa en términos de nuevas variables $S$ y $\rho_{0}$, donde $S$ es una cantidad constante en el fondo del Universo o \textit{background} y $\rho_{0}$ será la densidad de energía del fluido también en esta región, así el campo se expresa como
\begin{equation}
\Phi_{0} = (\psi_{0}e^{-imt/\hbar} + \psi_{0}^{*}e^{imt/\hbar}),\label{eqn 1.60}
\end{equation}
donde
\begin{equation}
\psi_{0}(t) = \sqrt{\rho_{0}(t)}e^{iS/\hbar},\label{eqn 1.61}
\end{equation}
de esta manera, el campo escalar en la región del fondo del Universo se puede expresar como 
\begin{equation}
\Phi_{0}=2\sqrt{\rho_{0}}\cos(S-mt/\hbar),\label{eqn 1.62}
\end{equation}
así se obtiene
\begin{equation}
\dot{\Phi}_{0}^{2} = \rho_{0} 
\left[
\frac{\dot{\rho}_{0}}{\rho_{0}}\cos(S-mt/\hbar) 
- 2(\dot{S}-mt/\hbar)\sin(S-mt/\hbar)
\right]^{2}.\label{eqn 1.63}
\end{equation}
Observe que el principio de incertidumbre implica que $m \Delta t \sim \hbar$, y que para el fondo en el caso no relativista se cumple la relación $\dot{S}/m \sim 0$. 
\subsection{Perturbaciones de SFDM}
El Universo no es exactamente isótropo ni espacialmente homogéneo, estas propiedades del principio cosmológico dependen de la escala que se esté analizando. En escalas pequeñas (1-50 Mpc), el campo escalar tiene oscilaciones primordiales que se transmiten a las fluctuaciones y crecen de manera rápida. Este comportamiento no es físico, ya que se observan oscilaciones en los campos pero no se observa una evolución de su densidad. Para descartar estas oscilaciones se hacen dos transformaciones. La primera cambia la ecuación de Klein-Gordon perturbada en una ecuación tipo Schrödinger, la segunda transformación cambia esta ecuación a un sistema hidrodinámico, para que puedan interpretarse de manera más sencilla las cantidades físicas observables \cite{1.3.02.2}.

Una perturbación del campo escalar es la diferencia entre su valor correspondiente en un evento en el espacio--tiempo real y su correspondiente valor en el fondo o \textit{background}, de esta manera  se obtiene lo siguiente
\begin{equation}
\Phi = \Phi_{0}(t) + \delta\Phi(\vec{x},t),\label{eqn 1.64}
\end{equation}
que al insertar en la ecuación de Klein-Gordon, con $\dot{\phi}=0$, se tiene que
\begin{equation}
\delta\ddot{\Phi} + 3H\delta\dot{\Phi}
- \frac{1}{a^{2}}\vec{\nabla}^{2}\delta\Phi
+V_{,\Phi\Phi}\delta\Phi +2V_{,\Phi}\phi = 0.\label{eqn 1.65}
\end{equation}
Donde $\phi$ es el potencial gravitacional. El campo escalar perturbado $\delta\Phi$ en términos de $\Psi$ puede expresarse de la siguiente manera
\begin{equation}
\delta\Phi = \Psi e^{-imt/\hbar} +\Psi^{*}e^{imt/\hbar},\label{eqn 1.66}
\end{equation}
que se interpreta como una superposición de ondas. Estas oscilan con una frecuencia proporcional a $m$ y $\Psi = \Psi(\vec{x},t)$. Esta función es porporcional a una función de onda de un conjunto de partículas en el condensado. Con esta ecuación y la expresión del potencial del campo escalar, la ecuación (\ref{eqn 1.65}) se convierte en 
\begin{equation}
-i\hbar(\dot{\Psi}+\frac{3}{2}H\Psi) + \frac{\hbar^{2}}{2m}(\Box \Psi +9\lambda|\Psi|^{2}\Psi) + m\phi\Psi = 0,\label{eqn 1.67}
\end{equation}
donde $\Box$ se define como 
\begin{equation}
\Box = \frac{d^{2}}{d t^{2}} + 3H\frac{d}{d t} - \frac{1}{a^{2}}\vec{\nabla}^{2}\label{eqn 1.68}
\end{equation}
Para entender la naturaleza hidrodinámica de este modelo de materia oscura, se hace una aproximación utilizando una transformación de Madelung \cite{3.2, 3.3, 3.4}, la cual conecta la teoría de campos y las funciones de onda de los condensados, es decir, se considera 
\begin{equation}
\Psi=\sqrt{\hat{\rho}} e^{iS},\label{eqn 1.69}
\end{equation}
donde $\Psi$ será la función de onda del condensado, con $\hat{\rho}=\rho/m=\hat{\rho}(\vec{x},t)$ y $S=S(\vec{x},t)$. La función $\Psi$ se separa en una fase real $S$ y una amplitud real $\hat{\rho}$, mientras que se satisface la condición $|\Psi|^{2}=\Psi\Psi^{*}= \hat{\rho}$. Sustituyendo en la ecuación (\ref{eqn 1.67}), se obtiene
\begin{equation}
\dot{\hat{\rho}} + 3H\hat{\rho}
-\frac{\hbar}{m}\hat{\rho}\Box S 
+\frac{\hbar}{a^{2}m}\vec{\nabla}S\vec{\nabla}\hat{\rho}
-\frac{\hbar}{m}\dot{\hat{\rho}}\dot{S}=0,\label{eqn 1.70}
\end{equation}
y
\begin{equation}
\hbar \dot{S}/m + \omega\hat{\rho}
+ \phi
+ \frac{\hbar^{2}}{2m^{2}}\left(\frac{\Box\sqrt{\hat{\rho}}}{\sqrt{\hat{\rho}}}\right)
+ \frac{\hbar^{2}}{2a^{2}}[\vec{\nabla}(S/m)]^{2}
- \frac{\hbar^{2}}{2}(\dot{S}/m)^{2} = 0.\label{eqn 1.71}
\end{equation}
Al tomar el gradiente de las ecuaciones (\ref{eqn 1.70}), (\ref{eqn 1.71}) dividiendo por $a$ y utilizando la definición 
\begin{equation}
\vec{v}\equiv \frac{\hbar}{ma}\vec{\nabla}S\label{eqn 1.72}
\end{equation}
se obtiene
\begin{equation}
\dot{\hat{\rho}} + 3H\hat{\rho} - \frac{\hbar}{m}\hat{\rho}\Box S 
+ \frac{1}{a}\vec{v}\vec{\nabla}\hat{\rho} - \frac{\hbar}{m}\dot{\hat{\rho}}\dot{S} = 0,\label{eqn 1.73}
\end{equation}
\begin{equation*}
\dot{\vec{v}} + H\vec{v} + \frac{1}{2a\hat{\rho}}(\vec{\nabla}p) 
+ \frac{1}{a}(\vec{\nabla}\phi) + \frac{\hbar^{2}}{2m^{2}a}\vec{\nabla}
\left(\frac{\Box\sqrt{\hat{\rho}}}{\sqrt{\hat{\rho}}}\right) 
\end{equation*}  
\begin{equation}
+\frac{1}{a}(\vec{v}\cdot\vec{\nabla})\vec{v}-\hbar(\dot{\vec{v}}+H\vec{v})(\dot{S}/m) = 0\label{eqn 1.74}
\end{equation}
donde se ha definido $\omega = 9\hbar^{2}\lambda/2m^{2}$ y $p= \omega\hat{ \rho}^{2}$. 
Ignorando los términos cuadráticos así como las derivadas temporales de segundo orden y el producto de derivades temporales en las ecuaciones (\ref{eqn 1.73}) y (\ref{eqn 1.74}) se obtiene
\begin{equation}
\frac{\partial \hat{\rho}}{\partial t} +
\vec{\nabla}\cdot(\hat{\rho} \vec{v}) + 3H\hat{\rho}=0,\label{eqn 1.75}
\end{equation}
\begin{equation}
\frac{\partial \vec{v}}{\partial t} + H \vec{v}
-\frac{\hbar^{2}}{2m^{2}}\vec{\nabla}\left(\frac{1}{2\hat{\rho}}\vec{\nabla}^{2}\hat{\rho}\right) + \omega\vec{\nabla}\hat{\rho} +\vec{\nabla}\phi,\label{eqn 1.76}
\end{equation}
\begin{equation}
\vec{\nabla}^{2}\phi = 4\pi G\hat{\rho},\label{eqn 1.77}
\end{equation}
donde la ecuación para el campo gravitacional está dado por la ecuación de Poisson y se ha introducido la notación de coordenadas comóviles $\vec{r} = a(t)\vec{x}$ de tal forma que $1/a\vec{\nabla} = \vec{\nabla} = \partial_{r}$. En la ecuación (\ref{eqn 1.72}) se observa una proporcionalidad entre el gradiente de la fase y la velocidad del fluido. Es importante observar que $\vec{v}$ puede representar el campo de velocidades para el fluido y $\hat{\rho}$ será la densidad de número de las partículas dentro del fluido. Además exixte término extra con derivadas de tercer orden en el espacio, que varía con el gradiente de 
\begin{equation*}
\frac{\hbar^{2}}{2m^{2}}\frac{\Box\sqrt{\hat{\rho}}}{\sqrt{\hat{\rho}}}.
\end{equation*}
Las ecuaciones (\ref{eqn 1.73}) y (\ref{eqn 1.74}) conducen al análogo de las ecuaciones de Euler para fluidos clásicos, con la diferencia de la existencia de un término cuántico, llamado $Q$ y definido por
\begin{equation}
Q = \frac{\hbar^{2}}{2m^{2}}\frac{\Box\sqrt{\hat{\rho}}}{\sqrt{\hat{\rho}}},\label{eqn 1.78}
\end{equation}
este último término puede describir una fuerza o algún tipo de presión negativa de naturaleza cuántica. La cantidad $Q$ se puede interpretar como un tipo de interacción entre partículas de rango corto, cuyo orden es de un valor $Q \sim \lambda$, que es la longitud de onda de Compton de las partículas del campo. En particular, este término es el responsable de que en la teoría de SFDM se solucionen los problemas CUSP-CORE y de satélites faltantes, dada la naturaleza de este campo escalar, la interacción entre esas partículas depende de la longitud de onda y de la masa del campo.
\subsection{Otros Candidatos a Materia Oscura}
Con el paso de los años, las observaciones del Universo son cada vez más precisas y con éstas, la presencia de la materia oscura es más evidente \cite{1.3.2.1}. Se sabe que se agrupa formando halos galácticos y que es la responsable de la formación a gran escala del Cosmos. Descifrar la naturaleza de la materia oscura es una tarea para físicos de partículas y cosmólogos por igual, ya que las partículas elementales son los principales candidatos a materia oscura en el Universo. 

En las secciones anteriores se han descrito dos modelos de materia oscura, el modelo estándar $\Lambda$CDM y el modelo de materia oscura escalar SFDM. Estos no son los únicos modelos que se han desarrollado. Existe una gran variedad de candidatos que no por ser menos conocidos, son menos interesantes. Se describirán algunos de ellos brevemente:

\begin{itemize}
\item Materia oscura auto-interactuante (SIDM): Las partículas de materia oscura fría tienen auto-interacción con poca disipación o aniquilación \cite{1.3.1}.
\item Materia oscura tibia (WDM): Las partículas se mueven a velocidades altas pero no relativistas, los halos de materia oscura se forman en épocas similares a CDM pero se forma menos subestructura en simulaciones de $N$-cuerpos \cite{1.3.2}.
\item Materia oscura repulsiva (RDM): la materia oscura se comporta como un condensado de bosones masivos que interactúan por un potencial repulsivo entre partículas además de la gravedad, lo cual conduce a un comportamiento de superfluidez \cite{1.3.3}.
\item Materia oscura difusa (FDM): Las partículas están compuestas de partículas ultra-ligeras, similares a materia oscura escalar \cite{1.3.4}.
\item Materia oscura auto-aniquilante (SADM): La aniquilación de materia oscura permite suavizar los perfiles CUSP de halos galácticos \cite{1.3.5}.
\item Materia oscura que decae (DDM):  La formación de estructura en $z \sim 2$ mejora para el modelo de DDM \cite{1.3.6}.
\end{itemize}


\subsubsection*{WIMP}
Los \textit{Weak Interactive Massive Particles} (WIMP) son cadidatos a materia oscura fría. Estas partículas solo interactúan de manera gravitacional con la materia bariónica y están predichas por teorías de unificación. En la mayoría de los modelos de partículas, la partícula supersimétrica más conocida es el \textit{neutralino}, el cual posee  características que coinciden con las de un WIMP: Es estable, no tiene carga eléctrica, sus interacciones son solo de tipo débil, su masa está en un rango adecuado para que se produzca con abundancia necesaria y da lugar a materia oscura fría \cite{1.3.7}.

\subsubsection*{Modificaciones a la teoría newtoniana}

En 1983, Mordehai Milgrom propone que la teoría newtoniana debe modificarse para aceleraciones pequeñas ($a_{0} \approx 1.2 \pm 0.1 \times 10^{-10}$m/s$^{2}$), y que la física de Newton es sólo una buena aproximación para aceleraciones mayores a $a_{0}$ \cite{1.3.8}. Esta modificación conduce a que la segunda ley de Newton debe replantearse para pequeñas aceleraciones de la siguiente manera 
\begin{equation}
\vec{F} = m \mu (\frac{a}{a_{0}})\vec{a}.\label{eqn 1.79}
\end{equation}
Esta modificación permite explicar muchos datos observados sin recurrir a postular materia oscura no--bariónica. Su rango de aplicabilidad y éxito es muy amplio: desde galaxias enanas esferoidales hasta supercúmulos galácticos.\\\

La materia oscura es un tipo de materia que solo interactúa con la materia bariónica de forma gravitacional, hasta ahora el modelo que mejor describe su comportamiento es $\Lambda$CDM, a pesar de presentar problemas y contradicciones, la mayoría a escalas galácticas. El modelo SFDM ayuda a solucionar en gran parte estas discrepancias presentes en CDM. Para tratar de comparar ambos modelos a esas escalas se requiere tanto de mejores observaciones como datos obtenidos de ellas. Las simulaciones numéricas de $N$-cuerpos son una herramienta útil para realizar una comparación directa de la naturaleza de distintos modelos de materia oscura y pueden apoyarlos o contradecirlos. Las simulaciones de $N$-cuerpos se describen en el siguiente capítulo.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Simulaciones de $N$-cuerpos}\label{cap.nudo}
En el capítulo anterior, se llega a la conclusión de que la naturaleza de la materia oscura es aún desconocida. El crear teorías que expliquen esa naturaleza y además concuerden con las observaciones actuales del Universo no es tarea fácil. Al no conocer su composición, una de las soluciones que se proponen es el de emplear simulaciones que involucren toda la física desarrollada en la teoría y que a su vez permitan tener resultados comparables con observaciones. Las simulaciones de $N$-cuerpos son uno de los enfoques más amplios para comprender la formación a gran escala del Universo, la inestabilidad gravitacional en escalas cosmológicas, y la formación y evolución de las galaxias. En años recientes, el poder computacional ha permitido crear simulaciones de alta resolución y que muestran la evolución del Universo desde épocas extremadamente tempranas ($z \sim 1100$).

La evolución cosmológica se aproxima con aglomeramiento gravitacional lineal a grandes escalas ($\geq100$ Mpc), y no lineal en escalas más pequeñas o galácticas (entre 10 kpc y 1 Mpc), generando condiciones iniciales específicas de partículas de materia oscura que además pueden refinarse introduciendo efectos de dinámica de gases, procesos químicos, transferencia radiativa y otros procesos astrofísicos. La fiabilidad de una simulación se mide por su resolución en masa, longitud y tiempo. La resolución de masa es especificada por la masa de la partícula más pequeña considerada, siendo la escala por debajo de la cual las fluctuaciones son despreciables. La resolución en longitud está limitada por una escala de ``suavizado'' (softening), introducida para evitar infinitos en la fuerza gravitacional cuando las partículas colisionan.

La formación de estructura en el Universo es originada por pequeñas perturbaciones en la densidad de materia, o fluctuaciones cuánticas que se expanden a escalas cosmológicas en la época de inflación. Al simular materia oscura se debe enfocar en su colapso gravitacional, al haber más colapso, las perturbaciones crecen. La teoría de perturbaciones lineal es una excelente primera aproximación a la evolución temprana del Universo. El resultado de este conjunto de consideraciones es una red de halos que se forman a lo largo de paredes y filamentos, creando un entramado cósmico. Este entramado es consistente con mediciones de aglomeraciones de galaxias en un amplio intervalo de escalas.

Existe una gran variedad de códigos que involucran teoría de simulaciones de $N$-cuerpos, incluyendo dinámica de gases, conocida como Smoothed Particle Hydrodynamics (SPH). Estos códigos han sido utilizados en numeradas ocasiones obteniendo resultados consistentes con observaciones. Por mencionar algunos: ART \cite{2.1.1}, ENZO \cite{2.1.2}, RAMSES \cite{2.1.3}, GADGET \cite{b4} etc.

Este capítulo está dedicado a describir las bases teóricas para simulaciones de $N$-cuerpos e Hidrodinámica de Partículas Suavizadas (SPH) que utiliza el código GADGET.

\section{Modelos de Fluidos Sin Colisión Autogravitantes}
Para derivar las ecuaciones del problema cosmológico de $N$-cuerpos, se puede iniciar desde las ecuaciones de la relatividad general y deducir las ecuaciones de movimiento de partículas no relativistas autogravitantes en un Universo en expansión. Para el caso de materia no relativista en el límite de campo débil, se llega a las ecuaciones de Newton. Hay algunas limitaciones con esta aproximación: no se pueden estudiar partículas relativistas y se ignoran las perturbaciones a la gravedad, es decir, los cambios en el potencial gravitacional se consideran instantáneos.

Iniciando con las definiciones de coordenadas comóviles del Capítulo 1, la distancia propia se define como  
\begin{equation}
\vec{r} = a(t)\vec{x},\label{eqn 2.1}
\end{equation}
donde $a(t)$ es el factor de escala. Al diferenciar la ecuación (\ref{eqn 2.1}) respecto del tiempo se obtienen las velocidades
\begin{equation}
\vec{v}(\vec{x},t)\equiv\dot{r}=a\vec{\dot{x}}+\dot{a}\vec{x}
=H\vec{r}+\vec{v}_{pec}.\label{eqn 2.2}
\end{equation}
Aquí, $\vec{v}_{pec}=a\vec{x}$ es la velocidad peculiar y $H=\dot{a}/a$ es la constante de Hubble. El problema de $N$-cuerpos en cosmología es algo específico.  Los sistemas estudiados en cosmología tales como la evolución no lineal de la materia oscura pueden tratarse utilizando la ecuación de Boltzmann no colisional en coordenadas comóviles acoplada en conjunto con la ecuación de Poisson que describe el comportamiento y evolución de un fluido sujeto a fuerzas externas y que tiene la siguiente forma 
\begin{equation}
\frac{\partial f}{\partial t} + \vec{v}\cdot\frac{\partial f}{\partial r} + \frac{\vec{F}}{m}\cdot\frac{\partial f}{\partial v}=0,\label{eqn 2.3}
\end{equation}
donde $f= f(\vec{r}, \vec{p}, t)$ es una función de distribución de la densidad, $\vec{v}$ es la velocidad, $\vec{r}$ es la posición, $\vec{F}$ es la fuerza y $m$ la masa que describen completamente al fluido \cite{b3}.

En el caso de que esta fuerza $\vec{F}$ se derive de un potencial, tal que 
\begin{equation}
\vec{F} = -m\nabla\Phi,\label{eqn 2.4}
\end{equation}
donde $m$ es la masa de la partícula del sistema. Sustituyendo la ecuación (\ref{eqn 2.4}) en (\ref{eqn 2.3}) se encuentra
\begin{equation}
\frac{\partial f}{\partial t} + \vec{v}\cdot\frac{\partial f}{\partial r} - \vec\nabla\Phi\cdot\frac{\partial f}{\partial v}=0\label{eqn 2.5}
\end{equation} 
Este potencial $\Phi$ debe satisfacer la ecuación de Poisson
\begin{equation}
\nabla^{2} \Phi (\vec{r},t) = 4\pi \int_{S} f(\vec{r},\vec{v},t)d^{3}v\label{eqn 2.6}
\end{equation}
donde $S$ es todo el espacio y $f$ se define mediante la siguiente expresión
\begin{equation}
f = f(\vec{r},\vec{v},t)d^{3}v d^{3}r\label{eqn 2.7}
\end{equation}
que viene dada por la masa total de las partículas que se encuentran en un cubo de volumen $d^{3}r$ centrado en $\vec{r}$ y velocidad ubicada en un cubo de volumen $d^{3}v$ centrado en $\vec{v}$. Al integrar en el espacio, lo que se obtiene es la densidad de masa que puede depender del tiempo $\rho(t)$, con esto la ecuación de Poisson presentada en la ecuación (\ref{eqn 2.6}) se reduce a la conocida.

El problema que se intenta resolver numéricamente es el siguiente:\\

Dadas las coordenadas iniciales $\vec{r}_{init}$ y velocidades $\vec{v}_{init}$ de $N$ partículas con masa en el momento $t = t_{i}$, encontrar sus velocidades $\vec{v}$ y coordenadas $\vec{r}$ en el siguiente instante $t = t_{next}$, suponiendo que las partículas interaccionan mediante la fuerza de gravedad, que se considera Newtoniana. Si $\vec{r}_{i}$ y $m_{i}$ es la coordenada y masa para cada partícula, entonces las ecuaciones de movimiento son
\begin{equation}
\frac{d^{2}\vec{r}_{i}}{d t^{2}}=
-G \sum_{j=1, i \not= j}^{N} \frac{m_{j}(\vec{r}_{i}-\vec{r}_{j})}{|\vec{r}_{i}-\vec{r}_{j}|^{3}}, \label{eqn 2.8}
\end{equation}
donde $G$ es la constante de gravitación universal. Se debe tomar la siguiente consideración antes de resolver estas ecuaciones de forma numérica.

\begin{figure}
\centering
\subfigure[]{\includegraphics[width=0.45\textwidth]{./Figuras/nbody0}}
\subfigure[]{\includegraphics[width=0.45\textwidth]{./Figuras/nbody4}}
\subfigure[]{\includegraphics[width=0.6\textwidth]{./Figuras/nbody7}}
\caption{\footnotesize{Colapso gravitacional en una simulación de $N$-cuerpos.}}
\end{figure}

\textbf{Introducir un suavizante de fuerza}: la fuerza se hace más débil (se suaviza) en distancias pequeñas para evitar aceleraciones grandes. En otras palabras, si dos partículas se encuentran muy cercanas unas a otras, estas ecuaciones pueden indefinirse. Al añadir el suavizado, la integración numérica se estabiliza. Otra razón para realizar esta acción es que cuando se integran galaxias, cúmulos de galaxias, o la estructura a gran escala , los efectos de las colisiones cercanas entre partículas individuales puede ignorarse, es decir, la fuerza que actúe en una partícula está dominada por la contribución acumulada de todas las partículas, no de pocas partículas cercanas.

Para este propósito se agrega un parámetro $\epsilon$ conocido como “suavizante gravitacional” que permite evitar una divergencia repentina en el cálculo de la fuerza. Esto se soluciona si se agrega un parámetro $\epsilon^{2}$ de manera que 
\begin{equation}
\frac{d^{2}\vec{r}_{i}}{d t^{2}}=
-G \sum_{j=1, i \not= j}^{N} \frac{m_{j}(\vec{r}_{i}-\vec{r}_{j})}{(\Delta\vec{r}_{ij}^{2} + \epsilon^{2})^{3/2}},\label{eqn2.7}
\end{equation} 
donde se ha definido $\Delta\vec{r}_{ij}^{2} = |\vec{r}_{i} - \vec{r}_{j}|$ y $\epsilon$ es el parámetro de suavización o “softening length” (Bodenheimer et al., 2007 \cite{b5}). Físicamente, se puede interpretar a este parámetro $\epsilon$ como la distancia entre los centros de dos partículas que están “unidas".

En el caso descrito al comienzo de la sección, el potencial puede escribirse de la siguiente manera

\begin{equation}
  \Phi(\vec{r},t)
  = -G
  \int_{S}\int_{S}
  \frac{f(\vec{r}, \vec{v}, t)d^{3}v'd^{3}r'}{||\vec{r}-\vec{r'}||},\label{eqn2.8}
\end{equation}
e introduciendo el parámetro $\epsilon$ se obtiene

\begin{equation}
 \Phi(\vec{r},t)
  = -G
  \int_{S}\int_{S}
  \frac{f(\vec{r}, \vec{v}, t)d^{3}v'd^{3}r'}{||\epsilon^{2} + \vec{r}-\vec{r'}||}.\label{eqn2.9}
\end{equation}
Estos resultados son válidos para el caso de un Universo Newtoniano.

Al considerar el modelo de Friedman--Lemaître--Robertson--Walker, es decir, el de un Universo homogéneo e isótropo en expansión, la dinámica de las partículas se describe mejor con el siguiente Hamiltoniano

\begin{equation}
  H 
  = \sum_{i=1}^{N} \frac{\vec{p_{i}}^{2}}{2 m_{i} a^{2}(t)} 
  +
  \frac{1}{2} \sum_{i\not=1,i\not=j}^{N}\sum_{j=1,j\not=i}^{N}
  \frac{m_{i}m_{j}\Phi(\vec{x_{i}}-\vec{x_{j}})}{a(t)},\label{eqn2.10}
\end{equation}
donde $\vec{p_{k}}$ y $\vec{x_{k}}$ son los vectores de momento y posición en el sistema de coordenadas comóviles, $a$ es el factor de escala de la métrica FLRW. El caso Newtoniano se recupera al tomar $a = 1$. El momento canónico viene dado por $\vec{p_{k}} = a^{2}(t)m_{k}\vec{x_{k}}$.

Se suponen además condiciones periódicas a la frontera para una caja de volumen $L^{3}$. Así el potencial de interacción $\Phi(\vec{x})$ será solución de la ecuación

\begin{equation}
 \nabla^{2}\Phi(\vec{x})
 =
 4\pi G
 \left[
 -\frac{1}{L^{3}}
 +
 \sum_{\vec{n}} \tilde{\delta}(\vec{x}-\vec{n}L)
 \right],\label{eqn2.11}
\end{equation}
aquí $\vec{n}$ simboliza un vector de números naturales. Esta solución corresponde a un “potencial peculiar”
\begin{equation}
 \Phi
 =
 \sum_{i=1}^{N} m_{i} \phi(\vec{x}-\vec{x_{i}}),\label{eqn2.12}
\end{equation}
cuya dinámica la gobierna la ecuación

\begin{equation}
  \nabla^{2}\Phi(\vec{x})
  =
  4 \pi G
  [\rho(\vec{x}-\bar{\rho})]\label{eqn2.13}
\end{equation}

la ecuación (\ref{eqn2.13}) es la ecuación de Poisson con un campo de fluctuaciones de densidad $\rho(\vec{x})$ y densidad media $\bar{\rho}$.
El suavizamiento gravitacional es normalizado en forma de kernel con factor de escala comóvil $\epsilon$, para esto se aplica el kernel de Spline (Monaghan \& Lattanzio 1985 \cite{b8.1}) usado en SPH y se toma $\tilde{\delta} = W(\vec{x}-\vec{n}L,2.8\epsilon)$ (véase sección 2.2 Hidrodinámica de Partículas Suavizadas), la ecuación (\ref{eqn2.11}) se convierte en

\begin{equation}
 \nabla^{2}\Phi(\vec{x})
 =
 4\pi G
 \left[
 -\frac{1}{L^{3}}
 +
 \sum_{\vec{n}}W(\vec{x}-\vec{n}L,2.8\epsilon)
 \right].
\end{equation}\label{eqn2.14}
La dinámica descrita en esta sección es la que se utiliza para describir a las partículas de materia oscura fría (CDM). Se observa que se calcula solo la fuerza entre partículas de materia oscura. Si se utilizara un método tradicional de cálculo,  requeriría $N(N-1)$ fuerzas para $N$ partículas. Si $N$ es grande, la fuerza será de un orden de $\mathcal{O}(N^{2})$. La ventaja de el método descrito aquí es que reduce ese orden a un cálculo de $N \ln N$. 

Esto es debido a que se considera un cubo mínimo que reúne a todas las partículas. Al calcular la expansión multipolar del potencial de las partículas, cosiderando el suavizamiento y el centro de masas, se ubica una partícula y se hace la pregunta : ¿Es la distancia del centro de masa del conjunto agrupado mayor que el tamaño del cubo inicial dividido por algún parámetro a escoger?

Es decir, se pregunta si se cumple la relación 
\begin{equation}
r > \frac{l}{\theta}, \label{eqn 2.15}
\end{equation}
donde $r$ es la distancia de la partícula al centro de masa del agrupamiento, $l$ es el largo del cubo inicial y $\theta$ es un parámetro de precisión. Si la expresión (\ref{eqn 2.15}) resulta ser cierta para todas las partículas de la simulación, ésta sigue su evolución, si una o más de ellas no satisface esa condición, el cubo inicial se divide en un cubo pequeño de lado $l/2$ y se repite el proceso. Se calculan las expansiones multipolares y los centros de masa para cada cubo y la pregunta se vuelve a repetir para cada proceso. Lo anterior es lo que se conoce como un \textit{Tree algorithm}, algoritmo tipo árbol o algoritmo Barnes--Hut \cite{b8.2}.
 
\begin{figure}
\centering
  \subfigure[BH]{\includegraphics[width=0.45\textwidth, height=0.4\textwidth]{./Figuras/BHAlgorithm}}
  \subfigure[PM]{\includegraphics[width=0.4\textwidth]{./Figuras/PM}}
  \caption{\footnotesize{(a) Algoritmo BH para 100 partículas y \textit{TreePM Algorithm} de una simulación cosmológica (b).}}
  \label{fig 2.1}
\end{figure}

Las simulaciones de $N$-cuerpos requieren de gran poder computacional, pues cada cálculo de fuerza se efectúa para cada una de las partículas dentro de la simulación. Con el paso del tiempo han surgido nuevos métodos para calcular estas fuerzas. 

Ejemplo de esto es el \textit{Particle Mesh algorithm}. El principio básico es que un sistema de partículas se convierte en una rejilla (o ``malla'') de valores de densidad. El potencial se resuelve luego para esta cuadrícula de densidad, y las fuerzas se aplican a cada partícula en función de en qué celda se encuentra y en qué parte de la celda se encuentra. Una vez que se encuentra la distribución de densidad, la energía potencial de cada punto en la malla se puede determinar a partir de la forma diferencial de la ley de Gauss, que después da lugar a una ecuación de Poisson que se resuelve fácilmente después de aplicar transformadas de Fourier (Klypin \& Shadarin 1983; White, Frenk \& Davis 1983 \cite{b5.1, b5.2}).




\section{Hidrodinámica de Partículas Suavizadas (SPH)}

La Hidrodinámica de Partículas Suavizadas o SPH por sus siglas en inglés (Smoothed Particle Hydrodynamics) fue creada para simular fenómenos astrofísicos que invloucran fluidos masivos moviéndose de forma arbitraria en tres dimensiones, utiliza la diferenciación analítica con fórmulas de interpolación para calcular derivadas espaciales. A diferencia del método de $N$-cuerpos, que divide el espacio en celdas para calcular fuerzas entre partículas. Las ecuaciones de energía y momento se convierten en un conjunto de ecuaciones diferenciales ordinarias para describir la mecánica y termodinámica del fluido. SPH utiliza un conjunto de partículas discretas para describir el estado de un fluido con cantidades continuas asociadas a la dinámica de fluidos. Se hace la suposición de que, en cualquier momento, las posiciones de los elementos del fluido se  distribuyen de manera aleatoria conforme a su densidad. Recuperar la densidad conocida de su distribución inicial es equivalente a recuperar la probabilidad de distribucippon de una muestra del fliudo. Existen dos métodos para hacer esto posible. El primero de ellos es un metodo de suavizamiento de kernel o núcleo, para estimar la función de densidad de probabilidad de una función (Parzen 1962 \cite{b5.3}), el otro método es la técnica de spline delta (Boneva, Kendall \& Stepanov 1971 \cite{b5.4}) para análisis de datos (Gingold \& Monaghan, 1977; Lucy, 1977; Monaghan 1997 \cite{b6,b7}). Estos métodos son utiliados para aproximar múltiples integrales y que utilizan menor cantidad de procedimeintos para llevar a cabo dichos cálculos.

\subsection{Ecuaciones Fundamentales}
La idea principal detrás de SPH es un método de interpolación que permite que cualquier función pueda expresarse en términos de sus valores en un conjunto de puntos desordenados, es decir, las partículas. Por ejemplo, para representar al medio intergaláctico, las partículas que representan al medio en forma de gas deben moverse como elementos de un fluido en un sentido Lagrangiano, este fluido se maneja como un fluido perfecto. Para que las partículas se muevan de manera correcta, es necesario construir las fuerzas que un elemento del fluido pudiese experimentar. 

El modelo de SPH (Monaghan 1992; Price 2004 \cite{b8, b9}) comienza definiendo la interpolación integral de cualquier función $A(r)$ como
\begin{equation}
 A_{I}(\vec{r})
 =
 \int_{S} 
 A(\vec{r'})W(\vec{r}- \vec{r'}, h)d^{3}r',\label{eqn2.16}
\end{equation} 
donde la integración es sobre todo el espacio y W es un núcleo o kernel de interpolación quue debe satisfacer
\begin{equation}
 \int_{S}W(\vec{r}- \vec{r'},h)d^{3}r' = 1\label{eqn2.17}
\end{equation}
\begin{equation}
\lim_{h \to 0} W(\vec{r}-\vec{r'},h) = \delta(\vec{r}-\vec{r'}),\label{eqn2.18}
\end{equation}
donde el límite se interpreta como el límite correspondiente interpolación de la integral y $h$ es un parámetro con dimensiones de longitud mientras que el espacio se considera tridimensional. 
Al hacer cálculos numéricos, la interpolación integral se aproxima con una interpolación sumatoria
\begin{equation}
 A_{I}(\vec{r})
 =
 \sum_{j} m_{j} \frac{A_{j}}{\rho_{j}} W(\vec{r}- \vec{r_{j}},h),\label{eqn2.19}
\end{equation}
donde lon índices de sumatoria $j$ denotan la etiqueta para cada partícula, la suma se hace sobre todas las partículas. La partícula $j$ tiene una masa $m_{j}$, su posición es $\vec{r}_{j}$, su densidad es $\rho_{j}$ y su velocidad es $\vec{v}_{j}$. El valor de cualquier otra cantidad $A$ en $\vec{r}_{j}$ se denota por $A_{j}$. El punto esencial de este método es que se puede construir un interpolador diferenciable de cualquier función a partir de sus valores particulares (puntos de interpolación) utilizando un kernel de interpolación que también es diferenciable. No hay necesidad de utilizar diferencias finitas o de separar el espacio el mallas tal como lo hace $N$-cuerpos. Por ejemplo, si se requiere calcular $\vec{\nabla}A$, simplemente se utiliza
\begin{equation}
\vec{\nabla}A(\vec{r}) = 
\sum_{j} m_{j} \frac{A_{j}}{\rho_{j}} \vec{\nabla}W(\vec{r}-\vec{r}_{j}, h).\label{eqn 2.20}
\end{equation}
Los cálculos originales de Gingold \& Monaghan 1977 \cite{b9.1} utilizan un kernel Gaussiano unidimensional
\begin{equation}
  W(x,h)
  =
  \frac{1}{h \sqrt{\pi}} e^{-(x^{2}/h^{2})},\label{eqn2.21}
\end{equation}
y en tres dimensiones
\begin{equation}
W(\vec{r},h)
  =
  \frac{1}{h \pi^{3/2}} e^{-(\vec{r}^{2}/h^{2})}.\label{eqn 2.22}
\end{equation}
el cual es el ejemplo usual de una secuencia que imita a una función delta en el límite $h \rightarrow 0$. Si se quiere hallar una interpretación física de las ecuaciones de SPH, es mejor asumir siempre que el kernel es Gaussiano. Así, por ejemplo, la densidad en cualquier punto del espacio se estima como
\begin{equation}
\rho(\vec{r})
=
\sum_{j} m_{j} W (\vec{r}-\vec{r}_{j},h),\label{eqn 2.23}
\end{equation}
es decir, la densidad del fluido ya se está expresando de manera discreta al utilizar estas funciones de interpolación.
\begin{figure}
\centering
\subfigure[]{\includegraphics[width=0.5\textwidth]{./Figuras/SPH1}}
\subfigure[]{\includegraphics[width=0.5\textwidth]{./Figuras/SPH2}}
\subfigure[]{\includegraphics[width=0.8\textwidth]{./Figuras/SPH3}}
\caption{\footnotesize{Modelo de SPH. Se tiene la partícula de interés, que dependiendo del kernel crea un dominio para modelar el fluido. La figura (c) muestra el modelo SPH para simular una ola en un tanque de agua.}} \label{fig 2.2}
\end{figure}


\section{Ecuaciones de Movimiento}
Al tratar el fluido perfecto, este debe obedecer las ecuaciones de Euler de dinámica de fluidos, es decir, la ecuación de continuidad

\begin{equation}
 \frac{\partial\rho}{\partial t}
 +
 \vec{\nabla}\cdot(\rho\vec{v})
 = 0,\label{eqn2.24}
\end{equation}
y la ecuación de momento
\begin{equation}
 \frac{\partial\vec{v}}{\partial t}
 +
 (\vec{v}\cdot\vec{\nabla})\vec{v}
 =
 -\frac{1}{\rho} \vec{\nabla}\cdot\vec{P} - \vec{\nabla}\Phi,\label{eqn2.25}
\end{equation}
junto con la ecuación de Poisson
\begin{equation}
 \nabla^{2}\Phi = 4 \pi G \rho,\label{eqn2.26}
\end{equation}
donde $\rho, \vec{v}, P$, son la densidad, velocidad y presión del fluido en cualquier tiempo $t$ y $\Phi, G$ representan el potencial gravitacional y la constante universal de gravitación, respectivamente.
Estas ecuaciones ofrecen una visión global del fluido. En la representación de Lagrange, se elige un punto del campo vectorial obtenido por el esquema de Euler en algún tiempo $t = t_{0}$ y se analiza su evolución temporal, lo que permite estudiar la dinámica de las partículas de manera individual que conforman al fluido. Expresando la derivada total como
\begin{equation}
 \frac{d}{dt}
 =
 \frac{\partial }{\partial t} 
 +
 \vec{v}\cdot\vec{\nabla},\label{eqn2.27}
\end{equation}
entonces la ecuación (\ref{eqn2.24}) será
\begin{equation}
 \frac{d \rho}{d t}
 =
 - \rho \vec{\nabla}\cdot\vec{v},\label{eqn2.28}
\end{equation}
y la ecuación (\ref{eqn2.25})
\begin{equation}
 \frac{d \vec{v}}{d t} 
 =
 -\frac{1}{\rho}\vec{\nabla}\cdot\vec{P} - \vec{\nabla}\Phi.\label{eqn2.29}
\end{equation}.
En la siguiente subsección se analizará este esquema desde el punto de vista de SPH y se deberá llegar a expresiones consistentes con las ecuaciones de movimiento de Euler de la hidrodinámica.

\subsection{Ecuación de Momento}
Utilizando las ideas de las secciones anteriores, se pueden obtener las ecuaciones de movimiento de la siguiente manera. El gradiente de la presión se calcula utilizando 
\begin{equation}
\rho_{i} \vec{\nabla} P_{i}
=
\sum_{j} m_{i} (P_{j}-P_{i})\vec{\nabla}_{i}W_{ij},\label{eqn 2.30}
\end{equation}
donde $W_{ij}$ denota $W(\vec{r}_{i}-\vec{r}_{j},h)$. Este particular resultado tiene la ventaja de que la fuerza se hace cero cuando la presión es constante. Aunque su desventaja es que el momento lineal y angular no se conservan de forma exacta (un par aislado de partículas con diferentes presiones podría crear un \textit{loop} que resultaría en valores infinitos), y es difícil construir una ecuación de energía consistente. Monaghan apunta que es mejor simetrizar el término de gradiente de presión reescribiendo $\nabla P / \rho$ como 
\begin{equation}
\frac{\vec{\nabla} P}{\rho} 
=
\vec{\nabla} \left(\frac{P}{\rho}\right)
+ \frac{P}{\rho^{2}}\vec{\nabla}\rho.\label{eqn 2.31}
\end{equation}
La ecuación de momento para la partícula $i$ se escribe entonces de la forma siguiente
\begin{equation}
\frac{d \vec{v}_{i}}{d t}
=
- \sum_{j} m_{j} 
\left(\frac{P_{j}}{\rho_{j}^{2}}+ \frac{P_{i}}{\rho_{i}^{2}}\right)
\vec{\nabla}_{i}W_{ij}, \label{eqn 2.32}
\end{equation}
aquí la derivada $d/dt$ denota la derivada que acompaña al movimiento. El resultado de la ecuación (\ref{eqn 2.32}) se obtuvo de una forma discreta del principio de acción de un fluido adiabático. Existen otras formas simétricas de las ecuaciones de momento para SPH, aunque para este caso particular es suficiente con el obtenido en la ecuación (\ref{eqn 2.31}).

\subsection{Ecuación de Continuidad}
La ecuación de continuidad puede interpolarse de dos maneras
\begin{equation}
\rho_{i}=\sum_{j}m_{j}W_{ij}\label{eqn 2.33}
\end{equation}
o bien
\begin{equation}
\frac{d\rho_{i}}{d t}
=
\sum_{j}m_{j}\vec{v}_{ij}\vec{\nabla}W_{ij}\label{eqn 2.34}
\end{equation}
donde se usó la notación $\vec{v}_{ij} = \vec{v}_{i}-\vec{v}_{j}$. Con la ecuación (\ref{eqn 2.34}) la densidad de cada partícula se pede fijar y varía solamente cuando las partículas se mueven relativamente unas a otras.
\subsection{Ecuación de Energía Térmica}
la ecuación para el intercambio de energía térmica por unidad de masa en forma continua se escribe como
\begin{equation}
\frac{d u}{d t}
=
-\left(\frac{P}{\rho}\right)
\vec{\nabla}\cdot\vec{v},\label{eqn 2.35}
\end{equation}
para la partícula $i$ puede escribirse de la forma
\begin{equation}
\frac{d u_{i}}{d t}
=
\left(\frac{P_{i}}{\rho_{i}^{2}}\right)
\sum_{j}m_{j}\vec{v}_{ij}\cdot\vec{\nabla}_{i}W_{ij},\label{eqn 2.36}
\end{equation}
o, notando que 
\begin{equation}
\frac{d u}{d t}
=
-\vec{\nabla}
\left(\frac{P\vec{v}}{\rho}\right)
+ 
\vec{v}\cdot\vec{\nabla}\left(\frac{P}{\rho}\right),\label{eqn 2.37}
\end{equation}
la ecuación de energía para la partícula $i$ puede escribirse como
\begin{equation}
\frac{d u_{i}}{d t}
=
\sum_{j}m_{j}\left(\frac{P_{j}}{\rho_{j}^{2}}\right)
\vec{v}_{ij}\cdot\vec{\nabla}W_{ij}.\label{eqn 2.38}
\end{equation}
Al tomar el promedio de las ecuaciones (\ref{eqn 2.36}) y (\ref{eqn 2.38}), se tiene
\begin{equation}
\frac{d u_{i}}{d t}
=
\frac{1}{2}\sum_{j}m_{j}\left(\frac{P_{j}}{\rho_{j}^{2}}
+\frac{P_{i}}{\rho_{i}^{2}}\right)
\vec{v}_{ij}\cdot\vec{\nabla}_{i}W_{ij},\label{eqn 2.39}
\end{equation}
la cual tiene los mismos valores simétricos de la ecuación (\ref{eqn 2.32}). Cualquier forma de la ecuación de energía al ser interpretada utilizando un kernel Gaussiano muestra que la energía térmica de la partícula $i$ incrementa cuando la partícula $j$ se aproxima a ella.
\subsection{Viscosidad}
Para evitar una discontinuidad en el flujo de gases ideales, es necesario además introducir una viscosidad artificial (Monaghan \& Gingold 1983 \cite{b9.2}) denotada por $\Pi_{ij}$. La viscosidad artifical más utilizada se obtiene escribiendo la ecuación de momento como
\begin{equation}
\frac{d \vec{v}_{i}}{d t}
=
- \sum_{j} m_{j} 
\left(\frac{P_{j}}{\rho_{j}^{2}}+ \frac{P_{i}}{\rho_{i}^{2}} + \Pi_{ij}\right)
\vec{\nabla}_{i}W_{ij}, \label{eqn 2.40}
\end{equation}
donde $\Pi_{ij}$ está dada por
\begin{equation}
\Pi_{ij} = \left\lbrace
\begin{array}{ll}
\frac{-\alpha \bar{c}_{ij}\mu_{ij}+\beta\mu_{ij}^{2}}{\bar{\rho}_{ij}}  & \vec{v}_{ij}\cdot\vec{r}_{ij} < 0\\

0  & \vec{v}_{ij}\cdot\vec{r}_{ij} > 0
\end{array}
\right.,\label{eqn 2.41}
\end{equation}
y 
\begin{equation}
\mu_{ij}=\frac{h\vec{v}_{ij}\cdot\vec{r}_{ij}}{\vec{r}_{ij}^{2}+\eta^{2}},\label{eqn 2.42}
\end{equation}
donde $c_{ij}$ es la velocidad media del sonido, $\alpha$ y $\beta$ son parámetros adimensionales Y según pruebas hechas en simulaciones, deben tener valores cercanos a $\alpha=1$ y $\beta=2$, el valor $\eta^{2}$ previene singularidades, es el equivalente de suavizado gravitacional para la viscosidad. Esta expresión tiene ciertas ventajas:
\begin{enumerate}
\item Es invariante ante transformaciones de Galileo;
\item Desaparece para rotación de cuerpo rígido;
\item Conserva momento lineal y angular.
\end{enumerate}
La expresión para $\Pi_{ij}$ contiene un término que es lineal con la diferencia de velocidades, que produce viscosidad de corte.

\subsection{Kernels}
Utilizar diferentes kernels en SPH es análogo a utilizar diversos esquemas en métodos de diferencias finitas. El kernel basado en las funciones delta spline (Monaghan \& Lattanzio  1985 \cite{b8.1}) es
\begin{equation}
W(\vec{r},h) = \frac{\sigma}{h^{\nu}} \left\lbrace
\begin{array}{ll}
1- \frac{3}{2}q^{2} +\frac{3}{4}q^{3} \;\;\;\textup{si} & 0 \leq \frac{r}{h} \leq 1\\

\frac{1}{4}(2-q)^{3} \;\;\;\;\;\;\,\,\,\,\,\, \textup{si} & 1 \leq \frac{r}{h} \leq 2\\
0 & \textup{otra forma}
\end{array}
\right.,\label{eqn 2.43}
\end{equation}
donde $ q\equiv \vec{r}/h$, $\vec{r}=\vec{r}_{i} - \vec{r}_{j}$ y $\nu$ es el número de dimensiones y $\sigma$ es una constante de normalización, con valores
\begin{equation*}
\frac{2}{3}, \; \frac{10}{7\pi}, \; \frac{1}{\pi},
\end{equation*}
en una, dos y tres dimensiones, respectivamente. Este kernel es de soporte compacto; la segunda derivada es continua y el error dominante de el interpolador de la integral es del orden $\mathcal{O}(h^{2})$. Que sea de soporte compacto significa que las interacciones se anulan exactamente para $r>2h$; la continuidad de la segunda derivada implica que el kernel no es sensible al desorden de las partículas y los errores de los interpoladores son pequeños dado que el desorden de las partículas no es muy grande. La diferencia al utilizar SPH para modelar fluidos, tales como agua o gas, es que sobre la partícula de interés de estudio, se crea un dominio dependiendo de la distancia $\vec{r}$ y de $h$, por lo que dentro de ese dominio existen partículas que influyen en la interacción de la partícula, lo cual eventualmente permite modelar la interacción (Figura \ref{fig 2.2}).\\\


El método SPH describe la dinámica de un gas de partículas, en este caso, materia visible o bariónica, junto con la dinámica de fluidos sin colisión autogravitantes, se tiene lo necesario para llevar a cabo una simulación cosmológica que pueda incluir ambos componentes. En el siguiente capítulo se describe la función lógica, aunque de manera breve, del código GADGET-2.



\chapter{GADGET}\label{GADGET}
GAlaxies with Dark matter and Gas intEracT (GADGET) es un código libre que utiliza el método de $N$-cuerpos en conjunto con SPH para el cálculo de simulaciones cosmológicas y que ha tenido varias etapas y modificaciones desde su primer etapa pública en 2001. El código fue desarrollado en su mayoría por Volker Springel \cite{b4} como parte de su tesis de doctorado en el Max Planck Institute for Astrophysics. Puede utilizarse para analizar sistemas aislados o para simulaciones que involucren la expansión del espacio. En ambos casos con o sin condiciones periódicas a la frontera. En todas las simulaciones, GADGET sigue la evolución de un sistema de $N$-cuerpos sin colisión autogravitante y permite la inclusión de dinámica de gases, descrita por el método SPH.
GADGET es capaz de simular sistemas aislados, tales como la colisión y formación de galaxias hasta la formación a gran escala del Universo. La versión pública del código, Gadget-2 \cite{b10}, lanzada en 2005 es la que se utilizó para las diversas simulaciones de este trabajo.

En la sección 2.1 del Capítulo 2, se comenta que GADGET hace uso de distintos algoritmos para calcular fuerzas entre partículas de materia oscura y la dinámica de gases para materia bariónica. Se describe de forma breve dos algoritmos para calcular la fuerza entre partículas, los algoritmos tree y PM. GADGET-2 utiliza una combinación de ambos algoritmos, el \textit{TreePM method} (Bode, Ostriker \& Xu 2000; Bagla 2002 \cite{3.0.1, 3.0.2}). Este método costruye un campo de densidades de masa en la malla, en la cual se efectúa una transformada de Fourier discreta. Se deja evolucionar en el tiempo y se aplica una transformada de Fourier inversa para obtener el potencial gravitacional de la malla.

Una simulación cosmológica requiere de un poder computacional más allá del de un simple ordenador, se necesita un arreglo de computadoras que permitan el cálculo de manera paralela, es decir, un clúster computacional. Este es un conjunto de ordenadores unidos entre sí normalmente por una red de alta velocidad y que se comportan como si fuesen una única computadora. El clúster es un recurso vital para llevar a cabo una simulación de tal magnitud. Gadget-2 utiliza una serie de algoritmos de descomposición. Este arreglo permite distribuir la carga de memoria en procesadores individuales, reduciendo el tiempo de cálculo de manera jerárquica, es decir, se le da prioridad a los cálculos que requieran mayor memoria, por ejemplo en el método TreePM, que divide el espacio en celdas cada vez más pequeñas. Los cálculos que requieren mayor memoria son distribuidos a más procesadores, se les da más prioridad, un proceso como esto se observa mejor en la Figura \ref{fig 3.1}.

\begin{figure}
\centering
  %\begin{adjustbox}{addcode={\begin{minipage}{\width}}{\caption{%
      %\footnotesize{Ilustración entre un algoritmo BH y una descomposición de procesos Peano-Hilbert. Esta es una curva que recorre cada malla de la simulación solo una vez. El volumen de la simulación se reparte en dominios al segmentar esta curva en puntos arbitrarios entre los límites de la celda. Esto genera una manera de distribuir el conjunto de partículas en procesadores individuales.}
      %}\end{minipage}},center}
      \includegraphics[width=0.9\textwidth, height=0.5\textwidth]{./Figuras/TreePM}{\caption{\footnotesize{Ilustración entre un algoritmo BH y una descomposición de procesos Peano-Hilbert. Esta es una curva que recorre cada malla de la simulación solo una vez. El volumen de la simulación se reparte en dominios al segmentar esta curva en puntos arbitrarios entre los límites de la celda. Esto genera una manera de distribuir el conjunto de partículas en procesadores individuales.}}}\label{fig 3.1}%
  %\end{adjustbox}
\end{figure}
%\begin{figure}
%\centering
%  \includegraphics[width=0.7\textwidth]{./Figuras/TreePM}
%  \caption{\footnotesize{Ilustración entre un algoritmo BH y una descomposición de procesos Peano-Hilbert. Esta es una curva que recorre cada malla de la simulación solo una vez. El volumen de la simulación se reparte en dominios al segmentar esta curva en puntos arbitrarios entre los límites de la celda. Esto genera una manera de distribuir el conjunto de partículas en procesadores individuales.}}
% \label{fig 3.1}
%\end{figure}

El equipo de Volker Springel realizó la simulación del milenio \cite{3.0.3} (Figura \ref{fig 3.2}) utilizando Gadget-2; esta simulación utilizó más de 10 mil millones de partículas para rastrear la evolución de la distribución de la materia en una región cúbica del Universo de más de 500 Mpc. Mantuvo ocupado el superordenador principal en el Centro de Supercomputación de la Sociedad Max Planck en Garching, Alemania, durante más de un mes y la cantidad de información obtenida durante esa simulación rebasa los 25 Tbytes.

La simulación incluye 20 millones de galaxias dentro de este enorme volumen agrupadas en halos de materia oscura, visualizada a esta escala como filamentos.\\\\\\\

\begin{figure}
\centering
%  \begin{adjustbox}{addcode={\begin{minipage}{\width}}{\caption{%
%      \footnotesize{Distribución de materia oscura en la simulación del milenio.}
%      }%\end{minipage}},rotate=90,center}
      \includegraphics[width=1.0\textwidth, height=0.7\textwidth]{./Figuras/Millenium}{\caption{\footnotesize{Distribución de materia oscura en la simulación del milenio.}}}\label{fig 3.2}%
%  \end{adjustbox}
\end{figure}

\section{Axion-Gadget}
Axion-Gadget \cite{3.1} es una modificación del código de simulaciones de $N$-cuerpos/SPH de Gadget-2. Está basado en un modelo diferente de materia oscura, el Axion Ultra--Ligero o Ultra--Light Axion DM, también llamado Fuzzy Dark Matter (Turner 1983 \cite{3.1.1}, Sin 1994 \cite{3.1.2}, Matos et al. 2002 \cite{3.1.3} Guzmán \& Ureña-López, 2003 \cite{3.1.4}, Kim \& Marsh 2016 \cite{3.1.5}), sugiere la utilización del modelo SFDM para resolver los problemas que han surgido de la teoría de $\Lambda$CDM así como en sus resultados numéricos. FDM es un bosón escalar, ya discutido en la sección 1.2.3., con una masa ultra ligera $(m \sim 10^{-22})$ eV, la cuál es requerida debido a una reciente observación de la época de reionización del Universo. 

Algunos de los valores discutidos entre los que debe valer esta masa dicen debe ser del orden de 10$^{-22}$eV, y que la longitud de onda de Compton de FDM debe rondar $\sim \mathcal{O}$(kpc). FDM se produce de manera no térmica y en el régimen no relativista se comporta como CDM. La característica más llamativa del FDM es que el halo tiene un núcleo solitónico de tamaño $\sim \mathcal{O} $(kpc) resultante de la presión cuántica de las partículas FDM, que puede ser más grande que su propia gravedad. Por lo tanto, la presión cuántica juega un papel esencial en la resolución de la crisis de pequeña escala. 

La modificación propone un nuevo esquema de la interacción efectiva Partícula--Partícula del algoritmo PM para simular el modelo FDM, mediante el cual se puede calcular el efecto cuántico del FDM en simulaciones de $N$-cuerpos.
\subsection{Propiedades Físicas}
La naturaleza de FDM se describe mediante las ecuaciones de Schrödinger-Poisson (Zhang et al. 2017 \cite{3.1})
\begin{equation}
i\hbar \frac{d \Psi}{dt} 
=
-\frac{\hbar^{2}}{2m_{\chi}} \vec{\nabla}^{2}\Psi + m_{\chi}V\Psi,\label{eqn 3.1}
\end{equation}
y
\begin{equation}
\vec{\nabla}^{2}V = 4\pi G m_{\chi}|\Psi|^{2},\label{eqn 3.2}
\end{equation}
donde $\hbar$, $m\chi$ y $V$ son la constante de Planck, la masa de la partícula y el potencial gravitacional actuando sobre la partícula, respectivamente. La función de onda se escribe como
\begin{equation}
\Psi = \sqrt{\frac{\rho}{m_{\chi}}}\exp(\frac{iS}{\hbar})\label{eqn 3.3}
\end{equation}
en términos de la densidad de número $\rho/m_{\chi}$, mientras que se puede definir el gradiente de $S$ como el momento lineal de la DM
\begin{equation}
\vec{\nabla}S = m_{\chi}\vec{v}.\label{eqn 3.4}
\end{equation}
Con esta definición, al introducir la función de onda $\Psi$ en la ecuación (\ref{eqn 3.1}) y resolviendo las ecuaciones de Schrödinger-Poisson, de la parte imaginaria, se obtiene la ecuación de continuidad
\begin{equation}
\frac{d\rho}{dt} + \vec{\nabla}\cdot(\rho\vec{v}) = 0,\label{eqn 3.5}
\end{equation}
mientras que de la parte real, se obtiene la ecuación de conservación de momento
\begin{equation}
\frac{d\vec{v}}{dt} + (\vec{v}\cdot\vec{\nabla})\vec{v} 
=
-\vec{\nabla}(Q + V).\label{eqn 3.6}
\end{equation}
$Q$ es un potencial cúantico , llamado potencial de Bohm, y está definido como
\begin{equation}
Q 
=
-\frac{\hbar^{2}}{2m^{2}_{\chi}}\frac{\vec{\nabla}^{2}\sqrt{\rho}}{\sqrt{\rho}}.\label{eqn 3.7}
\end{equation}
Note la relación entre esta presión y la presión encontrada en el Capítulo 1, en la ecuación (\ref{eqn 1.78}). La diferencia está en que en lugar de utilizar el operador d'Alambertiano $\Box$ se utiliza el operador Laplaciano $\nabla$, dado que la interacción entre partículas de materia oscura en este punto no es relativista, si no que meramente gravitacional. Esta ``presión cuántica'' es la que hace posible que en SFDM los halos de materia oscura creados sean en menor medida a comparación de $\Lambda$CDM. Esto es un resultado esperado para el modelo.

Estas dos últimas ecuaciones son llamadas ecuaciones de Madelung (Spiegel 1980 \cite{3.2}, Uhleman et al. 2014 \cite{3.3}, Marsh 2015 \cite{3.4}). Se observa que la presión $Q$ solo está definida por la densidad de masa $\rho$ y puede identificarse como una fuerza adicional ejercida sobre las partículas.

Para tomar en cuenta el efecto de la presión cuántica, se inicia con el Hamiltoniano sin el término de gravedad
\begin{equation}
H = \int \frac{\hbar^{2}}{2 m_{\chi}} |\vec{\nabla}\Psi|^{2}d^{3}x
  = \int \frac{\rho}{2} |\vec{v}|^{2}d^{3}x + \int \frac{\hbar^{2}}{2 m_{\chi}} (\vec{\nabla}\sqrt{\rho})^{2}d^{3}x.\label{eqn 3.8}
\end{equation}
Entonces la energía cinética en forma discreta, con índice $j$ para identificar a cada partícula se escribe como
\begin{equation}
T = \int \frac{\rho}{2} |\vec{v}|^{2}d^{3}x = \sum_{j} \frac{1}{2} m_{j} \left(\frac{d q_{j}}{dt}\right)^{2}, \label{eqn 3.9}
\end{equation}
donde $q_{j}$ es la coordenada de la $j$--ésima partícula y la energía potencial será 
\begin{equation}
K_{p} = \int \frac{\hbar^{2}}{2 m_{\chi}} (\vec{\nabla}\sqrt{\rho})^{2}d^{3}x. \label{eqn 3.10}
\end{equation}
Note que el término de la energía potencial $K_{p}$ no está discretizado aún. Esto se realizará más adelante.

El Lagrangiano del sistema será entonces 
\begin{equation}
L = T - K_{p}
  =
\sum_{j} \frac{1}{2} m_{j} \left(\frac{d q_{j}}{dt}\right)^{2}
-
 \int \frac{\hbar^{2}}{2 m_{\chi}} (\vec{\nabla}\sqrt{\rho})^{2}d^{3}x,\label{eqn 3.11}  
\end{equation}
y las ecuaciones de Euler-Lagrange tendrán la forma
\begin{equation}
\frac{d}{dt}\frac{\partial L}{\partial \dot{q}_{j}} - \frac{\partial L }{\partial q_{j}} = 0 
\Rightarrow 
m_{j} \ddot{q}_{j} = - \frac{\partial K_{p}}{\partial q_{j}}.\label{eqn 3.12}
\end{equation}
$K_{p}$ es una función continua y no puede usarse en el método Particle-Particle ($PP \; method$). Para eso debe implementarse una aproximación numérica con funciones delta que discreticen a la densidad de número de cada partícula individual.
\subsection{Implementación de la Presión Cuántica}
Para una interacción partícula--partícula, la densidad de número para cada partícula individual se describe con funciones delta. De manera que la densidad de masa $\rho$ puede escribirse como
\begin{equation}
\rho(\vec{r})
=
\sum_{i}m_{i}\delta(\vec{r}-\vec{r}_{i}).\label{eqn 3.13}
\end{equation}
Numéricamente, una función delta puede ser un problema computacional dada la cobertura de la función, ya que eso podría llevar a inconsistencias en el cálculo, tales como valores infinitos o no definidos. Sin embargo, se puede aproximar esta función delta como una función kernel/Gaussiana muy puntiaguda, con tal de que su anchura sea lo suficientemente pequeña.
Las ventajas de esta aproximación son las siguientes:
\begin{enumerate}
\item Mantiene naturalmente el suavizamiento del kernel, es diferenciable y esféricamente simétrico. 
\item La interacción partícula--partícula evita singularidades en posiciones donde la densidad sea nula.
\end{enumerate}
Debido al tamaño infinito de la red, esa singularidad puede hacer que numéricamente, el resultado no tenga sentido físico.
Con esto en mente, se escribe la función $\delta$ como una Gaussiana de la forma
\begin{equation}
\delta (\vec{r}-\vec{r}_{i}) = 
\frac{2\sqrt{2}}{\lambda ^{3} \pi ^{3/2}} \exp \left(-\frac{2|\vec{r}-\vec{r}_{i}|^{2}}{\lambda ^{2}}\right).\label{eqn 3.14}
\end{equation}
El valor de $\lambda$ no es arbitrario, debe ser del mismo orden de la longitud de onda de Compton ya que una partícula de FDM debe tener probabilidad alta de ser encontrada dentro de un paquete de onda descrito por la ecuación (\ref{eqn 3.3}). Con estos valores, la probabilidad de encontrar una partícula de FDM en una longitud de onda es de $95 \%$. Tomando la masa del FDM con orden $\mathcal{O}(M_{\chi})\sim 10^{-22}$ eV como ejemplo, su longitud de onda $\lambda_{M}$ es de $\mathcal{O}(\lambda_{M})\sim$ kpc. Insertando la ecuación (\ref{eqn 3.14}) en el término $(\vec{\nabla}\sqrt{\rho})^{2}$ de la ecuación (\ref{eqn 3.10}) la expresión se puede expandir utilizando la función kernel
\begin{equation}
\begin{array}{ll}
\left[\vec{\nabla}\sqrt{\rho (\vec{r})}\right]^{2} &=
\frac{1}{4\rho(\vec{r})}\left[\sum_{i} m_{i}\vec{\nabla}\delta(\vec{r}-\vec{r}_{i})\right]^{2}, \\\\\\ 
&=
\frac{1}{4\rho(\vec{r})} 
\left[\sum_{i}
m_{i}\delta(\vec{r}-\vec{r}_{i})(-\frac{4}{\lambda^{2}})(\vec{r}-\vec{r}_{i})\right]^{2}, \\\\\\
&=
\frac{4}{\lambda^{4}\rho(\vec{r})}
\left[
\sum_{i} m_{i}\delta(\vec{r}-\vec{r}_{i})(\vec{r}-\vec{r}_{i})
\right]^{2}. \label{eqn 3.15}

\end{array}
\end{equation}
En la simulación, esas partículas de FDM se agrupan en cúmulos masivos en el espacio, estos cúmulos pueden tratarse como partículas puntuales (ignorando el tamaño de los cúmulos a escalas cosmológicas). La densidad de masa (\ref{eqn 3.13}) toma la forma
\begin{equation}
\rho(\vec{r})
=
\sum_{j}\sum_{i}m_{i}\delta(\vec{r}-\vec{r}_{j}),\label{eqn 3.16}
\end{equation} 
con el índice $j$ para cada agrupación de cúmulos. 

\begin{figure}
\centering
\includegraphics[width=0.50\textwidth, height=0.60\textwidth]{./Figuras/Density}
\caption{\footnotesize{Interpretación de la densidad de las partículas dentro del código.}}
\end{figure}

Matemáticamente, se puede pensar que la densidad de masa se expande alrededor de $\vec{r}_{j}$ para incluir a todas las partículas de FDM: $\vec{r} \rightarrow \vec{r}-\vec{r}_{j}$ y $\vec{r}_{i} \rightarrow \vec{r}_{i} - \vec{r}_{j}$. Tomando eso en consideración, la suma de partículas individuales de FDM es efectivamente la misma que sumando sobre todos los puntos y la ecuación (\ref{eqn 3.15}) puede reescribirse como 
\begin{equation}
\left[\vec{\nabla}\sqrt{\rho (\vec{r})}\right]^{2} \simeq 
\frac{4}{\lambda^{4}}
\left[
\sum_{i}m_{i}\delta(\vec{r}-\vec{r}_{j})(\vec{r}-\vec{r}_{j})
\right]^{2}
\left[
\sum_{j}m_{j}\delta(\vec{r}-\vec{r}_{j})
\right]^{-1}. \label{eqn 3.17}
\end{equation}
Las ecuaciones (\ref{eqn 3.15}) y (\ref{eqn 3.17}) son prácticamente iguales pero su significado no debe confundirse en este punto; el paquete de onda Gaussiano se vuelve un kernel imaginario de suavizamiento de partículas.

Para discretizar completamente $\partial K_{p}/\partial q_{j}$ debe integrarse la ecuación (\ref{eqn 3.17}) en todo el espacio; dada la naturaleza de la propia función $\delta$, se enfoca en el volumen que rodea los puntos imaginarios de las partículas. Así, la integración total con la aproximación del kernel da
\begin{equation}
\int\left[\vec{\nabla}\sqrt{\rho (\vec{r})}\right]^{2}  \simeq 
\int \footnotesize{\frac{4 d^{3}x}{\lambda^{4}}
\left[
\sum_{j} m_{j}\delta(\vec{r}-\vec{r}_{j})(\vec{r}-\vec{r}_{j})
\right]^{2}
\left[
\sum_{j}m_{j}\delta(\vec{r}-\vec{r}_{j})
\right]^{-1}}\label{eqn 3.18}
\end{equation} 
\begin{equation}
\simeq
\footnotesize{4\lambda ^{-4} 
\sum_{j}m_{j}\delta(\vec{r}-\vec{r}_{j})(\vec{r}-\vec{r}_{j})^{2}\Delta V_{j}B_{j},}\label{eqn 3.19}
\end{equation}
\begin{equation}
\simeq
\footnotesize{4\lambda^{-4}
\sum_{j}m_{j}
\frac{\Delta V_{j}B_{j}}{\lambda^{3}\pi^{3/2}}
\exp\left[-\frac{(\vec{r}-\vec{r}_{j})^{2}}{\lambda^{2}}\right]
(\vec{r}-\vec{r}_{j})^{2},} \label{eqn 3.20}
\end{equation}
donde $V_{j}$ y $B_{j}$ son el volumen efectivo y el factor de corrección de la $j$--ésima partícula. 

El factor de corrección $B_{j}$ para la $j$--ésima partícula en la simulación se propone para que numéricamente pueda distinguirse entre los resultados de la integración de la función $\delta$ como un kernel Gaussiano, es decir,  cuando se considera a esta función como kernel cuya anchura es igual a una longitud de onda de una partícula, no se comporta como una función $\delta$ en la  región donde la distancia entre dos centros del kernel es menor a una longitud de onda. En rangos tan pequeños, la superposición entre dos Gaussianas puede contribuir significativamente, especialmente al hacer integraciones con alta densidad de partículas.

El volumen efectivo $\Delta V_{j}$ para cada partícula en la simulación es del orden de $\lambda^{3}\pi^{3/2}$, resultado de una integral del kernel Gaussiano; el valor exacto de $\Delta V_{j}$ puede diferir de  sistema a sistema por la propia complejidad de la región central del kernel. Se trata de un parámetro libre fenomenológico o constante, pero se ajusta su valor para hacer coincidir el resultado dentro del núcleo del solitón obtenido con otras aproximaciones con mejor resolución en regiones que miden menos de una longitud de onda. (Schieve et al. 2014 \cite{3.5}).

Finalmente; la ecuación (\ref{eqn 3.10}) se reacomoda
\begin{equation}
\footnotesize{\sum_{j} \frac{\partial K_{p}}{\partial q_{j}}
=
\frac{4\hbar^{2}}{m_{\chi}^{2}\lambda^{4}}
\sum_{j}m_{j}\Delta V_{j}B_{j}
\exp\left[
-\frac{2|\vec{r}-\vec{r}_{j}|^{2}}{\lambda^{2}}\right]
(1-\frac{2|\vec{r}-\vec{r}_{j}|^{2}}{\lambda^{2}})
(\vec{r}-\vec{r}_{j})},\label{eqn 3.21}
\end{equation}
al igual que la ecuación de movimiento (\ref{eqn 3.12})
\begin{equation}
\footnotesize{\sum_{j}m_{j}\ddot{q}_{j}
=
\frac{4\hbar^{2}}{m_{\chi}^{2}\lambda^{4}}
m_{j}\Delta V_{j}B_{j}
\exp\left[
-\frac{2|\vec{r}-\vec{r}_{j}|^{2}}{\lambda^{2}}\right]
(1-\frac{2|\vec{r}-\vec{r}_{j}|^{2}}{\lambda^{2}})
(\vec{r}-\vec{r}_{j}).}\label{eqn 3.22}
\end{equation}
Sustituyendo $q$ con $\vec{r}$, la aceleración adicional de la presión cuántica en la simulación se describe como
\begin{equation}
\footnotesize{\ddot{\vec{r}}
=
\frac{4M\hbar^{2}}{M_{0}m_{\chi}^{2}\lambda^{4}}
\sum_{j}B_{j}
\exp\left[
-\frac{2|\vec{r}-\vec{r}_{j}|^{2}}{\lambda^{2}}\right]
(1-\frac{2|\vec{r}-\vec{r}_{j}|^{2}}{\lambda^{2}})
(\vec{r}_{j}-\vec{r}).}\label{eqn 3.23}
\end{equation}
$M$ es la masa de la partícula en la simulación y $M_{0}$ es un factor de normalización que involucra a $\Delta V_{j}$, cuyo valor se elige $M_{0} = 10^{6} M_{\odot}$. Si se coloca cualquier partícula solitaria de prueba alrededor de fuentes de presión cuántica, la energía adicional dada al sistema por parte de esta presión es cero. El trabajo total, es decir la integración de la ecuación (\ref{eqn 3.23}) de $r=0$ a $r=\infty$ se anula. 

Es decir, se ha deducido que la presión cuántica es una interacción de rango corto, mostrado con la ecuación (\ref{eqn 3.23}) ya que el término exponencial que decrece y depende en gran manera de la longitud de onda $\lambda$ de Compton que posea la materia oscura.

Zhang en su artículo menciona que pone a prueba esta nueva modificación con un sistema de dos partículas ($B_{j}=1$), separadas por una distancia del orden de $\mathcal{O}$(kpc), la aceleración causada por la presión cuántica será de $\mathcal{O}$($\frac{\hbar^{2}}{m^{2}\lambda^{3}}$) $\sim$ $\mathcal{O}$($10^{-10}m/s^{2}$). La presión cuántica puede ser atractiva si la distancia entre dos partículas es menor a $\lambda/\sqrt{2}$. Sin embargo, se vuelve repulsiva si la distancia es mayor a $\lambda/\sqrt{2}$. Al recordar el término $Q$ de la ecuación (\ref{eqn 3.3}), la presión cuántica es proporcional a la segunda derivada de la densidad de masa, que puede tener valores positivos, negativos o nulos, correspondientes físicamente a fuerzas atractivas, repulsivas o nulas. 

La modificación al código se hace solamente para el cálculo de fuerzas entre partículas de materia oscura, es decir el $TreePM\;algorithm$ es el gran cambio en este código, el cálculo de fuerza para materia bariónica, es decir, SPH se deja intacto. La finalidad de utilizar esta modificación es la de comparar el modelo FDM con $\Lambda$CDM en escalas cosmológicas. 


\section{Ejemplos}
Los siguientes son ejemplos incluidos dentro de la distribución de GADGET-2. Antes de ejecutar cualquier simulación se debe editar el \textsf{makefile} dentro del folder de \textsf{Gadget2}, este proceso se detalla más profundamente en el Apéndice \ref{Apend.B}. Las simulaciones ejecutadas son una colisión de dos galaxias y la evolución a gran escala en un Universo $\Lambda$CDM y fueron realizados en una laptop con un solo procesador.

\subsection{Colisión de galaxias}
Esta simulación consiste de dos discos de galaxias acercándose una a otra, llevando a una fusión entre ellas. Cada galaxia consiste de un disco estelar y un halo masivo extenso de materia oscura. Este ejemplo utiliza física Newtoniana, con 20000 partículas de disco y 40000 partículas de halo (Figura \ref{fig 3.3}). 

\subsection{Formación de estructura a gran escala}
Este ejemplo consiste de $32^{3}$ partículas de materia oscura, junto con $32^{3}$ partículas de gas, la formación de estructura se lleva a cabo en una caja periódica de tamaño $(50 h^{-1} \textup{Mpc})^{3}$ en un Universo $\Lambda$CDM. La física involucrada es para gases adiabáticos y la temperatura mínima del gas se fija en 1000 K. Este ejemplo utiliza condiciones iniciales tipo malla, donde las partículas de gas se colocan en los centros de la malla rodeados por partículas de materia oscura. La simulación inicia en $z = 10$ y termina en la época presente (Figura \ref{fig 3.5}).

%\begin{figure}[H]
%\centering
 % \includegraphics[width=0.6\textwidth]{./Figuras/lcdm_gas_xy_00001}
  %\caption{\footnotesize{Inicio de la simulación. Las partículas están ordenadas en una malla dentro de una caja de tamaño $(50 h^{-1} \textup{Mpc})^{3}$.}}\label{fig 3.4}
%\end{figure}

Los parámetros utilizados para esta simulación se indican en la tabla \ref{Tabla 3.1}

\begin{table}[htb]%
\caption{Parámetros del ejemplo incluido en Gadget para $\Lambda$CDM}
\label{Tabla 3.1}%
\centering
\begin{tabularx}{0.9\textwidth}{@{\extracolsep{\fill}}  l c c }
\toprule%
Descripción & Símbolo & Valor\\\toprule%
Densidad de materia oscura & $\Omega_{0}$ & 0.3\\
Densidad de energía oscura & $\Omega_{\Lambda}$ & 0.7\\
Densidad de materia bariónica & $\Omega_{b}$ &0.04\\\midrule
Parámetro de Hubble & $h$ & 0.7\\
($h=H_{0}/100$ $\textup{Mpc}\cdot\textup{km}\cdot\textup{s}^{-1}$)\\\bottomrule
\end{tabularx}
\end{table}


\begin{figure}[htpb]
\centering
\subfigure[]{\includegraphics[width=0.4\textwidth]{./Figuras/movie_xy_00000}}
\subfigure[]{\includegraphics[width=0.4\textwidth]{./Figuras/movie_xy_00030}}
\subfigure[]{\includegraphics[width=0.7\textwidth]{./Figuras/movie_xy_00101}}
\caption{\footnotesize{Evolución de dos galaxias espirales colisionando para formar una sola. En la figura las partículas azules representan el halo de materia oscura, las partículas rojas representan el disco estelar.}} \label{fig 3.3}
\end{figure}

\begin{figure}[htpb]
\centering
\subfigure[Materia oscura]{\includegraphics[width=0.4\textwidth]{./Figuras/lcdm_DM_xy_00080}}
\subfigure[Gas]{\includegraphics[width=0.4\textwidth]{./Figuras/lcdm_gas_xy_00080gas}}
\subfigure[Estructura]{\includegraphics[width=0.7\textwidth]{./Figuras/lcdm_gas_xy_00080}}
\caption{\footnotesize{Evolución desde $z=10$ hasta $z = 0$. En la figura se observan los halos de materia oscura y las agrupaciones de gas alrededor de los mismos.}} \label{fig 3.5}
\end{figure}
El ejemplo de la formación de estructura a gran escala es el que se analizará con ambos códigos. Para este fin, se generan idénticas condiciones iniciales para ambas simulaciones, haciendo cambios en el suavizamiento gravitacional y en el caso de FDM, en el valor de la longitudo de onda de Compton de las partículas de materia oscura.  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Análisis de Resultados}
Al ya tener una idea general de lo que sucede al realizar simulaciones de $N$-cuerpos, Es necesario llevar a cabo un estudio a detalle de los resultados obtenidos, aunque realizar un análisis de la cantidad de datos de una sola simulación no es tarea fácil, dado que cada archivo es una especie de caja negra de la propia simulación. Existe una gran variedad de programas y códigos hechos para poder generar, visualizar e interpretar dichos resultados, algunos otros, deben crearse de acuerdo a los resultados físicos que se requieran. Otros códigos ayudan a la visualización directa de las partículas y permiten una observación  y manipulación en 3 dimensiones de los archivos de salida o \textsf{snapshots}. En esta sección se utilizarán diversas herramientas computacionales para crear condiciones iniciales de acuerdo a la capacidad de cálculo disponible; códigos para analizar los datos que se obtienen de cada \textsf{snapshot} y programas para interpretar resultados.

\section{Generar Condiciones Iniciales}
Para poder llevar a cabo una simulación cosmológica con Gadget-2 y en general, con cualquier otro código, se debe contar con un archivo de condiciones iniciales. En dicho archivo se indica:
\begin{enumerate}
\item El tipo de simulación que se va a llevar a cabo: cosmológica, galáctica, etc.
\item La cantidad de partículas que se usarán en la simulación ($N$).
\item El tiempo de inicio de la simulación en caso de que sea cosmológica ($z$).
\item La densidad de materia oscura ($\Omega_{0}$).
\item La densidad de energía oscura ($\Omega_{\Lambda}$).
\item La densidad de materia bariónica ($\Omega_{b}$).
\item El parámetro de Hubble ($h$).
\item El tamaño de la caja de simulación ($L$).
\item El término de normalización del espectro de potencias ($\sigma_{8}$) \cite{4.0}.
\end{enumerate}
Entre otras cantidades, tales como la longitud, la masa y la velocidad en unidades convencionales, es decir kpc, $\textup M_{\odot}$ y km/s. El código que genera este archivo de parámetros lleva a cabo una aproximación, llamada \textit{Aproximación Zeldovich} \cite{4.1, 4.2}. 

La aproximación Zeldovich describe el estado no lineal de la evolución gravitacional; la distribución de materia se considera homogénea y sin colisión. Si las coordenadas Lagrangianas (iniciales) no perturbadas de las partículas las describe $\vec{q}$, las coordenadas Eulerianas en el tiempo $t$ se definen como
\begin{equation}
\vec{r}(\vec{q}, t) = a(t)[\vec{q} + b(t)\vec{s}(\vec{q})],
\end{equation}
$a(t)$ es el factor de escala y $b(t)$ es la razón de crecimiento de las fluctuaciones lineales. El término de velocidad $\vec{s}(\vec{q})$ describe el desplazamiento de las partículas con respecto a la posición inicial (Laplaciana). Se relaciona con el potencial $\Phi_{0}(\vec{q})$ originado por las fluctuaciones lineales
\begin{equation}
\vec{s}(\vec{q}) = \vec{\nabla}\Phi_{0}(\vec{q}).\label{eqn 4.2}
\end{equation}
Se considera un medio homogéneo, sin presión ni viscosidad y sin interacción gravitacional. Para este sistema, las posiciones Eulerianas $\vec{x}$ en $t$ se relacionan a las Laplacianas como sigue
\begin{equation}
\vec{x}(\vec{q}, t) = \vec{q} + \vec{v}(\vec{q})t.\label{eqn 4.3}
\end{equation}
Dado que en $t>0$ se crean inhomogeneidades a la densidad, por conservación de masa se requiere que 
\begin{equation}
\rho(\vec{r}, t)d\vec{r} = \rho_{0}d\vec{q},\label{eqn 4.4}
\end{equation}
entonces, el campo de densidad en función de las coordenadas Lagrangianas será
\begin{equation}
\rho(\vec{r}, t) = \rho_{0} \left|\frac{\partial \vec{r}}{\partial t}\right|
=
\frac{\bar{\rho}}{\left|\delta_{ij} - b(t)\frac{\partial \vec{r}_{i}}{\partial q_{j}}\right|},\label{eqn 4.5}
\end{equation}
el tensor de deformación $\frac{\partial \vec{r}_{i}}{\partial q_{j}}$ lo toma en cuenta la evolución gravitacional del fluido y la densidad media $\bar{\rho}$ se define como $\bar{\rho}\equiv (a_{0}/a)^{3}\rho$. En un estado lineal, cuando $b(t)\vec{s}(\vec{q}) \leq 1$, la ecuación (\ref{eqn 4.5}) cambia a 
\begin{equation}
\rho(\vec{r}, t) = \bar{\rho}[1 - b(t)\vec{\nabla}_{q}\cdot\vec{s}(\vec{q})],\label{eqn 4.6}
\end{equation}
donde $\vec{\nabla}_{q} \equiv \frac{\partial\vec{q}}{\partial r}$. De forma más general, dado que la expresión (\ref{eqn 4.2})hace que el tensor de deformación se convierta en una matriz simétrica real, sus eigenvectores definen un conjunto de 3 ejes ortogonales principales. Después de diagonalizar, la ecuación (\ref{eqn 4.5}) puede escribirse en términos de sus eigenvalores, $-\alpha(\vec{q})$, $-\beta(\vec{q})$, $-\gamma(\vec{q})$, los cuales indican la contracción o expansión a lo largo de los tres ejes principales
\begin{equation}
\rho(\vec{r}, t) = \frac{\bar{\rho}}{[1 - b(t)\alpha(\vec{q})][1 - b(t)\beta(\vec{q})][1 - b(t)\gamma(\vec{q})]}.\label{eqn 4.7}
\end{equation}
Si los eigenvalores se ordenan de tal forma que $\alpha(\vec{q})\geq \beta(\vec{q})\geq \gamma(\vec{q})$, entonces, de manera que $b(t)$ crece, la primer singularidad en la ecuación (\ref{eqn 4.7}) ocurre en correspondencia con la primer coordenada Lagrangiana $\vec{q}_{1}$, donde $\alpha$ obtiene su valor máximo posible $\alpha_{max}$, en el tiempo $t_{1}$ de tal forma que $b(t_{1}) = \alpha_{max}^{-1}$. Esto corresponde a la formación de una \textit{rebanada de panqué} (estructura laminar) por contracción a lo largo de los ejes principales. Zeldovich argumentó que estos panqués son los que se producen primero debido al aglomeramiento gravitacional. Otras estructuras como filamentos y nodos provienen de contracción y expansión a lo largo de los ejes restantes.

Esta es una aproximación simple que describe la etapa no lineal de la evolución gravitacional de una distribución de materia, que se considera homogénea y sin colisiones. Utiliza teoría de perturbaciones no lineal para la densidad de materia. La aproximación Zeldovich se aplica de forma exitosa para describir la agrupación a gran escala de la distribución de los cúmulos de galaxias.

\begin{figure}
\centering
\includegraphics[width=0.65\textwidth]{./Figuras/Zeldovich}
\caption{\footnotesize{Estructura tridimensional de la Aproximación Zeldovich.}}\label{Zeld}
\end{figure}

Existe una gran cantidad de códigos para generar condiciones iniciales (MuSIC, pyICs, S-GenIC \cite{4.3}); en este trabajo se utilizó N-GenIC \cite{3.0.3}, dado que fue creado por Volker Springel en 2003 y sus archivos de salida son creados específicamente para GADGET, incluso este código fue utilizado para crear las condiciones iniciales para la simulación del milenio.

Las condiciones iniciales para la formación de estructura utilizada en este trabajo se indican en la tabla \ref{Tabla 4.1}. No se utilizaron partículas de materia bariónica debido a la implementación de Axion-Gadget.\\\\\\\\\\\\\

\begin{table}[]%
\caption{Condiciones Iniciales.}
\label{Tabla 4.1}\centering%
\begin{tabularx}{0.9\textwidth}{@{\extracolsep{\fill}}  l l c c }
\toprule%
&Descripción&Símbolo&Valor\\\toprule%
Densidades& Materia oscura&$\Omega_{0}$&0.268\\
($z=z_{f}$)&Energía oscura&$\Omega_{\Lambda}$&0.683\\
&Materia bariónica&$\Omega_{b}$&0.049\\\midrule
Simulación&Boxsize&$L$&[50 Mpc, 5 Mpc]\\\
&No. de partículas&$N$&$2^{21}\sim$2 Millones\\\midrule
Redshift&Inicial&$z_{init}$&[90, 70, 50, 30]\\
&Final&$z_{f}$&0\\\midrule
Otras cantidades&Parámetro de Hubble&$h$&0.7\\
&Espectro de potencias&$\sigma_{8}$&0.8\\\bottomrule
\end{tabularx}
\end{table}

\begin{table}[]%
\caption{Parámetros adicionales en las simulaciones.}
\label{Tabla 4.2}\centering%
\begin{tabularx}{0.9\textwidth}{@{\extracolsep{\fill}}  l l c c }
\toprule%
&Descripción&Cantidad&Unidades\\\toprule%
Sistema de unidades&Longitud(cm)&$3.08\times10^{21}$&1 kpc\\
&Masa (g)&$1.989\times10^{43}$&$10^{10}$ $M_{\odot}$\\
&Velocidad (cm/s)&$10^{5}$&1 km/s\\\midrule
Suavizados&$\Lambda$CDM($\epsilon$)&0.89&kpc\\
&SFDM($\lambda$)&1.414& kpc, pc\\\midrule
SFDM&FdmAxionMass ($M_{\chi}$)&$2.5\times10^{-22}$&eV\\
&FDmKernelLambda ($\lambda_{M}$)&1.41&kpc, pc\\\bottomrule

\end{tabularx}

\end{table}


\section{Ejecución de los códigos}
Gadget y Axion-Gadget cuentan con archivos de parámetros para cada simulación, lo importante es especificar distintos valores al ejecutar el código, ya que estos deben coincidir con los valores que se han generado en las condiciones iniciales.
\begin{figure}[]
\centering
\subfigure[Condiciones Iniciales]{\includegraphics[width=1\textwidth, height=0.4\textwidth]{./Figuras/condiciones1}}
\subfigure[Unidades y longitud de suavizado]{\includegraphics[width=0.9\textwidth, height=0.5\textwidth]{./Figuras/condiciones2}}
\caption{\footnotesize{Formato del archivo de parámetro para GADGET-2.}} \label{fig 4.1}
\end{figure}

Al utilizar el código Axion-Gadget deben añadirse 3 parámetros más, La masa de las partículas $M_{\chi}$ de FDM, un parámetro de normalización para la masa y su longitud de onda de Compton $\lambda_{M}$ (figura \ref{fig 4.2}). Las longitudes de suavizado escogidas tiene valores entre [pc] y [kpc] dado que la longitud de onda de Compton es de ese mismo orden, si se cambia el suavizado del archivo para ejecutar Axion-Gadget, el programa se detiene, esto es debido a que no puede interpretar de manera correcta los cálculos de la fuerza entre partículas. La modificación del código solo cambia la interacción entre partículas de materia oscura en rangos pequeños, dado que la presión entre ellas es de naturaleza cuántica.

Al hacer simulaciones para dos modelos de materia oscura no es necesario implementar materia bariónica, ya que implementar gas a las simulaciones implica doble carga de partículas, eventualmente esa doble carga lleva a tiempo invertido en simulación, añadir partículas de gas está contemplado para un trabajo suplementario a este.

\begin{figure}
\centering \includegraphics[width=0.8\textwidth]{./Figuras/ICs4}
\caption{\footnotesize{Parámetros adicionales para ejecutar Axion-Gadget.}}
\label{fig 4.2}
\end{figure}




Durante la etapa de simulación, se hizo notar que hay diferentes factores a tomar en cuenta antes de generar condiciones iniciales. Algunos de ellos fueron
\begin{itemize}
\item Iniciar las simulaciones desde $z$ grandes: dejar evolucionar más al sistema simulado.
\item Agregar función de transferencia a N-GenIC: el espectro de potencias de masa de halos de materia puede obtenerse de datos observacionales del CMB realizados por las misiones Planck a través de códigos como CAMB \cite{4.3.1}, CLASS \cite{4.3.1.2} o CosmoMC \cite{4.3.2}.
\item Resolución: simular cubos de escalas pequeñas con millones de partículas y cambiar parámetros de condiciones iniciales.
\item Simular cubos grandes ($> 50 $ Mpc): con la finalidad de analizar los halos masivos de materia oscura.
\end{itemize}

\begin{table}[]
\caption{Simulaciones hechas en este trabajo. El primer conjunto consiste en simulaciones con Gadget. El segundo conjunto fue para Axion-Gadget.}
\label{Tabla 4.3}\centering%
\begin{tabularx}{0.9\textwidth}{@{\extracolsep{\fill}}  l c c c c l }
\toprule%
ID&$N_{p}$&$L_{box}$&$z_{ini}$&Tiempo&Comentarios\\\toprule%
Set 1:\\
N1&$2^{21}$&50 Mpc&90&$\sim$4 horas&\\
N2&$2^{21}$&50 Mpc&70&$\sim$4 horas\\
N3&$2^{21}$&50 Mpc&50&$\sim$3 horas\\
N4&$2^{21}$&50 Mpc&30&$\sim$3 horas\\
N5&$2^{21}$&5 Mpc&90&$\sim$4 horas\\
N6&$2^{21}$&5 Mpc&70&$\sim$4 horas\\
N7&$2^{21}$&5 Mpc&50&$\sim$3 horas\\
N8&$2^{21}$&5 Mpc&30&$\sim$3 horas\\\midrule
Set 2:\\
SF1&$2^{21}$&50 Mpc&90&$\sim$7 horas&$\mathcal{O}(\lambda_{M})$kpc\\
SF2&$2^{21}$&50 Mpc&90&$\sim$7 horas&$\mathcal{O}(\lambda_{M})$pc\\
SF3&$2^{21}$&50 Mpc&70&$\sim$5 horas&$\mathcal{O}(\lambda_{M})$kpc\\
SF4&$2^{21}$&50 Mpc&70&$\sim$5 horas&$\mathcal{O}(\lambda_{M})$pc\\
SF5&$2^{21}$&50 Mpc&50&$\sim$4 horas&$\mathcal{O}(\lambda_{M})$kpc\\
SF6&$2^{21}$&50 Mpc&50&$\sim$4 horas&$\mathcal{O}(\lambda_{M})$pc\\
SF7&$2^{21}$&50 Mpc&30&$\sim$3 horas&$\mathcal{O}(\lambda_{M})$kpc\\
SF8&$2^{21}$&50 Mpc&30&$\sim$3 horas&$\mathcal{O}(\lambda_{M})$pc\\
SF9&$2^{21}$&5 Mpc&90&$\sim$7 horas&$\mathcal{O}(\lambda_{M})$kpc\\
SF10&$2^{21}$&5 Mpc&90&$\sim$7 horas&$\mathcal{O}(\lambda_{M})$pc\\
SF11&$2^{21}$&5 Mpc&70&$\sim$5 horas&$\mathcal{O}(\lambda_{M})$kpc\\\midrule
SF12&$2^{21}$&5 Mpc&70&$\sim$5 horas&$\mathcal{O}(\lambda_{M})$pc\\stop en $z = 2$\\\midrule
SF13&$2^{21}$&5 Mpc&50&$\sim$4 horas&$\mathcal{O}(\lambda_{M})$kpc\\\midrule
SF14&$2^{21}$&5 Mpc&50&$\sim$4 horas&$\mathcal{O}(\lambda_{M})$pc\\stop en $z = 2.57$\\\midrule
SF15&$2^{21}$&5 Mpc&30&$\sim$3 horas&$\mathcal{O}(\lambda_{M})$kpc\\
SF16&$2^{21}$&5 Mpc&30&$\sim$3 horas&$\mathcal{O}(\lambda_{M})$pc\\\bottomrule








%Sistema de unidades&Longitud(cm)&$3.08\times10^{21}$&1 kpc\\
%&Masa (g)&$1.989\times10^{43}$&$10^{10}$ $M_{\odot}$\\
%&Velocidad (cm/s)&$10^{5}$&1 km/s\\\midrule
%Suavizados&$\Lambda$CDM($\epsilon$)&1.81&kpc\\
%&SFDM($\lambda$)&1.14& kpc, pc\\\midrule
%SFDM&FdmAxionMass ($M_{\chi}$)&$2.5\times10^{-22}$&eV\\
%&FDmKernelLambda ($\lambda_{M}$)&1.14&kpc, pc\\\bottomrule
\end{tabularx}
\end{table}

La razón para ejecutar tantas simulaciones fue la de obtener distintos resultados respecto a las mismas condiciones iniciales generadas por la Teoría de Perturbaciones Lagrangiana de primer orden (1LPT) tomando en cuenta corrimientos al rojo grandes, medios y pequeños o tardíos, así como el impacto de la implementación del código modificado en escalas pequeñas.

Estos motivos han sido discutidos por mucho tiempo y de manera amplia, se ha llegado a la conclusión de que las condiciones iniciales y el tamaño de la simulación influyen en el resultado, como mencionan Bagla \& Rasad 2006 \cite{4.3.3} y L'Huillier et al. 2014 \cite{4.3.4}. Por ejemplo, iniciar desde un corrimiento al rojo muy alto causa que el desplazamiento sea pequeño con respecto a la longitud de resolución, produciendo inexactitud de las condiciones iniciales. Por otro lado, iniciar la simulación en corrimientos al rojo tardíos puede causar que la aproximación no sea confiable (se rompa) para las perturbaciones iniciales.

La implementación de Axion-Gadget en este estudio requiere declarar ciertas limitantes \cite{4.3.5}:
\begin{enumerate}
\item El tiempo de simulación es mayor debido a la presión cuántica entre partículas en escalas pequeñas.
\item El volumen de la simulación y el número de partículas están relacionados al resultado final, las simulaciones en cajas de tamaño $L = 50$ Mpc no son recomendadas, su resultado no es fiable.
\item Generar condiciones iniciales utilizando Teoría de Perturbaciones Lagrangiana de primer orden (1LPT), como se ha hecho en este trabajo, también tiene impacto en el resultado final.
\end{enumerate}

La elección de la masa del campo escalar también influye en el resultado para la creación de halos de materia oscura. Suárez \& Chavanis 2015; 2017 \cite{4.3.6, 4.3.7}, han calculado de forma analítica y numérica la masa $M_{\chi}$ del campo escalar y su longitud de onda de Jeans $\lambda_{J}$, que causa el colapso de materia oscura en halos para formar galaxias. La elección de una masa de $\mathcal{O}(M)\sim 10^{-22}$ eV  genera una longitud de inestabilidad de Jeans de aproximadamente $\mathcal{O}(\lambda_{J})\sim$ pc. Estudios relacionados están planeados para complementar este trabajo.

\subsection*{Suavizamiento gravitacional}
Como ya se ha mencionado, el paŕametro de longitud de suavizamiento gravitacional (opción \textsf{SofteningHalo} en Gadget-2), es un parámetro numérico crítico en simulaciones de $N$-cuerpos, ya que puede evitar que se llegue a singularidades cuando la distancia entre dos partícuas es muy pequeña. Sin embargo, en simulaciones con FDM (Axion-Gadget), esta longitud no puede ser cero, ni un parámetro completamente artificial porque la distribución de densidades la define un kernel Gaussiano. A diferencia de simulaciones con CDM, la longitud de suavizamiento gravitacional de FDM está fuertemente ligada a la longitud de onda del campo escalar.

Para una distribución de masa con distribución de densidad Gaussiana, la aceleración gravitacional de una partícula de prueba es
\begin{equation}
\ddot{\vec{r}}= \frac{G M(<r)}{r^{3}}\vec{r},
\end{equation}
donde $M(<r)$ es la masa encerrada en el radio $r$ del centro del kernel Gaussiano. La masa encerrada en este radio $r$ puede parametrizarse nuevamente como
\begin{equation*}
\frac{M(<r)}{M(r=\infty)} = \frac{\int_{0}^{r}\exp(\frac{-2r^{2}}{\lambda^{2}})4\pi r^{2}dr}{\int_{0}^{\infty}\exp(\frac{-2r^{2}}{\lambda^{2}})4\pi r^{2}dr}
\end{equation*}
\begin{equation}
= \textup{erf}(\frac{\sqrt{2}r}{\lambda}) -1.13\exp(-\frac{2r^{2}}{\lambda^{2}})\frac{\sqrt{2}r}{\lambda}
\end{equation}
donde erf($\frac{\sqrt{2}r}{\lambda}$) es una función de error del kernel Gaussiano, definida por
\begin{equation*}
\textup{erf}(z) \equiv \frac{2}{\sqrt{\pi}}\int_{0}^{z}\exp(-t^{2})dt
\end{equation*}
En su articulo, Zhang menciona que del cálculo analítico para la aceleración gravitacional de una distribución de densidad Gaussiana, el mejor fit de suavizamiento gravitacional tiene un valor de $\textsf{Soft}=0.89$ kpc. Por lo que este softening es el que se utiliza como parámetro central en las simulaciones para CDM.


\begin{figure}
\centering
\includegraphics[width=0.6\textwidth]{./Figuras/SOFT}
\caption{\footnotesize{Comparación de la curva de aceleración analítica de una distribución de densidad de masa gaussiana con diferentes longitudes de suavizado (Zhang et al. 2018).}}\label{fig 4.4}
\end{figure}

En la figura (\ref{fig 4.4}) puede observarse el cálculo de la aceleración debido a una distribución de densidad de masa gaussiana comparada con diversas longitudes de suavizado gravitacionales, siendo el $\textsf{Soft}=0.89$ kpc el que más se acerca al cálculo analítico. La longitud de onda $\lambda_{M}$ y el \textsf{softening} están correlacionados y su estudio profundo será objetivo de trabajos futuros.

\begin{figure}
\centering
%  \begin{adjustbox}{addcode={\begin{minipage}{\width}}{\caption{%
 %     \footnotesize{Simulación de $\Lambda$CDM con 4 millones de partículas en una caja de 50 Mpc.}
      }%\end{minipage}},rotate=90,center}
      \includegraphics[width=1.0\textwidth, height=0.7\textwidth]{./Figuras/LCDM_N1_7M}{\caption{%
      \footnotesize{Simulación de $\Lambda$CDM con 7 millones de partículas en una caja de 50 Mpc.}
      }\label{fig 3.2}%
  %\end{adjustbox}
\end{figure}

\section{Formación de estructura}
La formación de estructura de ambos modelos es, a grandes rasgos muy similar en lo que a escala se refiere. Por ejemplo, la Figura (\ref{Fig 4.6}) es el resultado de una simulación de una caja de 50 Mpc por lado y se observa la distribución de agrupaciones y cúmulos de  materia oscura en un $z\approx2$, haciendo después un acercamiento a la simulación. Estas imágenes se encuentran en escala logarítmica, siendo las partes rojas donde hay mayor concentración de partículas de materia oscura y que eventualmente formarán halos de galaxias

\begin{figure}
\centering
\subfigure[$\Lambda$CDM]{\includegraphics[width=0.42\textwidth]{./Figuras/LCDM_N1_113_2}}
\subfigure[SFDM]{\includegraphics[width=0.42\textwidth]{./Figuras/SFDM_113_2_kpc}}
\subfigure[$\Lambda$CDM]{\includegraphics[width=0.9\textwidth, height=0.4\textwidth]{./Figuras/LCDM_N1_113}}
\subfigure[SFDM]{\includegraphics[width=0.9\textwidth, height=0.4\textwidth]{./Figuras/SFDM_113_kpc}}
\caption{\footnotesize{Simulaciones N1 y SF1 en $z\approx2$.}}\label{Fig 4.6}
\end{figure}

Puede notarse de la figura (\ref{Fig 4.6}), que la diferencia entre ambos modelos ya es notable a simple vista, la estructura formada es similar en ambos casos, pero la diferencia en la formación de halos para $\Lambda$CDM y SFDM es bastante notable. Se observa que $\Lambda$CDM forma, en general, más halos pequeños de materia oscura alrededor de cúmulos grandes, y que estos halos tienen una densidad mayor, ya que las zonas rojas en los cúmulos se notan mayormente concentrados, a diferencia de SFDM, donde las grandes estructuras se reproducen al igual que $\Lambda$CDM, notando que la cantidad de halos pequeños creados alrededor de los cúmulos grandes es menor y que su densidad está mayormente distribuida sobre todo el halo.

Comparando similares simulaciones desde otros corrimientos al rojo, la diferencia persiste en lo que se ha observado anteriormente para escalas de 50 Mpc, aunque se ha mencionado que el corrimiento al rojo influye en el resultado final de las simulaciones, dadas las condiciones iniciales que se generan y que la caja simulada no sobrepasa los 100 Mpc, la diferencia a simple vista permanece inalterada (Figura \ref{Fig 4.7}), esto también se debe a que la resolución es muy baja, para simulaciones de este tamaño, 2 millones de partículas no son suficientes para obtener una diferencia mayor.

\begin{figure}
\centering
\subfigure[$\Lambda$CDM]{\includegraphics[width=0.4\textwidth]{./Figuras/LCDM_N1_138}}
\subfigure[SFDM]{\includegraphics[width=0.4\textwidth]{./Figuras/SFDM_129_kpc}}
\caption{\footnotesize{Simulaciones N1 y SF3 en $z\approx0.5$.}}\label{Fig 4.7}
\end{figure}
Es de recalcar que en escalas grandes, la longitud de onda de Compton $\lambda_{M}$ tuvo impacto en los resultados, al observar la figura (\ref{Fig 4.8}) dado que a pesar de que la cantidad de halos formados es similar, la simulación SF3 ($\mathcal{O}(\lambda)\sim$kpc) forma halos mayormente suavizados, a diferencia de SF4 ($\mathcal{O}(\lambda)\sim$pc), cuyos halos pueden observarse con mayor densidad, pero con menor formación de satélites. La longitud de onda de Compton si repercute en el resultado de la simulación, sin embargo, el cambio del valor de este parámetro no está justificado de manera física; en recientes discusiones y charlas, se ha llegado a la conclusión de que este resultado no dicta nada sobre la naturaleza de la materia oscura, dado que la implementación del código se efectúa en una caja pequeña, los parámetros de la simulación no son los correctos para esos valores, debe efectuarse un cálculo más para la frecuencia de Nyquist del archivo de condiciones iniciales así como cambiar el parámetro de normalización de la masa de Axion-Gadget $\Delta V_{0}$.

\begin{figure}
\centering
\subfigure[SF3($\mathcal{O}(\lambda)\sim$kpc)]{\includegraphics[width=0.4\textwidth]{./Figuras/SFDM_140_kpc}}
\subfigure[SF4($\mathcal{O}(\lambda)\sim$pc)]{\includegraphics[width=0.4\textwidth]{./Figuras/SFDM_140_pc}}
\caption{\footnotesize{Simulaciones SF3 y SF4 en $z\approx0.05$. }}\label{Fig 4.8}
\end{figure}
Sin embargo, al analizar simulaciones en cajas pequeñas, se obtiene un resultado no esperado para SFDM. Observando las imágenes de la simulación SF10 y comparando con SF9 (Figura \ref{Fig 4.9}), la estructura para ($\mathcal{O}(\lambda)\sim$kpc) no se forma y no tiene una geometría en lo más parecido a una distribución de halos de materia oscura. Este resultado es interesante, dado que, comparando el mismo resultado para SF10 ($\mathcal{O}(\lambda)\sim$pc), puede notarse una gran diferencia. Los halos de materia oscura para esta simulación sí se forman y sí es posible observar una buena estructura en esta escala. Las causas pueden ser muchas, aunque el candidato más fuerte a ser el origen del error es el parámetro de normalización de masa de Axion-Gadget $\Delta V_{0}$. Un estudio mejor detallado deberá hacerse en el futuro.

Como se ha mencionado, Suárez \& Chavanis 2015; 2017 \cite{4.3.6, 4.3.7}, calcularon que la longitud de onda de Jeans para el colapso gravitacional debería tomar un valor de $\mathcal{O}(\lambda_{J})\sim$ pc. La formación de estructura está ligada a la longitud de onda de Jeans por el principio de incertidumbre en escalas no mayores a 5 Mpc. Sin duda, estudiar y modificar el código para estas escalas será una tarea difícil pero que conviene llevar a cabo.



\begin{figure}
\centering
\subfigure[SF9($\mathcal{O}(\lambda)\sim$kpc)]{\includegraphics[width=0.4\textwidth]{./Figuras/SF10_kpc}}
\subfigure[SF10($\mathcal{O}(\lambda)\sim$pc)]{\includegraphics[width=0.4\textwidth]{./Figuras/SF10_pc}}
\caption{\footnotesize{Simulaciones SF9 y SF10 en $z\approx0.2$. No se aprecia una estructura para $\mathcal{O}(\lambda)\sim$kpc.}}\label{Fig 4.9}
\end{figure}


\section{Función de Masas de Halos }
Existen básicamente dos caminos para encontrar halos en una simulación. Uno de ellos, el método de sobredensidad, se basa en la identificación de regiones superdensas sobre una cierta región límite. Este límite puede definirse con respecto a la densidad crítica $\rho_{c} = 3H^{2}/ 8\pi G$. La masa $M_{\Delta}$ de un halo identificado de esta forma se define entonces como la masa encerrada en un radio $r_{\Delta}$ cuya densidad media es $\Delta_{\rho_{c}}$ (Voit 2005 \cite{4.4.1}).

El otro método, el algoritmo \textit{Friends-of-Friends} (FOF) encuentra vencindades de partículas y vecindades de vecindades definidas por una distancia de separación (Davis et al. 1985 \cite{4.4}). El algoritmo FOF identifica halos con formas arbitrarias ya que no se toman en cuenta suposiciones sobre la simetría de los halos. La masa del halo se define simplemente como la suma  de las partículas que pertenecen al halo.
 

La Función de Masas de Halos (la abundancia de halos como función de su masa), por sus siglas en inglés, \textit{Halo Mass Function} (HMF) es una cantidad fundamental que caracteriza la distribución no lineal de masa en el Universo. Existen muchos trabajos sobre la construcción de modelos teóricos para esta función y así calibrarla junto con simulaciones numéricas (Press \& Schechter 1973 \cite{4.4.2}, Mo \& White 1996 \cite{4.4.3}, Sheth \& Tormen 1999 \cite{4.4.4}, Jenkins et al. 2001 \cite{4.4.5}). 

La definición exacta de la función de masas varía mucho en la literatura. Para caracterizar diferentes ajustes, Jenkins introdujo la función de masas diferencial escalada  $f(\sigma, z)$ como una fracción de la masa total por el $\ln \sigma^{-1}$ perteneciente a los halos
\begin{equation}
F(\sigma, z) \equiv \frac{d \rho/\rho_{b}}{d \ln \sigma^{-1}}
=
\frac{M}{\rho_{b}(z)}\frac{d n(M,z)}{d\ln[\sigma^{-1}(M,z)]}.
\end{equation}
Donde $n(M,z)$ es la densidad de número de halos con masa $M$, $\rho_{b}(z)$ es la densidad del background en el corrimiento al rojo $z$, y $\sigma(M,z)$ es la variación lineal del campo de densidad. Esta definición de la función de masas tiene la ventaja de que una buena precisión no depende explícitamente del corrimiento al rojo, el espectro de potencias de masa o de la cosmología, ya que están descritas en la función $\sigma(M,z)$.

La función de masas de halos o  indica la población de halos de materia oscura en distintas épocas del Universo. Muchos estudios están de acuerdo en que esta puede aproximarse como la ley de potencias
\begin{equation}
dn/dm \sim m^{\alpha}\label{eqn 4.11}
\end{equation}
donde $n$ es el número de subhalos, m es la masa de los halos de materia oscura y $\alpha = 1.7 - 1.9$, este resultado es independiente del corrimiento al rojo y de la masa del halo principal (Moore et al. 1999 \cite{4.4.6}; Ghigna et al. 2000 \cite{4.4.7}; De Lucia et al. 2004 \cite{4.4.8}).

\begin{table}[]
\caption{Simulaciones adicionales}
\label{Tabla 4.4}\centering%
\begin{tabularx}{0.9\textwidth}{@{\extracolsep{\fill}}  l l c c c c c c l  }
\toprule%
&ID&$N_{p}$&$L_{box}$&$z_{ini}$&$\lambda_{M}$&$\epsilon$&Tiempo \\\toprule%
$\Lambda$CDM:\\
&N1&7077888&50 Mpc&23&N.A.&0.89 kpc&$\sim$10 horas\\\midrule
SFDM:\\
$M_{\chi}=2.5\times 10^{-22}$ eV&SFN2&7077888&50 Mpc&23&1.41 kpc&0.89 kpc&$\sim$8 horas\\
$M_{\chi}=2.5\times 10^{-23}$ eV&SFN3&7077888&50 Mpc&23&14.14 kpc&0.89 kpc&$\sim$8 horas\\\bottomrule
%SF4&$2^{21}$&50 Mpc&70&$\sim$5 horas&$\mathcal{O}(\lambda_{M})$pc\\
%SF5&$2^{21}$&50 Mpc&50&$\sim$4 horas&$\mathcal{O}(\lambda_{M})$kpc\\
%SF6&$2^{21}$&50 Mpc&50&$\sim$4 horas&$\mathcal{O}(\lambda_{M})$pc\\
%SF7&$2^{21}$&50 Mpc&30&$\sim$3 horas&$\mathcal{O}(\lambda_{M})$kpc\\
%SF8&$2^{21}$&50 Mpc&30&$\sim$3 horas&$\mathcal{O}(\lambda_{M})$pc\\
%SF9&$2^{21}$&5 Mpc&90&$\sim$7 horas&$\mathcal{O}(\lambda_{M})$kpc\\
%SF10&$2^{21}$&5 Mpc&90&$\sim$7 horas&$\mathcal{O}(\lambda_{M})$pc\\
%SF11&$2^{21}$&5 Mpc&70&$\sim$5 horas&$\mathcal{O}(\lambda_{M})$kpc\\\midrule
%SF12&$2^{21}$&5 Mpc&70&$\sim$5 horas&$\mathcal{O}(\lambda_{M})$pc\\stop en $z = 2$\\\midrule
%SF13&$2^{21}$&5 Mpc&50&$\sim$4 horas&$\mathcal{O}(\lambda_{M})$kpc\\\midrule
%SF14&$2^{21}$&5 Mpc&50&$\sim$4 horas&$\mathcal{O}(\lambda_{M})$pc\\stop en $z = 2.57$\\\midrule
%SF15&$2^{21}$&5 Mpc&30&$\sim$3 horas&$\mathcal{O}(\lambda_{M})$kpc\\
%SF16&$2^{21}$&5 Mpc&30&$\sim$3 horas&$\mathcal{O}(\lambda_{M})$pc\\\bottomrule








%Sistema de unidades&Longitud(cm)&$3.08\times10^{21}$&1 kpc\\
%&Masa (g)&$1.989\times10^{43}$&$10^{10}$ $M_{\odot}$\\
%&Velocidad (cm/s)&$10^{5}$&1 km/s\\\midrule
%Suavizados&$\Lambda$CDM($\epsilon$)&1.81&kpc\\
%&SFDM($\lambda$)&1.14& kpc, pc\\\midrule
%SFDM&FdmAxionMass ($M_{\chi}$)&$2.5\times10^{-22}$&eV\\
%&FDmKernelLambda ($\lambda_{M}$)&1.14&kpc, pc\\\bottomrule
\end{tabularx}
\end{table}

Otro set de simulaciones con mayor resolución (7 millones de partículas) fue llevado a cabo, añadiendo ahora la simualación SFN3, cuya masa y longitud de onda del campo escalar se cambiaron a un orden de $m = 2.5\times10^{-23}$ eV y $\lambda_{M}=14.142$ kpc. Las simulaciones tardaron cerca de 8 horas en terminarse ejecutadas en 8 procesadores.Con los datos de las simulaciones indicados en la tabla (\ref{Tabla 4.4}), se han analizado \textsf{snapshots} de las simulaciones en z $= 3, 2, 1$ y 0 respectivamente, con el objetivo de para observar la cantidad de halos creados en diferentes épocas y también el halo mass function de cada archivo, los datos obtenidos se indican en la tabla (\ref{Tabla 4.5}).




\begin{figure}
\centering
\subfigure[$\Lambda$CDM]{\includegraphics[width=0.9\textwidth]{./Figuras/COSMO001}}
\subfigure[SFN2 ($m \sim 10^{-22}$ eV)]{\includegraphics[width=0.9\textwidth]{./Figuras/LCDM_SF_2_007_Smooth_comp}}
\subfigure[SFN3 ($m \sim 10^{-23}$ eV)]{\includegraphics[width=0.9\textwidth]{./Figuras/COSMO003}}
\caption{\footnotesize{Simulaciones para $\Lambda$CDM y SFDM en z $\sim $0.}}\label{fig 4.10}
\end{figure}

En la figura (\ref{fig 4.10}) se observa la similitud entre ambos modelos de materia oscura, la diferencia entre ellos es muy sutil, dado que a simple vista es difícil observarlas. Para dicha tarea, se escribió un pequeño código de similitud de estructura, como se explica en el Apéndice C. Este código permite realizar una diferencia entre imágenes con dimensiones iguales. La similitud entre imágenes entra en un rango de [0,1], siendo 0 una imagen nada parecida, y 1 una imagen exactamente igual. La similitud obtenida para las simulaciones N1 y SFN2 fue de 0.887 y para las simulaciones N1 y SFN3 fue de 0.777, una similitud entre el 78 \% y 89 \% para las simulacionees. Dado que el \textsf{snapshot} es una imagen tridimensional, esta comparación se hace solo para una parte de ella y puede mejorarse utilizando procesos paralelos y analizando imágenes de manera más detallada.


\begin{table}
\caption{Datos de Halo Mass function}
\label{Tabla 4.5}\centering%
\begin{tabularx}{0.9\textwidth}{@{\extracolsep{\fill}}  l c c c }
\toprule%
&N1&SFN1&SFN3 \\\toprule%
z $\sim $3:\\
\textsf{snap}&N1\_{004}&SFN1\_{004}&SFN3\_{004}\\
$\lambda_{M}$&N.A.&1.41 kpc& 14.14 kpc\\
$\epsilon$&0.89 kpc&0.89 kpc& 0.89 kpc\\
\textsf{Groups}&2289&1815&252\\
\textsf{Mmax}&1277.184&1229.110&97.075\\
($\times10^{10}M_\odot$)\\
\textsf{Mmin}&4.335&4.335&4.335\\
($\times10^{10}M_\odot$)\\\midrule
z $\sim $2:\\
\textsf{snap}&N1\_{005}&SFN1\_{005}&SFN3\_{005}\\
$\lambda_{M}$&N.A.&1.41 kpc& 14.14 kpc\\
$\epsilon$&0.89 kpc&0.89 pc& 0.89 kpc\\
\textsf{Groups}&3458&2808&1107\\
\textsf{Mmax}&2367.107&2194.51&371.378\\
($\times10^{10}M_\odot$)\\
\textsf{Mmin}&4.335&4.335&4.335\\
($\times10^{10}M_\odot$)\\\midrule
z $\sim $1:\\
\textsf{snap}&N1\_{006}&SFN1\_{006}&SFN3\_{006}\\
$\lambda_{M}$&N.A.&1.41 kpc&14.14 kpc\\
$\epsilon$&0.89 kpc&0.89 kpc& 0.89 kpc\\
\textsf{Groups}&3995&3192&2438\\
\textsf{Mmax}&5245.197&4996.162&2532.079\\
($\times10^{10}M_\odot$)\\
\textsf{Mmin}&4.335&4.335&4.335\\
($\times10^{10}M_\odot$)\\\midrule
z $\sim $0:\\
\textsf{snap}&N1\_{007}&SFN1\_{007}&SFN3\_{007}\\
$\lambda_{M}$&N.A.&1.41 kpc&14.14 kpc\\
$\epsilon$&0.89 kpc&0.89 kpc& 0.89 kpc\\
\textsf{Groups}&3908&2871&3323\\
\textsf{Mmax}&26014.205&25280.607&N22566.453\\
($\times10^{10}M_\odot$)\\
\textsf{Mmin}&4.335&4.335&4.335\\
($\times10^{10}M_\odot$)\\\bottomrule
\end{tabularx}
\end{table} 

\begin{figure}
\centering
\subfigure[Escala logarítmica]{\includegraphics[width=0.9\textwidth , height=0.7\textwidth]{./Figuras/masses_LCDM_SFDM_7M_log}}
\subfigure[Escala lineal]{\includegraphics[width=0.9\textwidth , height=0.7\textwidth]{./Figuras/masses_LCDM_SFDM_linear_7M}}
%\subfigure[HMF($\Lambda$CDM (z$\sim$2))]{\includegraphics[width=0.5\textwidth]{./%Figuras/HMF_LCDM_N1_043}}
\caption{\footnotesize{Cantidad de halos creadas en las simulaciones.}}\label{fig 4.11}
\end{figure}

\begin{figure}
\centering
 \subfigure[HMF N1]{\includegraphics[width=0.7\textwidth, height=0.45\textwidth]{./Figuras/HMF_LCDM_7M_007}}
  \subfigure[HMF SFN2]{\includegraphics[width=0.7\textwidth, height=0.45\textwidth]{./Figuras/HMF_SF_10_22_eV_007_kpc}}
  \subfigure[HMF SFN2]{\includegraphics[width=0.7\textwidth, height=0.45\textwidth]{./Figuras/HMF_SF_10_23_eV_007_kpc}}
  \caption{\footnotesize{Función de masas de halos de materia oscura en z $= 0$ para los dos modelos de materia oscura.}}\label{fig. 4.12}
\end{figure}

Como puede observarse de la figura (\ref{fig 4.11}) y de los datos de la tabla (\ref{Tabla 4.5}) existe una gran diferencia de halos creados en las simulaciones, dependiendo del corrimiento al rojo $z$ y en el caso de campo escalar, la masa y longitud de onda. En $z=0$, la cantidad de halos detectados difiere entre 600 y 1000, en una simulación de esta escala este resultado es bastante favorable y es un acierto para el modelo de campo escalar.

Por otra parte, la función de masas de halos de materia oscura en $z = 0$ de la figura (\ref{fig. 4.12}) para ambos modelos cae dentro de los valores esperados dados por la ecuación (\ref{eqn 4.11}), salvo los subhalos de masas pequeñas ($\sim 10^{11} M_{\odot}$), pues en promedio los halos más masivos contienen mayor cantidad de subhalos que aquellos no tan masivos. Las simulaciones obedecen esta función universal y además, analizando otros $z$ se obtiene un comportamiento semejante, entonces se corrobora la no dependencia del corrimiento al rojo de la función de halos de masa. A pesar de que dicha función está predicha solamente para modelos de $\Lambda$CDM, el modelo SFDM también cumple con este comportamiento, probando entonces su similitud con el modelo estándar pero presentando ahora la solución a los satélites faltantes en observaciones y simulaciones. 








 %También se observa el Halo Mass Function de las simulaciones en varios corrimientos al rojo, Las variaciones que se aprecian son debidas a que las posiciones de los halos no son absolutas, el cubo está centrado en las coordenadas (25,25,25) Mpc, pero esta función cae dentro de los valores calculados y esperados para la función universal de población de halos de materia oscura en el Universo.


\section{Espectro de Potencias de Masa}
Se sabe que las galaxias se acumulan en grupos distribuidos en el espacio, la función de correlación de galaxias es una medida del grado de este acumulamiento en una distibución espacial o angular. El espectro de potencias de masa (Mass Power Spectrum) es la transfomada de Fourier de dicha función de correlación, descrita como
\begin{equation}
dP = \bar{n}^{2}(1+\xi(r_{12}))dV1dV2,\label{eqn 4.12}
\end{equation}
donde $\bar{n}$ es la densidad media de las galaxias y $\xi(r)$ es la distribución espacial. El espectro de potencias $P(k)$ se relaciona con esta función de correlación de dos puntos (ecuación (\ref{eqn 4.12})) como
\begin{equation}
\xi(r) = \frac{1}{2\pi^{2}}\int dk \;k^{2} P(k)\frac{\sin(kr)}{kr}\label{eqn 4.13}
\end{equation}
La escala de la longitud de onda $\lambda$ de una fluctuación se relaciona con el número de onda $k$ como $k = 2\pi/\lambda$.

El espectro de potencias es la cantidad predicha directamente de las teorías de formación a gran escala del Universo, en el caso de un campo de densidades en el cual las fluctuaciones provengan de una distribución Gaussiana, el espectro de potencias ofrece una descripción estadística completa de estas fluctuaciones. 

La amplitud de las fluctuaciones en diferentes escalas de longitud o equivalentemente en diferentes escalas de masa se describe con el espectro de potencias. El espectro primordial usualmente se asume como una ley de potencias dependiente de la escala $P(k) \propto k^{n}$ y una elección particular es la de invariante de escala con índice espectral $n=1$, en este caso, las fluctuaciones en diferentes escalas corresponden a la misma amplitud de fluctuaciones del campo gravitacional.

Por otra parte, las fluctuaciones crecen de diferente manera en diversas escalas, esta tasa de crecimiento se debe a una interacción entre la autogravitación, la presión y otros procesos de relajación. Estos efectos conducen a modificar el espectro primordial expresado en términos de una función de transferencia $T(k,z)$ como
\begin{equation}
P(k,z) = A(z)k^{n}T(k,z).\label{eqn 4.14}
\end{equation}
El factor de normalización $A(z)$ se determina observacionalmente. Existen muchos procesos teóricos que determinan este espectro, tales como las fluctuaciones de grandes escalas, las fluctuaciones dentro del horizonte, es decir la región donde la densidad de radiación es la responsable de la expansión del Universo mientras éste se va enfriando hasta que la densidad de materia y radiación es la misma.

Después del corrimiento al rojo en el cual la densidad de materia y radiación es la misma, las fluctuaciones de materia oscura pueden crecer de manera gravitacional, dado que no interactúa con la radiación.

Existen dos métodos de normalización del espectro de potencias de fluctuaciones de densidad. El primero utiiza la amplitud de las anisotropías de la temperatura del CMB. Datos de COBE de fluctuaciones de temperatura constriñen la amplitud del espectro de potencias en grandes escalas, esto es, $k \sim 0.001 \; h \; \textup{Mpc}^{-1}$. El segundo método es el conteo del número cúmulos emisores de rayos-X en el Universo local. La abundancia de estos objetos es sensible a la amplitud de las fluctuaciones de densidad en escalas alrededor $8 \; h \; \textup{Mpc}^{-1}$, que corresponden a una masa de $10^{15}h^{-1}M_{\odot}$ en un Universo con densidad crítica. 

La forma y la amplitud del espectro de potencias de estas fluctuaciones de densidad contiene información acerca de la cantidad y comportamiento de la materia en el Universo. Las mediciones directas del espectro de potencias de masa se obtienen de observaciones y conteos de cúmulos de galaxias. 

Uno de los códigos más conocidos para obtener este espectro de potencias de datos observacionales es \textit{CAMB} (Code for Anisotropies in the Microwave Background) \cite{4.3.1}, se modificó este código para obtener un espectro de potencias con los datos de la tabla (\ref{Tabla 4.1}),  así como la implementación del código \textit{POWMES} \cite{4.5}, el cual efectúa las transformaciones de Fourier en archivos de simulaciones de $N$-cuerpos. Utilizando estas herramientas, es posible obtener un espectro de potencias de datos observacionales proveniente de CAMB y compararlo con la reconstrucción del espectro para simulaciones de $N$-cuerpos en $z=0$.

\begin{figure}
\centering
\includegraphics[width=0.9\textwidth]{./Figuras/PS2}
\caption{\footnotesize{Espectro de potencias creado en CAMB comparado con las reconstrucciones de POWMES en $z=0$.}}
\end{figure}




\chapter{Conclusiones}
Durante más de un siglo, la cosmología se ha consolidado como una de las ramas de la ciencia con mayores retos y enigmas por descifrar. Su desarrollo ha sido tanto de forma teórica como observacional y existen diversas áreas dentro de la cosmología que tienen un futuro prometedor. El modelo estándar cosmológico sigue teniendo validez y aceptación dentro de la comunidad científica pues su parametrización concuerda en gran forma con datos observacionales en el Universo. No es la teoría definitiva, algunas predicciones hechas por este modelo no tienen solución alguna pero existen vías alternativas para tratar de mejorar esas predicciones o darle solución a problemas observacionales. 

La existencia de otras teorías de materia oscura permiten modelar su comportamiento en el Universo en grandes escalas, y su presencia en todas o la mayoría de las galaxias. Estas proposiciones son importantes ya que modifican el comportamiento de la dinámica de la materia oscura y buscan darle solución a las incosistencias que se presente en el modelo $\Lambda$CDM. 

Puesto que solo se obtienen datos observacionales del Universo, las simulaciones numéricas permiten recrear y experimentar con esos datos la dinámica del Universo como se ha comprendido hasta ahora, existe una gran cantidad de códigos numéricos que tienen la base teórica de $N$-cuerpos para materia oscura y SPH para gas y fluidos en simulaciones a gran escala ($\geq$ 50 Mpc).

Los códigos libres, son desarrollados con la teoría de $\Lambda$CDM en su mayoría, la capacidad de modificar la dinámica de la materia oscura dentro del código es un gran reto que requiere de un esfuerzo conjunto y años de estudio. En este trabajo se utilizó una modificación hecha para el modelo alternativo SFDM. Durante las simulaciones hechas con estos códigos surgieron varias dudas acerca de esta modificación, dado que los resultados en escalas pequeñas ($\leq$ 50 Mpc) no son favorables para el modelo, aunque existan publicaciones que respaldan SFDM en estas escalas, es necesario revisar a fondo la modificación o en su caso, desarrollar una modificación propia que tenga mejores resultados en esas escalas.

Los resultados obtenidos para grandes escalas respaldan bien el modelo de SFDM, el problema de satélites faltantes en $\Lambda$CDM se resuelve en las simulaciones de campo escalar, dado que la interacción cuántica entre las partículas de materia oscura puede ser atractiva o repulsiva dependiendo de su longitud de onda de Compton, también el problema del CUSP-CORE se minimiza por esta interacción, analizar los perfiles de densidad de halos de materia oscura será un trabajo futuro utilizando el clúster computacional ABACUS del CINVESTAV para realizar simulaciones con mayor resolución y con datos observacionales recientes, los datos de la misión Planck 2018 son los más actualizados al momento de la publicación de esta tesis.

Este trabajo fue una introducción a los códigos de simulación y al análisis de datos y tendrá una continuación enfocada a mejorar la visualización y la extracción de datos de esas simulaciones. El análisis de datos y los métodos numéricos y estadísticos se utilizan como herramienta principal para comprender los datos obtenidos de simulaciones. 

Existe gran cantidad de proyectos para recopilación y análisis de datos dentro del área de cosmología y en otras áreas de la física y matemáticas. Su uso no está limitado a estas áreas por supuesto. Estos recursos son utilizados también para estudiar las altas y bajas en la bolsa de valores o dentro de la industria, pues muchas empresas buscan profesionistas con perfiles de analistas de datos para desarrollar software o redes neuronales para programar alguna iteligencia artificial. El recurso computacional es necesario para seguir mejorando el avance científico de nuestra época.



 
\appendix 

\chapter{Principio de Mínima Acción}\label{Apend. A}
El principio de mínima acción o principio de Hamilton establece que, para sistemas en mecánica clásica, su evolución temporal es tal que la acción tiende a ser una cantidad mínima. La acción tiene unidades de energía por tiempo y se define como 
\begin{equation}
S = \int_{t_{1}}^{t_{2}}L(q,\dot{q})dt,\label{A1}
\end{equation}
donde $L$ es el Lagrangiano del sistema. Para un sistema clásico cualquiera, se puede encontrar su trayectoria minimizando su acción
\begin{equation}
\delta S = \delta \int_{t_{1}}^{t_{2}}L(q,\dot{q})dt = 0,\label{A2}
\end{equation} 
donde $\delta$ es una variación en la acción. Es así que se puede asegurar que, de las diferentes trayectorias que pudiese tener una partícula de un sistema desde un punto inicial a un punto final, la trayectoria real será la que minimice la acción, aunque la distancia de esa trayectoria no es necesariamente la más corta entre dos puntos del espacio.
\subsection*{Densidad Lagrangiana}
En este formalismo, el Lagrangiano será una función que tome funciones como argumento, es decir un funcional. El objetivo es obtener el comportamiento dinámico de un campo para después encontrar sus ecuaciones de movimiento utilizando el principio de mínima acción. Las ecuaciones de Euler-Lagrange para teoría de campos provienen de requerir que la acción permanezca invariante ante pequeñas variaciones en el campo. Dada $\phi$ una función, entonces
\begin{equation}
\phi \rightarrow \phi + \delta\phi\label{A3}
\end{equation}
\begin{equation}
\partial_{\mu}\phi \rightarrow \partial_{\mu}(\delta\phi).\label{A4}
\end{equation}
Así, el Lagrangiano tiene la siguiente forma
\begin{equation}
\mathcal{L}(\phi,\partial_{\mu}\phi) \rightarrow \mathcal{L}(\phi + \delta\phi, \partial_{\mu}\phi + \partial_{\mu}(\delta\phi),\label{A5}
\end{equation}
entonces
\begin{equation}
\delta \mathcal{L}(\phi,\partial_{\mu}\phi) = \frac{\partial \mathcal{L}}{\partial \phi}\delta\phi + \frac{\partial \mathcal{L}}{\partial(\partial_{\mu}\phi)}\partial_{\mu}(\delta\phi).\label{A6}
\end{equation}
Aplicando el principio de mínima acción se tiene que
\begin{equation}
\delta S = \int d^{4}x \left[\frac{\partial \mathcal{L}}{\partial \phi}\delta\phi + \frac{\partial \mathcal{L}}{\partial(\partial_{\mu}\phi)}\partial_{\mu}(\delta\phi)\right],\label{A7}
\end{equation}
que al realizar la integración por partes en el segundo término, se encuentra
\begin{equation}
\int d^{4}x \frac{\partial \mathcal{L}}{\partial(\partial_{\mu}\phi)}\partial_{\mu}(\delta\phi)
 = 
 \int d^{4}x\partial_{\mu}\left(\frac{\partial\mathcal{L}}{\partial(\partial_{\mu}\phi)}\delta\phi^{i}\right)
 -
 \int d^{4}x\partial_{\mu}\left(\frac{\partial\mathcal{L}}{\partial(\partial_{\mu}\phi)}\right)\delta\phi,\label{A8}
\end{equation}
para simplificar este resultado, se hace mediante el teorema de Stokes en el primer término. Si $V^{\mu}$ es un vector del campo sobre una región $\Sigma$ con frontera $\partial\Sigma$, el teorema de Stokes etablece que 
\begin{equation}
\int_{\Sigma}\nabla_{\mu}V^{\mu}d^{n}x = \int_{\partial\Sigma}n_{\mu}V^{\mu}d^{n-1}x,\label{A9}
\end{equation}
donde $n_{\mu}$ es un vector normal a la superficie $\Sigma$. Sustituyendo en la ecuación (\ref{A8}) se obtiene
\begin{equation}
\int_{\Sigma} d^{4}x\partial_{\mu}\left(\frac{\partial\mathcal{L}}{\partial(\partial_{\mu}\phi)}\delta\phi\right)
=
\int_{\partial\Sigma}d^{3}xn_{\mu}\frac{\partial\mathcal{L}}{\partial(\partial_{\mu}\phi)}\delta\phi.\label{A10}
\end{equation}
La variación es nula en la frontera, entonces
\begin{equation}
\int_{\partial\Sigma}d^{3}xn_{\mu}\frac{\partial\mathcal{L}}{\partial(\partial_{\mu}\phi)}\delta\phi = 0,\label{A11}
\end{equation}
entonces, la ecuación (\ref{A7}) se reduce a
\begin{equation}
\int d^{4}x \left[\frac{\partial\mathcal{L}}{\partial\phi} -
\partial_{\mu}\left(\frac{\partial\mathcal{L}}{\partial(\partial_{\mu}\phi)}\right)\right]\delta\phi = 0,\label{A12}
\end{equation}
que, para satisfacer la igualdad, el argumento de la integral debe ser cero, es decir 
\begin{equation}
\frac{\partial\mathcal{L}}{\partial\phi} -
\partial_{\mu}\left(\frac{\partial\mathcal{L}}{\partial(\partial_{\mu}\phi)}\right) = 0,\label{A13}
\end{equation}
las cuales son las ecuaciones de Euler-Lagrange para campos.


\chapter{Instalación de GADGET-2}\label{Apend.B}
GADGET-2 es un código fuente de dominio libre, de manera que cualquier persona pueda hacer simulaciones con el. Las instrucciones para compilar y correr el código dependen en gran manera de la plataforma que se utilice; si el usuario tiene Linux o UNIX, las herramientas necesarias para compilarlo están completas. En MacOS, se necesita una actualización de \textsf{Xcode}, el cual incluye todos los compiladores necesarios para instalar el código. En Windows, es probable que tenga que obtenerse \textsf{cygwin}, el cual proporciona soporte completo de UNIX en sistemas.

Primero, se necesita descargar el siguiente software:
\begin{enumerate}
\item \underline{Gadget-2.0.7}.
\item Versión \underline{1.9} o superior de \underline{GNU scientific library} (GSL).
\item Versión \underline{2.1.5} de \underline{FFTW fast Fourier Transform in the West}.
\item Una librería de procesamiento en paralelo, como Message Passing Interface (MPI) o como \textsf{Open-MPI} o \textsf{MPICH}.
\end{enumerate}

\textsf{Open-MPI} viene incluido en MacOS, por lo que usuarios con ese sistema operativo no requieren descargarlo. No descargar una versión \underline{3.x} de FFTW, ya que no incluye soporte para procesamiento en paralelo.

Una vez que se tiene todo el software descargado, se requiere extraer el \textsf{.tar.gz} e instalar. Todo el proceso se hace en una Terminal para un sistema operativo Linux, la instalación prosigue de la siguiente manera:
\begin{enumerate}
\item Extraer el software:

\textsf{jazhiel@PC$\sim$/Documents/code: tar -xzvf fftw-2.1.5.tar.gz}

\textsf{jazhiel@PC$\sim$/Documents/code: tar -xzvf gsl-1.9.tar.gz}

\textsf{jazhiel@PC$\sim$/Documents/code: tar -xzvf gadget-2.0.7.tar.gz}

\item Instalar GSL:

\textsf{jazhiel@PC$\sim$/Documents/code: cd gsl-1.9/}

\textsf{jazhiel@PC$\sim$/Documents/code/gsl-1.9: ./configure}

\textsf{snip: muchos outputs de diagnóstico}

\textsf{jazhiel@PC$\sim$/Documents/code/gsl-1.9: make}

\textsf{jazhiel@PC$\sim$/Documents/code/gsl-1.9: sudo make install}

Esta es una instalación en una carpeta \textsf{root}. Si no se tienen privilegios de administrador es probable que se necesite instalar en una carpeta aparte, esto se hace con el comando \begin{verbatim} --prefix=/path/to/folder/
\end{verbatim}  donde \textsf{path} es la dirección del directorio donde se instalará el software.

\item Instalar FFTW:

\textsf{jazhiel@PC$\sim$/Documents/code: cd fftw-2.1.5/}

\textsf{jazhiel@PC$\sim$/Documents/code/fftw-2.1.5: ./configure - -enable-mpi - -enable-type-prefix - -enable-float}

\textsf{jazhiel@PC$\sim$/Documents/code/fftw-2.1.5: make}

\textsf{Este es un buen momento para ir por un café.}

\textsf{jazhiel@PC$\sim$/Documents/code/fftw-2.1.5: sudo make install}

\item Editar el \textsf{Makefile} de Gadget:

GADGET tiene una increíble cantidad de parámetros para compilar, los cuales se describen de manera extensa en la guía de usuario. Hay muchos cambios que se deben hacer al \textsf{makefile} de Gadget para que compile correctamente.  En el directorio donde se extrajo Gadget, luego al directorio de \textsf{Gadget-2} dentro de ese directorio. Abrir el \textsf{makefile} en un editor de textos (e.g. \textsf{vim, emacs, textedit, notepad}), editar los parámetros de compilación para que la parte inicial del \textsf{makefile} luzca así:
\begin{verbatim}

#------------------------- Basic operation mode of code
#OPT += -DPERIODIC
OPT += -DUNEQUALSOFTENINGS

#--------------------Things that are always recommended
OPT += -DPEANOHILBERT
OPT += -DWALLCLOCK

#--------------------TreePM Options
#OPT += -DPMGRID=128
#OPT += -DPLACEHIGHRESREGION=3
#OPT += -DENLARGEREGION=1.2
#OPT += -DASMTH=1.25
#OPT += -DRCUT=4.5

#------------------------Single/Double Precision
#OPT += -DDOUBLEPRECISION
#OPT += -DDOUBLEPRECISION_FFTW

#-----------------------Time integration options
OPT += -DSYNCHRONIZATION
#OPT += -DFLEXSTEPS
#OPT += -DPSEUDOSYMMETRIC
#OPT += -DNOSTOP_WHEN_BELOW_MINTIMESTEP
#OPT += -DNOPMSTEPADJUSTMENT

#-------------------Output
#OPT += -DHAVE_HDF5
#OPT += -DOUTPUTPOTENTIAL
#OPT += -DOUTPUTACCELERATION
#OPT += -DOUTPUTCHANGEOFENTROPY
#OPT += -DOUTPUTTIMESTEP

#------------------Things for special behaviour
#OPT += -DNOGRAVITY
#OPT += -DNOTREERND
#OPT += -DNOTYPEPREFIX_FFTW
#OPT += -DLONG_X=60
#OPT += -DLONG_Y=5
#OPT += -DLONG_Z=0.2
#OPT += -DTWODIMS
#OPT += -DSPH_BND_PARTICLES
#OPT += -DNOVISCOSITYLIMITER
#OPT += -DCOMPUTE_POTENTIAL_ENERGY
#OPT += -DLONGIDS
#OPT += -DISOTHERM_EQS
#OPT += -DADAPTIVE_GRAVSOFT_FORGAS
#OPT += -DSELECTIVE_NO_GRAVITY=2+4+8+16

#----------------------Testing and Debugging options
#OPT += -DFORCETEST=0.1

#------------------------- Glass making
#OPT += -DMAKEGLASS=262144

El cambio más importane es comentar la opción de
HAVE_HDF5 para evitar errores de compilación.

Luego, se debe editar nuevamente el makefile para 
indicar dónde se han instalado las librerías GSL y FFTW,
mi makefile luce así:

#--------------------------------------------------------
# Here, select compile environment for the target machine. 
#This may need adjustment, depending on your local system. 
#Follow the examples to add additional target platforms, 
#and to get things properly compiled.
#--------------------------------------------------------

#------------------ Select some defaults

CC = mpicc # sets the C-compiler
OPTIMIZE = -O2 -Wall -g # sets optimization and warning 
                        #flags

MPICHLIB = -lmpich

#-------------------Select target computer

SYSTYPE="MPA"

#------------------Adjust settings for target computer

ifeq ($(SYSTYPE),"MPA")
CC       =  mpicc   
OPTIMIZE =  -O3 -Wall
GSL_INCL =  -I/usr/local/include
GSL_LIBS =  -L/usr/local/lib  -Wl,"-R /usr/common/pdsoft/
\lib"
FFTW_INCL=  -I/usr/local/include
FFTW_LIBS=  -L/usr/local/lib
MPICHLIB =  -L/usr/lib
#HDF5INCL =  
#HDF5LIB  =  -lhdf5 -lz 
endif
\end{verbatim}
Puede definirse un \textsf{SYSTYPE} propio para indicar a GADGET las direcciones donde se ha instalado las librerías de GSL y FFTW. Por default, están en \textsf{/usr/local/}. Es importante guardar los cambios que se han hecho y leer el manual del usuario de GADGET, ya que dependiendo de lo que se quiera simular, el \textsf{makefile} tiene que editarse; la configuración anterior es para simular la colisión de dos galaxias.

Para correr esta colisión, se recomienda crear un folder de trabajo con los ejecutables y archivos de parámetros:

\textsf{jazhiel@PC$\sim$/Documents/code/Gadget-2.0.7: mkdir galaxy}

Copiar el ejecutable \textsf{Gadget2} en el folder \textsf{galaxy}:

\textsf{jazhiel@PC$\sim$/Documents/code/Gadget-2.0.7: cp Gadget2/Gadget2 galaxy/}

Copiar los archivos de parámetros en el folder \textsf{galaxy}:

\textsf{jazhiel@PC$\sim$/Documents/code/Gadget-2.0.7: cp Gadget2/parameterfiles/
galaxy.param galaxy/}

Entrar en el folder \textsf{galaxy}:

\textsf{jazhiel@PC$\sim$/Documents/code/Gadget-2.0.7: cd galaxy}

Editar el archivo \textsf{galaxy.param} para que las dos primeras líneas luzcan de la siguiente manera:

\begin{verbatim}
% Relevant files

InitCondFile /path/to/Gadget-2.0.7/ICs/galaxy_littleendian
\.dat
OutputDir /path/to/Gadget-2.0.7/galaxy/
\end{verbatim}

Debe cambiarse la dirección al folder de condiciones iniciales del código y el directorio de \textsf{output} en donde se ha creado el folder \textsf{galaxy}. Ahora se tiene todo para correr la primera simulación con el siguiente comando:

\textsf{jazhiel@PC$\sim$/Documents/code/Gadget-2.0.7/galaxy: mpirun -np 2 ./Gadget2 galaxy.param}

Este comando llama un programa de MPI para procesamiento en paralelo, en este caso Gadget. El parámetro \textsf{-np 2} indica cuántos procesadores se utilizarán para la ejecución de Gadget, es decir, 2. Si se cuenta con más de dos procesadores puede cambiarse \textsf{-np 2} al número de procesadores disponibles. Si no se cuenta con procesamiento en paralelo, invocar el comando:

\textsf{jazhiel@PC$\sim$/Documents/code/Gadget-2.0.7/galaxy: ./Gadget2\\ galaxy.param}

será suficiente, aunque más tardado. Se recomienda incrementar el número de archivos de salida para crear una animación de la colisión de las galaxias.
\end{enumerate}

\chapter{Diferencia de Imágenes}
Resulta de gran utilidad realizar una comparación de las imágenes creadas en los archivos de salida, para este fin se elaboró un pequeño script en Python, el cual realiza una diferenciación entre dos imágenes que a simple vista parecen similares. Este script utiliza paquetes y librerías propias de Python necesarias para el procesamiento de imágenes, siendo la paquetería \textsf{SSIM} la base del script.

Lo que realiza \textsf{SSIM} es un Índice de Similitud de Estructura \cite{4.6} que tiene la siguiente forma
\begin{equation}
SSIM(x,y) = \frac{(2\mu_{x}\mu_{y}+c_{1})(2\sigma_{xy}+c_{2})}{(\mu_{x}^{2}+\mu_{y}^{2}+c_{1})(\sigma_{x}^{2}+\sigma_{y}^{2}+c_{2})}.\label{SSIM}
\end{equation}
\textsf{SSIM} trata de modelar el cambio percibido en la informaci\'on estructural de la imagen. La ecuación (\ref{SSIM}) se utiliza para comparar dos \textit{ventanas} o porciones de la imagen en lugar de la imagen completa. Esto conlleva a una aproximaci\'on más exacta que puede contar los cambios en la estructura de la imagen.

Los parámetros de la ecuación (\ref{SSIM}) incluyen las posiciones $(x,y)$ de la ventana de lado $N\times N$ de cada imagen, el promedio de la intensidad de píxeles en la dirección $x$ e $y$ y la varianza de las intensidades igualmente en dirección $x$ e $y$, así como la covarianza. Esto permite valores de $SSIM \in [-1,1]$, siendo el valor de $1$ una perfecta similitud. 

El script convierte ambas imágenes en un arreglo de $8$-bits para después procesar los píxeles de cada imagen y crea regiones, en este caso de color rojo, donde identifica diferencias entre el promedio y la varianza de píxeles. A pesar de tener una buena resoluci\'on dada la cantidad de partículas, procesar las imágenes de esta forma es engañoso, dado que los archivos de salida de las simulaciones crean imágenes en un ambiente tridimensional.

Este script está escrito en Python y puede ejecutarse para realizar una comparación entre dos imágenes similares:
\begin{verbatim}
# importar paquetes necesarios
from skimage.measure import compare_ssim
import argparse
import imutils
import cv2
 
# construir  argument parse and analizar los argumentos
ap = argparse.ArgumentParser()
ap.add_argument("-f", "--first", required=True,
	help="first input image")
ap.add_argument("-s", "--second", required=True,
	help="second")
args = vars(ap.parse_args())
\end{verbatim}

\textsf{- -first} y \textsf{- -second} serán los argumentos para las direcciones de las imágenes que se quieren comparar. Luego se carga cada imagen y se convierte a una escala de grises

\begin{verbatim}
# cargar imagenes de input
imageA = cv2.imread(args["first"])
imageB = cv2.imread(args["second"])
 
# convertir a escala de grises
grayA = cv2.cvtColor(imageA, cv2.COLOR_BGR2GRAY)
grayB = cv2.cvtColor(imageB, cv2.COLOR_BGR2GRAY)
\end{verbatim}

Se calcula el Índice de Similitud de Estructura (SSIM)
\begin{verbatim}
# Calcular Structural Similarity Index (SSIM) entre
# imagenes, asegura que la imagen de diferencia sea un 
#output
(score, diff) = compare_ssim(grayA, grayB, full=True)
diff = (diff * 255).astype("uint8")
print("SSIM: {}".format(score))
\end{verbatim}

Utilizando la función \textsf{compare} se calcula un \textsf{score} y una imagen de diferencia \textsf{diff}. \textsf{score} representa el índice de similitud de estructura entre imágenes y puede arrojar el valor entre $[-1,1]$, siendo $1$ una ``similitud perfecta''.

La imagen \textsf{diff} contiene las \textit{diferencias} reales entre las imágenes que se desea visualizar. Esta imagen está representada como un arreglo de datos tipo \textsf{float} en el rango $[0,1]$, el arreglo se convierte a 8-bits, todos enteros en el rango $[0,255]$. 

Se buscan los contornos para que pueda colocarse rectángulos alrededor de las regiones identificadas como ``diferentes''
\begin{verbatim}
# limitar(threshold) la imagen diferencia, 
#luego encontrar contornos para
# obtener regiones de las imagenes que difieran
thresh = cv2.threshold(diff, 0, 255,
	cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]
cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,
	cv2.CHAIN_APPROX_SIMPLE)
cnts = cnts[0] if imutils.is_cv2() else cnts[1]
\end{verbatim}

Ya que se tienen los contornos almacenados en una lista, se dibujan rectángulos alrededor de las diferentes regiones en cada imagen
\begin{verbatim}
# loop alrededor de contornos
for c in cnts:
	# calcular la bounding box del contorno y dibujar 
	# bounding box en ambas imagenes para representar donde 
	# difieren las dos imagenes
	(x, y, w, h) = cv2.boundingRect(c)
	cv2.rectangle(imageA, (x, y), (x + w, y + h), (0, 0, 255), 2)
	cv2.rectangle(imageB, (x, y), (x + w, y + h), (0, 0, 255), 2)
 
# mostrar output de imagenes
cv2.imshow("Original", imageA)
cv2.imshow("Modified", imageB)
cv2.imshow("Diff", diff)
cv2.imshow("Thresh", thresh)
cv2.waitKey(0)
\end{verbatim}

Pueden guardarse las imágenes en la carpeta que se desee
\begin{verbatim}
cv2.imwrite('path/to/folder/Original.png', imageA)
cv2.imwrite('path/to/folder/Modified.png', imageB)
cv2.imwrite('path/to/folder/Diff.png', diff)
cv2.imwrite('path/to/folder/Thresh.png', thresh)
\end{verbatim}

finalmente, para ejecutar el script
\begin{verbatim}
python image_diff.py --first /path/to/first/image1.png
--second /path/to/second/image2.png
\end{verbatim}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%BIBLIOGRAFIAPAPUUU$%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%---------------------------------------------------------------------------------%
\cleardoublepage
\addcontentsline{toc}{chapter}{Bibliografía}
\bibliographystyle{acm} % estilo de la bibliografía.
\bibliography{yyyy} % yyyy.bib es el fichero donde está salvada la bibliografía.
\begin{thebibliography}{a}

%1%
\bibitem{1.01} \textsc{Ryden, B. S. (2003)},
\textit{Introduction To Cosmology},
San Francisco: Addison-Wesley

%1%
\bibitem{1.02} \textsc{Battaner, E. (2015)},
\textit{Grandes estructuras del universo: El cosmos a gran escala},
RBA Contenidos Editoriales y Audiovisuales, S.A.U.
%2%
\bibitem{1.1} \textsc{Hubble, E. (1929)}
\textit{A Relation between Distance and Radial Velocity among Extra-Galactic Nebulae}
Proceedings of the National Academy of Sciences of the United States of America, 
vol. 15, Issue 3, pp. 168-173

\bibitem{1.1.01} \textsc{Eddington, A. (1933)},
\textit{The Expanding Universe: Astronomy's 'Great Debate'. 1900-1931},
Press Syndicate of the University of Cambridge

\bibitem{1.1.02} \textsc{Liddle, A. R.; Lyth, D. H.; (2000)},
\textit{Cosmological Inflation and Large-Scale Structure},
Cambridge University Press

\bibitem{1.4} \textsc{Schutz, B. (2009)},
The Einstein field equations. In
\textit{A first Course in General Relativity},
pp. 184-202, Cambridge: Cambrige University Press

\bibitem{1.2} \textsc{ Grøn, O. Hervik, S. (2004)},
Dynamics of Homogeneus and Isotropic cosmologies. In
\textit{Einstein's General Theory of Relativity},
University of Oslo, pp. 265-267
%19%
\bibitem{1.3} \textsc{Schutz, B. (2009)},
Perfect fluids in special relativity. In 
\textit{A first Course in General Relativity},
pp. 84-110, Cambridge: Cambridge University Press
%3%
\bibitem{1.1.1} \textsc{Zwicky, F. (1937)},
\textit{On the Masses of Nebulae and of Clusters of Nebulae},
Astrophysical Journal, vol. 86, p.217
%4%
\bibitem{1.1.2} \textsc{Rubin, V. C.; Ford, W. K. (1970)},
\textit{Rotation of the Andromeda Nebula from a Spectroscopic Survey of Emission Regions},
Astrophysical Journal, vol. 159, p.379 
\bibitem{1.1.2.1} \textsc{Penzias, A. A.; Wilson, R., W. (1965)}
\textit{A Measurement of Excess Antenna Temperature at 4080 Mc/s}
Astrophysical Journal, vol. 142, p.419-421
%5%
\bibitem{1.1.3} \textsc{Spergel, D.N. et al. (2007)},
\textit{Wilkinson Microwave Anisotropy Probe (WMAP) Three Year
Observations: Implications for Cosmology},
ArXiv preprint, arXiv:astro-ph/0603449v2
%6%
\bibitem{1.1.4} \textsc{Mandolesi, N.; Burigana, C.; Gruppuso, A.; Natoli, P. (2013)},
\textit{The Planck Mission: Recent Results, Cosmological and Fundamental Physics Perspectives},
International Journal of Modern Physics D, vol. 22, Issue 14, id. 1330029
%7%
\bibitem{1.1.5} \textsc{Spergel, D. N.; Bolte, M.; Freedman, W. (1997)},
\textit{The age of the universe},
Proceedings of the National Academy of Sciences of the United States of America, vol. 94 pp. 6579-6584
%8%
\bibitem{1.1.6} \textsc{Sarkar, S. (1996)},
\textit{Big Bang nucleosynthesis and physics beyond the Standard Model},
ArXiv preprint, arXiv:hep-ph/9602260v2
%9%
\bibitem{1.1.7} \textsc{Burles, S.; Nollet, K. M.; Turner, M. S. (2000)},
\textit{What Is The BBN Prediction for the Baryon Density and How Reliable Is It?},
ArXiv preprint, arXiv:astro-ph/0008495v4
%10%
\bibitem{1.1.8} \textsc{Olive, K. A.; Stelgman G.; Walker, T. P.; (1999)},
\textit{Primordial Nucleosynthesis: Theory and Observations},
ArXiv preprint arXiv:astro-ph/9905320v1 
%11%
\bibitem{1.1.9} \textsc{Blanton, M. R. et al. (2017)},
\textit{Sloan Digital Sky Survey IV: Mapping the Milky Way, Nearby Galaxies, and the Distant Universe},
The Astronomical Journal, vol. 154, Issue 1, pp. 35 (2017)

\bibitem{1.2.3} \textsc{Sasaki, M. (1986)},
\textit{Large Scale Quantum Fluctuations in the Inflationary Universe},
Progress of Theoretical Physics, vol. 76, Issue 5, pp. 1036–1046
%12%
\bibitem{1.2.1} \textsc{Guth, A. H. (1981)},
\textit{Inflationary universe: A possible solution to the horizon and flatness problems},
Physical Review D (Particles and Fields), vol. 23, Issue 2, 15 January 1981, pp.347-356
%13%
\bibitem{1.2.2} \textsc{Peebles, P. J. E.; Ratra, B. (2002)},
\textit{The Cosmological Costant and Dark Energy},
ArXiv preprint arXiv:astro-ph/0207347v2
%14%

%15%
%16%
%18%
%20%

%21%
\bibitem{1.2.03} \textsc{López-Correidora, M. (2017)},
\textit{Tests and problems of the standard model in Cosmology},
ArXiv preprint arXiv:1701.0872


\bibitem{b1} \textsc{Navarro, J. F.; Frenk, C. S.; White, S. D. M. (1996)},
\textit{The Structure of Cold Dark Matter Halos},
Astrophysical Journal vol. 462, p.563

\bibitem{Moore 1999} \textsc{Moore, B., Quinn, T., Governato, F., Stadel, J., Lake, G. (1999)},
\textit{Cold collapse and the core catastrophe}
Monthly Notices of the Royal Astronomical Society, vol. 310, Issue 4, pp. 1147-1152
%22%
\bibitem{b2} \textsc{Moore, B. (1994)},
\textit{Evidence against dissipation-less dark matter from observations of galaxy haloes},
Nature, vol. 370, pp. 629-631 
%23%
\bibitem{1.2.4} \textsc{Springel, V. et al. (2005)},
\textit{Simulations of the formation, evolution and clustering of galaxies and quasars},
Nature, vol 435, Issue 7042, pp. 629-636

\bibitem{b26}\textsc{Taylor, J. E.; Navarro, J. F. (2001)},
\textit{The Phase-Space Density Profiles of Cold Dark Matter Halos},
The Astrophysical Journal, vol. 563, pp. 483-488

\bibitem{b27}\textsc{Colín, P.; Klypin, A.; Valenzuela, O.; Gottlöber, S. (2004)},
\textit{Dwarf Dark Matter Halos},
The Astrophysical Journal, vol. 612, No. 1

\bibitem{b28}\textsc{Diemand, J.; Moore, B.; Stadel, J. (2005)},
\textit{Earth-mass dark-matter haloes as the first structures in the early Universe},
Nature vol. 433, pp. 389–391

\bibitem{Navarro Hayashi} \textsc{Navarro, J. F.; Hayashi, E.; Power, C.; Jenkins, A. R.; Frenk, C. S.; White, S. D. M.; Springel, V.; Stadel, J.; Quinn, T. R. (2004)}, 
\textit{The inner structure of $\Lambda$CDM haloes - III. Universality and asymptotic slopes}, 
Monthly Notices of the Royal Astronomical Society, vol. 349, Issue 3, pp. 1039-1051

\bibitem{1.2.5} \textsc{Klypin, A. A.; Kravstov, A. V.; Bullock, J. S.; Primack, J. R. (2001)},
\textit{Resolving the Structure of Cold Dark Matter Halos},
The Astrophysical Journal, vol. 554, Issue 2, pp. 903-915
%17%
\bibitem{1.2.6} \textsc{Homma, D.; Chiba, M.; Okamoto, S. et al. (2016)},
\textit{A New Milky Way satellite discovered in the SUBARU/HYPER SUPRIME-CAM survey},
The Astrophysical Journal, vol. 832, 1
\bibitem{1.2.6.1} \textsc{Dokkum, P. et al. (2018)}
\textit{A galaxy lacking dark matter}
Nature, vol. 555 pp. 629-632
%24%

%25%
\bibitem{1.3.01} \textsc{Ji, S. U.; Sin, S. J. (1994)},
\textit{Late-time phase transition and the galactic halo as a Bose liquid},
Physical Review D, vol. 50, Issue 6, pp. 3650-3654 

\bibitem{1.3.001} \textsc{Ostriker, J. P.; Steindhart, P. J. (2003)},
\textit{New Light on Dark Matter},
ArXiv preprint arXiv:astro-ph/0306402

\bibitem{Siddhartha Matos} \textsc{Guzmán, F. S.; Matos T. (2000)}, 
\textit{Scalar fields as dark matter in spiral galaxies},
Classical and Quantum Gravity, vol. 17, Issue 1, pp. L9-L16 
%26%


\bibitem{1.3.02} \textsc{Lee, J.; Koh, I. (1996)},
\textit{Galactic halos as boson stars},
Physical Review D, vol. 53, Issue 4, pp. 2236-2239

\bibitem{1.3.03} \textsc{Guzmán, F. S. Matos, T. (2000)},
\textit{Scalar Fields as Dark Matter in Spiral Galaxies}
ArXiv preprint arXiv:gr-qc/9810028

\bibitem{1.3.03.1} \textsc{Suárez, A.; Chavanis, P.-H. (2015)}
\textit{Hydrodynamic representation of the Klein-Gordon-Einstein equations
in the weak field limit: I. General formalism and perturbations analysis}
ArXiv preprint arXiv:1503.0743

\bibitem{1.3.02.1} \textsc{Magaña, J., Matos, T., Robles, V., Suárez, A. (2012)},
\textit{A brief Review of the Scalar Field Dark Matter model},
ArXiv preprint arXiv:1201.6107 [astro-ph.CO]

\bibitem{1.3.02.2} \textsc{Suárez, A., Matos, T. (2011)},
\textit{Structure formation with scalar-field dark matter: the fluid approach}
Monthly Notices of the Royal Astronomical Society, vol. 416, Issue 1, pp. 87–93


\bibitem{1.3.2.1} \textsc{Clowe, D.; et al. (2006)},
\textit{A Direct Empirical Proof of the Existence of Dark Matter},
The Astrophysical Journal, vol. 648, Issue 2, pp L109-L113

\bibitem{1.3.1} \textsc{Spergel, D. N.; Steinhardt P. J. (2000)},
\textit{Observational Evidence for Self-Interacting Cold Dark Matter},
Physical Review Letters, vol. 84, Issue 3760
%27%
\bibitem{1.3.2} \textsc{Colín, P.; Avila-Reese, V.; Valenzuela, O. (2000)},
\textit{Substructure and halo density profiles in a Warm Dark Matter Cosmology},
ArXiv preprint arXiv:astro-ph/0004115
%28%

 
\bibitem{1.3.3} \textsc{Goodman, J. (2000)},
\textit{Repulsive Dark Matter},
ArXiv preprint arXiv:astro-ph/0003018
%29%
\bibitem{1.3.4} \textsc{Hu, W.; Barkana, R.; Gruzinov, A. (2000)},
\textit{Cold and Fuzzy Dark Matter}
ArXiv preprint arXiv:astro-ph/0003365
%30%
\bibitem{1.3.5} \textsc{Kaplinghat, M.; Knox, L. Turner, M. S. (2000)},
\textit{Annihilating Cold Dark Matter}
ArXiv preprint arXiv:astro-ph/0005210
%31%
\bibitem{1.3.6} \textsc{Cen, R. (2000)},
\textit{Decaying Cold Dark Matter Model and Small-Scale Power},
ArXiv preprint arXiv:astro-ph/0005206
%32%
\bibitem{1.3.7} \textsc{Ellis, J. (2007)},
\textsc{Beyond the standard model with the LHC},
Nature, vol. 448, Issue 7151, pp. 297-301
%33%
\bibitem{1.3.8} \textsc{Milgrom, M. (2002)},
\textit{MOND--theoretical aspects}
ArXiv preprint arXiv:astro-ph/0207231
%34%
\bibitem{2.1.1} \textsc{Kravstov, A. V. (1999)},
\textit{High-resolution simulations of structure formation in the universe}
Thesis (PhD). NEW MEXICO STATE UNIVERSITY, Source DAI-B 60/11, p. 5564, May 2000, 256 pages
%35%
\bibitem{2.1.2} \textsc{O'Shea, B. W.; Bryan, G.; Bordner, J.; Norman, M. L.; Abel, T.; Harkness, R.; Kritsuk, A. (2004)},
\textit{Introducing Enzo, an AMR Cosmology Application}
ArXiv preprint arXiv:astro-ph/0403044
%36%
\bibitem{2.1.3} \textsc{Teyssier, R. (2002)},
\textit{Cosmological hydrodynamics with adaptative mesh refinement. A new high resolution code called RAMSES},
Astronomy and Astrophysics, vol.385, pp.337-364

\bibitem{b4} \textsc{Springel, V.; Yoshida, N.; White, S. D. M., (2001)}
\textit{GADGET: a code for collisionless and gasdynamical cosmological simulations },
New Astronomy Volume 6, pp. 79-117
%38%
\bibitem{b3} \textsc{Reif, F.; Scott, H. L.,(1998)},
\textit{Fundamentals of Statistical and Thermal Physics}
American Journal of Physics, vol. 66, Issue 2, pp. 164-167
%39%

%40%
\bibitem{b5} \textsc{Bodenheimer, P.; Laughlin, G. P.; Rózyczka, M.; Yorke, H. W., (2007)} 
\textit{Numerical Methods in Astrophysics: An Introduction},
CRC Press, December 2006

\bibitem{b8.2} \textsc{Barnes, J.; Hut, P. (1986)},
\textit{A hierarchical $\mathcal{O}N\log N$ force--calculation algorithm}
Nature, vol. 324, Issue 4, pp. 446-449

\bibitem{b5.1} \textsc{Klypin, A. A.; Shadarin, S. F. (1983)},
\textit{Three--dimensional numerical model of the formation of large--scale structure in the Universe}
Monthly Notices of the Royal Astronomical Society (ISSN 0035-8711), vol. 204, pp. 891-907

\bibitem{b5.2} \textsc{White, S. D. M.; Frenk, C. S.; Davis, M. (1983)},
\textit{Clustering in a neutrino--dominated universe},
Astrophysical Journal, Part 2 - Letters to the Editor (ISSN 0004-637X), vol. 274, pp. L1-L5

\bibitem{b5.3} \textsc{Parzen, E. (1962)},
\textit{On Estimation of a Probability Density Function and Mode},
Annals of Mathematical Statistics, vol. 33 no. 3 pp. 1065-1076

\bibitem{b5.4} \textsc{Boneva, L. I.; Kendall, D.; Stepanov, I. (1971)}
\textit{Spline Transformations: Three New Diagnostic Aids for the Statiscical Data-Analyst},
Journal of the Royal Statistical Society, vol. 33 no. 1 pp. 1-71
%41%
\bibitem{b6} \textsc{Gingold, R. A.; Monaghan, J.J. (1977)}
\textit{Smoothed Particle Hydrodynamics: Theory and applications to non-spherical stars},
Monthly Notices of the Royal Astronomical Society, vol. 181, pp. 375-389
%42%
\bibitem{b7} \textsc{Monaghan, J. J., (1997)}
\textit{SPH and Riemman Solvers},
Journal of Computational Physics, vol. 136, Issue 2 pp. 298-307 
%43%
\bibitem{b8} \textsc{Monaghan, J. J. (1992)}
\textit{Smoothed Particle Hydrodynamics},
%44%
\bibitem{b8.1} \textsc{Monaghan, J.J.; Lattanzio, J. C. (1985)},
\textit{A refined particle method for astrophysical problems},
Astronomy and Astrophysics (ISSN 0004-6361), vol. 149, no. 1, pp. 135-143
Annual review of astronomy and astrophysics, vol. 30 (A93-25826 09-90), pp. 543-574
%45%


\bibitem{b9} \textsc{Price, D. J. (2004)}
\textit{Smoothed Particle Magnetohydrodynamics-II. Variational principles and variable smoothing-length terms},
Monthly Notices of the Royal Astronomical Society, vol. 348, Issue 1, pp. 139-152
%46%
\bibitem{b9.1} \textsc{Gingold, R. A.; Monaghan, J.J. (1977)},
\textit{Smoothed particle hydrodynamics - Theory and application to non-spherical stars},
Monthly Notices of the Royal Astronomical Society, vol. 181, pp. 375-389
%47%
\bibitem{b9.2} \textsc{Monaghan, J. J.; Gingold, R. A. (1983)},
\textit{Shock Simulation by the Particle Method SPH},
Journal of Computational Physics, vol. 52, Issue 2, pp. 374-389

\bibitem{b10} \textsc{Springel, V. (2005)},
\textit{The cosmological simulation code: GADGET-2},
Monthly Notices of the Royal Astronomical Society, vol. 364, pp. 1105-1134
%47%
\bibitem{3.0.1} \textsc{Bode, P.; Ostriker, J. P.; Xu, G. (2000)}
\textit{The Tree-Particle-Mesh N-body Gravity Solver}
ArXiv preprint arXiv:astro-ph/9912541 


\bibitem{3.0.2} \textsc{Bagla, J. S. (2002)},
\textit{TreePM: A code for cosmological N-body simulations}
Journal of Astrophysics and Astronomy, vol. 23, Issue 3-4, pp.185-196

\bibitem{3.0.3} \textsc{Springel, V.; White,S. D. M.; Jenkins, A.; Frenk, C. S.; Yoshida, N.; Gao, L.; Navarro, J.; Thacker, R.; Croton, Da.; Helly, J.; Peacock, J. A.; Cole, S.; Thomas, P.; Couchman, H.; Evrard, A.; Colberg, J.; Pearce, F. (2005)}
\textit{Simulations of the formation, evolution and clustering of galaxies and quasars}
Nature, vol. 435, pp. 629

\bibitem{3.1} \textsc{Zhang, J., Tsai, Y.-L. S., Kuo, J.-L, Cheung, K., Chu, M.-C (2017)},
\textit{Ultra-Light Axion Dark Matter and its Impacts on Dark Halo Structure in $N$-body Simulation},
ArXiv preprint  arXiv:1611.00892v6

\bibitem{3.1.1}\textsc{Turner, M. S. (1983)},
\textit{Coherent scalar-field oscillations in an expanding universe},
Physical Review D vol. 28, pp. 1243

\bibitem{3.1.2} \textsc{Sin, S.-J. (1994)},
\textit{Late-time phase transition and the galactic halo as a Bose liquid},
Physical Review D, vol 50, pp. 3650

\bibitem{3.1.3} \textsc{Matos, T.; Guzmán, F.; Ureña-López, L. A.; Núñez, D.;(2002)},
\textit{Scalar Field Dark Matter},
Exact Solutions and Scalar Fields in Gravity (Springer), pp. 165-184

\bibitem{3.1.4} \textsc{Guzmán, F.; Ureña-López, L. A. (2003)},
\textit{Newtonian collapse of scalar field dark matter},
Physical Review D, \textbf{68}, 024023

\bibitem{3.1.5} \textsc{Kim, J. E.; Marsh, D. J.; (2016)},
\textit{An ultralight pseudoscalar boson}
Physical Review D, \textbf{93}, 025027


%48%
%\bibitem{3.1.1} \textsc{Bardos, C., Erdös, L., Goise, F., Mauser, N., Yau, H.-T (2002)},
%\textit{Derivation of the Schrödinger–Poisson equation from the quantum
%$N$-body problem}
%Comptes Rendus Mathematique, vol. 334, Issue 6, pp. 515-520
%49%
\bibitem{3.2} \textsc{Spiegel, E. A. (1980)},
\textit{Fluid form of the linear and nonlinear Schrödinger equations},
Physica D: Nonlinear Phenomena vol. 1 Issue 2, pp. 236-240 
%50%
\bibitem{3.3} \textsc{Uhleman, C., Kopp, M., Haugg, T. (2014)},
\textit{Schrödinger method as N-body double and UV completion of dust},
Physical Review D. vol. 90, Issue 2 
%51%
\bibitem{3.4}\textsc{Marsh, D. J. E. (2015)},
\textit{Nonlinear hydrodynamics of axion dark matter: Relative velocity effects and quantum forces},
Physical Review, vol. 91, Issue 12
%52%
\bibitem{3.5} \textsc{Schive, H.-Y.m Chiueh, T., Broadhurst, T. (2014)},
\textit{Cosmic structure as the quantum interference of a coherent dark wave},
Nature Physics, vol. 10, Issue 7, pp. 496

\bibitem{4.0} \textsc{White, S. D. M.; Efstathiou, G.; Frenk, C. S. (1993)},
\textit{The amplitude of mass fluctuations in the Universe}
Monthly Notices of the Royal Astronomy Society, vol. 262, pp. 1023-1028

\bibitem{4.1} \textsc{Zeldovich, Y. B. (1970)},
\textit{Gravitational instability: An approximate theory for large density perturbations},
Astronomy and Astrophysics, vol. 5, pp. 84 - 89

\bibitem{4.2} \textsc{Shandarin, S. F.; Zeldovich, Y. B. (1989)},
\textit{The large-scale structure of the universe: Turbulence, intermittency, structures in a self-gravitating medium},
Reviews of Modern Physics, vol. 61, pp. 185

\bibitem{4.3} \textsc{Hahn, O.; Abel, T. (2011)},
\textit{Multi-scale initial conditions for cosmological simulations},
ArXiv preprint, arXiv:1103.6031

\bibitem{4.3.1} \textsc{Lewis, A.; Challinor, A.; Lasenby, A. (2000)},
\textit{Efficient computation of CMB anisotropies in closed FRW models},
ArXiv preprint, arXiv:astro-ph/9911177

\bibitem{4.3.1.2} \textsc{Lesgourges, J: (2011)}, 
\textit{The Cosmic Linear Anisotropy Solving System (CLASS) I: Overview},
ArXiv preprint, arXiv:1104.2932

\bibitem{4.3.2} \textsc{Lewis, A.; Bridle, S. (2002)},
\textit{Cosmological parameters from CMB and other data: A Monte Carlo Approach},
ArXiv preprint, arXiv:astro-ph/0205436

\bibitem{4.3.3} \textsc{L'Huillier, B.; Park, C.; Kim, J. (2014)},
\textit{Effects of the initial conditions on cosmological $N$-body simulations},
ArXiv preprint, arXiv:1401.6180

\bibitem{4.3.4} \textsc{Bagla, J. S.; Rasad, J. (2006)},
\textit{Effects of the size of cosmological N-body simulations on physical quantities--I: Mass Function},
ArXiv preprint, arXiv:astro-ph/0601320

\bibitem{4.3.5} \textsc{Zhang, J., Tsai, Y.-L. S.; Kuo, J.-L; Liu, H.; Cheung, K.; Chu, M.-C (2017)},
\textit{Is Fuzzy Dark Matter in tension with Lyman-$\alpha$ forest?},
ArXiv preprint, arXiv:1708.04389

\bibitem{4.3.6} \textsc{Suárez, A.; Chavanis, P.H. (2015)},
\textit{Hydrodynamic representation of the Klein-Gordon-Einstein equations
in the weak field limit:  I. General formalism and perturbations analysis},
ArXiv preprint, arXiv:1503.07437

\bibitem{4.3.7} \textsc{Suárez, A.; Chavanis, P.H. (2017)},
\textit{Jeans type instability of a complex self-interacting scalar field in general relativity},
ArXiv preprint, arXiv 1710.10486


\bibitem{4.4.1} \textsc{Voit, G. M. (2005)},
\textit{Tracing cosmic evolution with clusters of galaxies},
Reviews of Modern Physics, vol. 77, pp. 207 


\bibitem{4.4} \textsc{Davis, M.; Efstathiou, G.; Frenk, C. S.; White, S. D. M. (1985)},
\textit{The evolution of large-scale structure in a universe dominated by cold dark matter},
Astrophysical Journal, Part 1 (ISSN 0004-637X), vol. 292, pp. 371-394 

\bibitem{4.4.2} \textsc{Press, W. H.; Schechter, P. (1973)},
\textit{Formation of Galaxies and Clusters of Galaxies by Self-Similar Gravitational Condensation},
Astrophysical Journal, vol. 187, pp. 425-438

\bibitem{4.4.3} \textsc{Mo, H. J.; White, S. D. M. (1996)},
\textit{An analytic model for the spatial clustering of dark matter haloes},
Monthly Notices of the Royal Astronomical Society, vol. 282, Issue 2, pp. 347-361

\bibitem{4.4.4} \textsc{Sheth, R. K.; Tormen, G. (1999)},
\textit{Large-scale bias and the peak background split},
Monthly Notices of the Royal Astronomical Society, vol. 308, Issue 1, pp. 119-126

\bibitem{4.4.5}\textsc{Jenkins, A.; Frenk, C. S.; White, S. D. M.; Colberg, J. M.; Cole, S.; Evrard, A. E.; Couchman, H. M. P.; Yoshida, N. (2001)},
\textit{The mass function of dark matter haloes},
Monthly Notices of the Royal Astronomical Society, vol. 321, Issue 2, pp. 372-384


\bibitem{4.4.6} \textsc{Moore, B.; Ghigna, S.; Governato, F. (1999)},
\textit{Dark Matter Substructure within Galactic Halos},
The Astrophysical Journal, vol.524, pp. L19-L22

\bibitem{4.4.7} \textsc{Ghigna, S.; Moore, B.; Governato, F.; Lake, G.; Quinn, T.; Stadel, J. (2000)},
\textit{Density Profiles and Substructure of Dark Matter Halos: Converging Results at Ultra-High Numerical Resolution},
The Astrophysical Journal, vol. 544, Issue 2, pp. 616-628

\bibitem{4.4.8} \textsc{De Lucia G.; Kauffmann G.; Springel V.; White S. D. M; Lanzoni B.; Stoehr F.; Tormen G.; Yoshida N. (2004)},
\textit{Substructures in cold dark matter haloes},
Monthly Notices of the Royal Astronomical Society, vol. 348, pp. 333-344



%\bibitem{4.5} \textsc{Knollmann, S. R.; Knebe, A. (2009)},
%\textit{AHF: Amiga's Halo Finder},
%The Astrophysical Journal Supplement, vol. 182, Issue 2, pp. 608-624

\bibitem{4.5} \textsc{Colombi, S.; Jaffe, A.; Novikov, D.; Pichon, C. (2009)},
\textit{Accurate estimators of power spectra in N-body simulations}, 
Monthly Notices of the Royal Astronomical Society, vol. 393, Issue 2, pp. 511-526

\bibitem{4.6} \textsc{Wang, Z.; Bovik, A. C.; Sheikh, H. R.; Simoncelli E. P. (2004)}
\textit{Image Quality Assessment: From Error Visibility to Structural Similarity}
IEEE Transactions On Image Processing, vol. 13, no. 4
\end{thebibliography}
\end{document}